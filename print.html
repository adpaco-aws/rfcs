<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Cedar RFC Book</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Cedar RFC Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><a href="https://www.cedarpolicy.com/en">Cedar</a>
is an open source policy language and evaluation engine.
This book collects all the accepted RFCs
(<a href="https://en.wikipedia.org/wiki/Request_for_Comments">Request for Comments</a>) for Cedar,
providing a central repository for easier access and reference.</p>
<h1 id="rfc-status"><a class="header" href="#rfc-status">RFC Status</a></h1>
<!-- TBD -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-template-fill-in-your-title-here"><a class="header" href="#rfc-template-fill-in-your-title-here">RFC Template (Fill in your title here)</a></h1>
<h2 id="related-issues-and-prs"><a class="header" href="#related-issues-and-prs">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: (fill in existing related issues, if any)</li>
<li>Implementation PR(s): (leave this empty)</li>
</ul>
<h2 id="timeline"><a class="header" href="#timeline">Timeline</a></h2>
<ul>
<li>Started: (fill in with today's date, YYYY-MM-DD)</li>
<li>Accepted: TBD</li>
<li>Landed: TBD</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>Brief explanation of the feature.</p>
<h2 id="basic-example"><a class="header" href="#basic-example">Basic example</a></h2>
<p>If the proposal involves a new or changed API, include a basic code example.
Omit this section if it's not applicable.</p>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>Why are we doing this? What use cases does it support? What is the expected
outcome?</p>
<p>Please focus on explaining the motivation so that if this RFC is not accepted,
the motivation could be used to develop alternative solutions. In other words,
enumerate the constraints you are trying to solve without coupling them too
closely to the solution you have in mind.</p>
<h2 id="detailed-design"><a class="header" href="#detailed-design">Detailed design</a></h2>
<p>This is the bulk of the RFC. Explain the design in enough detail for somebody familiar with Cedar to understand, and for somebody familiar with the implementation to implement. This should get into specifics and corner-cases, and include examples of how the feature is used. Any new terminology should be defined here.</p>
<h2 id="drawbacks"><a class="header" href="#drawbacks">Drawbacks</a></h2>
<p>Why should we <em>not</em> do this? Please consider:</p>
<ul>
<li>implementation cost, both in term of code size and complexity</li>
<li>integration of this feature with other existing and planned features</li>
<li>cost of migrating existing Cedar applications (is it a breaking change?)</li>
</ul>
<p>There are tradeoffs to choosing any path. Attempt to identify them here.</p>
<h2 id="alternatives"><a class="header" href="#alternatives">Alternatives</a></h2>
<p>What other designs have been considered? What is the impact of not doing this?</p>
<h2 id="unresolved-questions"><a class="header" href="#unresolved-questions">Unresolved questions</a></h2>
<p>Optional, but suggested for first drafts. What parts of the design are still
TBD?</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="is-operator"><a class="header" href="#is-operator"><code>is</code> Operator</a></h1>
<h2 id="related-issues-and-prs-1"><a class="header" href="#related-issues-and-prs-1">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: <a href="https://github.com/cedar-policy/cedar/issues/94">https://github.com/cedar-policy/cedar/issues/94</a></li>
<li>Implementation PR(s): <a href="https://github.com/cedar-policy/cedar/pull/396">https://github.com/cedar-policy/cedar/pull/396</a></li>
</ul>
<h2 id="timeline-1"><a class="header" href="#timeline-1">Timeline</a></h2>
<ul>
<li>Started: 2023-06-16</li>
<li>Accepted: 2023-07-28</li>
<li>Landed: 2023-11-08 on <code>main</code></li>
<li>Released: 2023-12-15 in <code>cedar-policy</code> v3.0.0</li>
</ul>
<h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<p>This RFC proposes to add an <code>is</code> operator to the Cedar language that allows users to check the type of entities.</p>
<h2 id="basic-example-1"><a class="header" href="#basic-example-1">Basic example</a></h2>
<p>Say that a user wants to allow any <code>User</code> to view files in the folder <code>Folder::"public"</code>.
With an <code>is</code> operator, the following policy achieves this goal.</p>
<pre><code>permit(
  principal is User,
  action == Action::"viewFile",
  resource is File in Folder::"public"
);
</code></pre>
<p>At evaluation time, <code>principal is User</code> will evaluate to true if the type of <code>principal</code> is <code>User</code>, and <code>resource is File in Folder::"public"</code> will evaluate to true if the type of <code>resource</code> is <code>File</code> and it is a member of <code>Folder::"public"</code>.</p>
<h2 id="motivation-1"><a class="header" href="#motivation-1">Motivation</a></h2>
<p>The <code>is</code> operator allows users to restrict the scope of their policies to particular entity types.</p>
<p>In many cases, this can also be done by adding restrictions to the schema.
For example, the <code>appliesTo</code> field for each action in the schema allows users to specify which entity types can be used as principals and resources for that action.
In the example <a href="0005-is-operator.html#basic-example">above</a>, the schema could specify that <code>viewFile</code> should only apply to principals of type <code>User</code> and resources of type <code>File</code>.
However, this doesn't help if the user is not using a schema, the action is unconstrained, or the policy refers to an action that may act on multiple principal/resource types.</p>
<p>For example, here is one case where the action is unconstrained, taken from the Cedar <a href="https://github.com/cedar-policy/cedar-examples/tree/main/cedar-example-use-cases/document_cloud">document cloud example</a>.</p>
<pre><code>forbid (principal, action, resource)
when
{
  resource has owner &amp;&amp;
  principal != resource.owner &amp;&amp;
  resource has isPrivate &amp;&amp;
  resource.isPrivate
};
</code></pre>
<p>This policy applies to any principal, action, resource pair, but requires that the resource has <code>owner</code> and <code>isPrivate</code> attributes.
If the resource does not have these attributes, then the policy is a no-op.</p>
<p>Say that only one entity type (e.g., <code>File</code>) has the fields <code>owner</code> and <code>isPrivate</code>.
Then this policy can be written more succinctly as follows.</p>
<pre><code>forbid (principal, action, resource is File)
when
{
  principal != resource.owner &amp;&amp;
  resource.isPrivate
};
</code></pre>
<h2 id="detailed-design-1"><a class="header" href="#detailed-design-1">Detailed design</a></h2>
<h3 id="changes-required-to-parserast"><a class="header" href="#changes-required-to-parserast">Changes required to parser/AST</a></h3>
<ul>
<li>Update the grammar and AST to support expressions of the form <code>e is et</code> where <code>et</code> is a <code>Name</code> (e.g., <code>Namespace::EntityType</code>).</li>
<li>Update the grammar and AST to support expressions of the form <code>e1 is et in e2</code> (but not <code>e1 in e2 is et</code>, because this is more difficult to mentally parse).</li>
<li>Update the grammar to allow expressions like <code>e is et</code> and <code>e1 is et in e2</code> in the policy scope for principals and resources.
The action part of the scope will only allow expressions like <code>action == Action::"foo"</code> and <code>action in [Action::"foo", Action::"bar"]</code>, as before.</li>
</ul>
<h3 id="changes-required-to-evaluator"><a class="header" href="#changes-required-to-evaluator">Changes required to evaluator</a></h3>
<p><code>e is et</code> will evaluate to true iff <code>et</code> is a <code>Name</code> (e.g., <code>Namespace::EntityType</code>) and <code>e</code> is an expression that is an entity of type <code>et</code>.
If <code>e</code> is an entity-typed expression, but does not have type <code>et</code>, then <code>e is et</code> will evaluate to false.
If <code>e</code> is a non-entity-typed expression, the evaluator will produce a type error.</p>
<p>Note that this design maintain the property that "conditions in the scope never error" because <code>principal</code> and <code>resource</code> are guaranteed to be entities, so the expression <code>(principal|resource) is et</code> will never error.</p>
<p>Namespaces are considered "part of" the entity type. So:</p>
<ul>
<li><code>User::"alice" is User</code> is true</li>
<li><code>Namespace::User::"alice" is User</code> is false</li>
<li><code>Namespace::User::"alice" is Namespace::User</code> is true</li>
<li><code>User::"alice" is Namespace::User</code> is false</li>
</ul>
<h3 id="changes-required-to-validator"><a class="header" href="#changes-required-to-validator">Changes required to validator</a></h3>
<p><code>e is et</code> will be typed as <code>True</code> if the validator can guarantee that expression <code>e</code> is an entity of type <code>et</code>, or <code>False</code> if the validator can guarantee that <code>e</code> is an entity not of type <code>et</code>.
If the validator can guarantee that <code>e</code> is an entity, but not determine the exact type, then <code>e is et</code> is given type <code>Bool</code>.
Otherwise, the validator produces a type error.</p>
<p>To improve typing precision, we can extend the current notion of "effects" to track information about entity types.
Currently, the validator uses effects to know whether an expression is guaranteed to have an attribute.
In particular, the validator knows that if <code>e has a</code> evaluates to true, then expression <code>e</code> is guaranteed to have attribute <code>a</code>.
We can do something similar for <code>is</code>: when the expression <code>e is et</code> evaluates to true, expression <code>e</code> is guaranteed to be an entity of type <code>et</code>.</p>
<h3 id="other-changes"><a class="header" href="#other-changes">Other changes</a></h3>
<p>The Dafny formalization of the Cedar language, corresponding proofs, and differential testing framework in <a href="https://github.com/cedar-policy/cedar-spec">cedar-spec</a> will need to be updated to include the new <code>is</code> operator.</p>
<h2 id="drawbacks-1"><a class="header" href="#drawbacks-1">Drawbacks</a></h2>
<ol>
<li>
<p>This is a substantial new feature that will require significant development effort.</p>
</li>
<li>
<p>This change will break existing applications that depend on the structure of policies. For example, if we decide to allow <code>is</code> in the policy scope (as shown in the examples above), tools that perform basic "policy slicing" based on the scope will need to decide how to handle the new syntax.</p>
</li>
<li>
<p>The <code>is</code> operator may encourage coding practices that go against our recommended "best practices" (more details below).</p>
</li>
</ol>
<h3 id="best-practice-using-typed-actions"><a class="header" href="#best-practice-using-typed-actions">Best practice: Using "typed" actions</a></h3>
<p>From the discussion on <a href="https://github.com/cedar-policy/cedar/issues/94">https://github.com/cedar-policy/cedar/issues/94</a>:</p>
<blockquote>
<p>Guidance we have given other customers is that actions should be "typed," in the sense that they include in their name the type of the resource they apply to. So instead of writing</p>
<pre><code>permit(
  principal == User::"admin",
  action == Action::"view",
  resource is Photo
);
</code></pre>
<p>you would write</p>
<pre><code>permit(
  principal == User::"admin",
  action == Action::"viewPhoto",
  resource
);
</code></pre>
<p>In your schema, you indicate that the "viewPhoto" action should always be accompanied by a <code>Photo</code> for the resource, so the policy doesn't need to say that explicitly (and doesn't need to perform a runtime check).</p>
</blockquote>
<p>If we support an <code>is</code> operator, then customers may be encouraged to use a single "view" action for multiple resource types, rather than a new "viewX" action for each resource type X.</p>
<h2 id="alternatives-1"><a class="header" href="#alternatives-1">Alternatives</a></h2>
<ol>
<li>
<p>Another way to simulate <code>is</code> is to add an <code>entity_type</code> attribute to entities, and check the type of an entity using <code>resource.entity_type == "File"</code> (for example).
However, this requires users to manually add an entity's type as an attribute, and leads to the possibility that an entity might be created with an attribute that doesn't actually match its type.</p>
</li>
<li>
<p>The behavior of <code>is</code> can also be simulated using groups.
For each entity type (e.g., <code>File</code>), a user could create a group (e.g., <code>Type::"File"</code>) and add all entities of that type to the group.
Then to check whether an entity has a particular type, users could use <code>in</code> (e.g., <code>resource in Type::"File"</code>).
Like alternative (2), this requires some extra work on the part of the user (setting up the memberOf relation), and does not prevent entities from being added as members of the wrong group.</p>
</li>
</ol>
<h2 id="resolved-questions"><a class="header" href="#resolved-questions">Resolved questions</a></h2>
<ul>
<li>Should we allow <code>is</code> in the policy scope?
Currently we only allow <code>==</code> and <code>in</code> expressions in the scope, with the intention that these expressions can be used to represent RBAC constraints, whereas more general expressions in the policy condition can be used to express ABAC constraints.
<ul>
<li><em>Decision:</em> We will allow <code>is</code> and <code>is ... in</code> in the scope.</li>
<li><em>Summary of discussion:</em>
<ul>
<li>We feel that <code>is</code> is natural to write in the policy scope since it limits the "scope" of the policy.</li>
<li>Most requests we have received for this feature use an example with <code>is</code> in the scope, confirming our belief that this is the most natural location for its use.</li>
<li>Although <code>is</code> is not currently used for policy indexing, it could be in the future, and current indexing strategies can safely ignore <code>is</code> constraints in the meantime.</li>
</ul>
</li>
</ul>
</li>
<li>Should users be able to indicate that an entity may be of multiple types, e.g., <code>principal is [User, Group]</code>? Can this be combined with <code>in</code> (e.g., <code>principal is [User, Group] in Group::"orgA"</code>, or even <code>principal is [User, Group] in [Group::"orgA", Group::"orgB"]</code>)?
<ul>
<li><em>Decision:</em> We will not support this. The syntax is more difficult to read and the same behavior can be achieved by writing multiple policies instead. We may reconsider this position based on user feedback.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="disallow-embedded-whitespace-in-string-representations-of-the-entityuid"><a class="header" href="#disallow-embedded-whitespace-in-string-representations-of-the-entityuid">Disallow embedded whitespace in string representations of the EntityUID</a></h1>
<h2 id="related-issues-and-prs-2"><a class="header" href="#related-issues-and-prs-2">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: none</li>
<li>Implementation PR(s): <a href="https://github.com/cedar-policy/cedar/pull/134">https://github.com/cedar-policy/cedar/pull/134</a></li>
</ul>
<h2 id="timeline-2"><a class="header" href="#timeline-2">Timeline</a></h2>
<ul>
<li>Started: 2023-06-19</li>
<li>Accepted: 2023-06-26</li>
<li>Landed: 2023-06-28 on <code>main</code></li>
<li>Released: 2023-06-29 in <code>cedar-policy</code> v2.3.0</li>
</ul>
<h2 id="summary-2"><a class="header" href="#summary-2">Summary</a></h2>
<p>Disallow embedded whitespace, comments, and control characters in string representations of the EntityUID</p>
<h2 id="basic-example-2"><a class="header" href="#basic-example-2">Basic example</a></h2>
<p>Currently, the following syntax is legal:</p>
<pre><code>EntityTypeName::from_str("ExampleCo  ::  Photoflash  ::  User  //comment");
</code></pre>
<p>This change would modify the function so that the string input must be normalized; i.e. all extraneous whitespace, control characters, and comments removed.</p>
<pre><code>EntityTypeName::from_str("ExampleCo::Photoflash::User");
</code></pre>
<h2 id="motivation-2"><a class="header" href="#motivation-2">Motivation</a></h2>
<p>Similar to other programming languages such as Rust, Cedar is currently whitespace agnostic. This leads to the ability to embed whitespace, control characters like newlines, and comments around the <code>::</code> delimiter in an Entity UID.</p>
<p>For example, the following syntax is valid:</p>
<pre><code>permit(
  principal == ExampleCo :: Photoflash  ::  //This is a comment
       :: User::"alice",
  action,
  resource
);

permit(
  principal == ExampleCo::Photoflash::User:://comment

  "alice",
  action,
  resource
);
</code></pre>
<p>This capability was little known, even amongst many Cedar team members, and was only identified as a result of a typo in a Cedar demo. While this behavior may be OK inside policy statements, there is a risk when policy contents such as the EntityTypeName are used as strings outside the context of policy statements, such as in the JSON schema representation. For laypersons who are not Cedar experts, these values appear to be normalized strings rather than fragments of Cedar policy syntax, leading to bugs in application code when whitespace and comments can appear in the value.</p>
<p>Examples:</p>
<ol>
<li>The Cedar Schema format models the schema configuration under a JSON key for the namespace. Policy stores which index schemas by namespace are unlikely to recognize the need to normalize the value, leading to the possibility of storing duplicate schema definitions for "ExampleCo::Photoflash" and "ExampleCo  ::  Photoflash" and indeterminate behavior regarding which schema takes effect at runtime.</li>
<li>Policy Stores can implement logic that relies on string comparisons against the EntityTypeName. In a real issue, an application using Cedar sought to preclude callers from passing Actions in the inline slice of entity definitions. It did so by checking if an EntityTypeName matched <code>.*::Action</code>. It presumed that <code>:: Action</code> was invalid syntax and would be rejected by the Cedar evalator, the same as any other syntatically invalid input. This resulted in a bug, as it allowed callers to bypass the extra validation that the application sought to enforce.</li>
<li>Customers are anticipated to build meta-permissions layers that restrict callers to manipulating policy store contents for only certain namespaces. This may lead to policies such as <code>forbid(...) when {context.namespace = "ExampleCo::Photoflash"};</code>. There is a risk that an unauthorized actor could bypass this restriction by using a namespace with embedded spaces.</li>
</ol>
<p>While it is technically possible for applications to mitigate this risk by diligently using Cedar tooling to normalize the values, the little-known nature of this Cedar behavior implies that few will know they <em>should</em> normalize the value. As a point of reference, application developers who have worked with Cedar extensively for over a year were bitten by this bug in production. Hence, this is likely to result in bugs in many other Cedar-based implementation with similar logic, risking a perception that Cedar is fragile or unsafe.</p>
<h2 id="detailed-design-2"><a class="header" href="#detailed-design-2">Detailed design</a></h2>
<p>In <code>EntityTypeName::from_str()</code>, whitespace would be disallowed throughout -- either before, after, or in the middle of the typename. The analagous change will also be made in functions <code>EntityNamespace::from_str()</code> and <code>EntityUid::from_str()</code>.</p>
<h2 id="drawbacks-2"><a class="header" href="#drawbacks-2">Drawbacks</a></h2>
<p>This is a breaking change. We do not generally want breaking changes in Cedar. It is being proposed only because it is believed the risk of breakage is low, and any potential short-term impacts to stability will pay long-term dividends in Cedar's perceived reliability.</p>
<p>The parties most at risk are those who accept <em>ad hoc</em> values of EntityTypeName from callers in a string format where the values may contain embedded whitespace. At the current time, the only known party who does this in a production setting is Amazon Verified Permissions. Due to the relative newness of Amazon Verified Permissions, this party is accepting of the change as it is not expected to break any production scenarios, and appears to be a valid risk to accept in order to benefit the Cedar community in the long-term.</p>
<p>Other parties at risk are those who use static, programmatically defined values of EntityTypeName where the code contains a typo in the value that accidentally includes additional whitespace. The belief is that this is likely to get caught in a test environment before going to production, and represents a typo that the impacted party may wish to fix, regardless.</p>
<p>The last party at risk are those who allow customers to upload custom schema files where the namespace value may contain whitespaces. The only known party who accepts adhoc schema uploads from customers with namespaces is Amazon Verified Permissions, which is accepting of this change.</p>
<p>To test these assumptions, this change will preceeded by reach-outs to Cedar early adopters to highlight the risks and gain community buy-in on the approach.</p>
<h2 id="alternatives-2"><a class="header" href="#alternatives-2">Alternatives</a></h2>
<p>An alternative is to modify the policy syntax to disallow embedded whitespace in Entity UID across all parts of Cedar, including within policy statements. This could be done by treating the UID as a single identifier with special structure (rather than tokenizing it into <code>::</code> separated sequence of identifiers).</p>
<p>One additional benefit of this approach is that it can mitigate attempts by pentesters and malicious actors who may seek ways to craft Cedar policy statements that look like they do one thing, but actually do another. The existence of little known parsing behaviors provide an avenue for exploration by this audience, as demonstrated by the following example:</p>
<pre><code>permit(
  principal == ExampleCo::Photoflash::User:://"alice"

  "bob", //TODO: Try various tricks to obfuscate this line from readers
  action,
  resource
);
</code></pre>
<p>Despite the potential benefit, this alternative was rejected due to the high risk of breaking existing Cedar users. In the worst case scenario, a customer may have an existing <code>forbid</code> statement that relies on this behavior as illustrated below. By changing the behavior, the <code>forbid</code> statement will error at runtime and be skipped, and hence the system could fail open.</p>
<pre><code>forbid(
  principal in ExampleCo:: Photoflash::UserGroup::"someGroup", //Accidential typo, but valid syntax
  action == ExampleCo:: Photoflash::Action::"write",
  resource
);
</code></pre>
<p>This risk is too great. Therefore, the suggested approach is a compromise that mitigates the known production bugs with fewer risks. Any concerns about pentesters and malicious actors crafting obfuscated policies will need to be addressed by other non-breaking means, such as linter warnings and syntax highlighting.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="standalone-strict-validation"><a class="header" href="#standalone-strict-validation">Standalone strict validation</a></h1>
<h2 id="related-issues-and-prs-3"><a class="header" href="#related-issues-and-prs-3">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues:</li>
<li>Implementation PR(s): https://github.com/cedar-policy/cedar/pull/282 and https://github.com/cedar-policy/cedar-spec/pull/111</li>
</ul>
<h2 id="timeline-3"><a class="header" href="#timeline-3">Timeline</a></h2>
<ul>
<li>Started: 2023-07-11</li>
<li>Accepted: 2023-09-05</li>
<li>Landed: 2023-09-08 on <code>main</code></li>
<li>Released: 2023-12-15 in <code>cedar-policy</code> v3.0.0</li>
</ul>
<h2 id="summary-3"><a class="header" href="#summary-3">Summary</a></h2>
<p>Internally, strict validation of a policy is implemented as 1/ checking and transforming the policy using a <em>permissive</em> validation mode; 2/ annotating the transformed policy with types, and 3/ checking the types against more restrictive rules. We would like to be able to at least <em>explain</em> strict mode independently of permissive mode, but there is no easy way to do that. This RFC proposes to separate strict mode from permissive mode, making the implementation simpler and more understandable/explainable, though somewhat more strict.</p>
<h2 id="motivation-3"><a class="header" href="#motivation-3">Motivation</a></h2>
<p>Consider this policy, given in file <a href="./0019/policy.cedar"><code>policy.cedar</code></a>, where <code>principal</code> is always of type <code>User</code>:</p>
<pre><code>permit(
    principal,
    action == Action::"read",
    resource)
when {
  (if context.sudo then Admin::"root" else principal) == resource.owner ||
  resource.isPublic
}
</code></pre>
<p>If we validate this policy against the schema <a href="./0019/schema.cedarschema.json"><code>schema.cedarschema.json</code></a>, then <code>resource.owner</code> is always of type <code>User</code>. As a result, the policy is rejected by strict-mode validation, with two errors:</p>
<ol>
<li>the <code>if</code>/<code>then</code>/<code>else</code> is trying to return entity type <code>Admin</code> in the true branch, and entity type <code>User</code> on the false branch, and these two are not equal.</li>
<li>since <code>resource.owner</code> has type <code>User</code>, it will have a type different than that returned by the <code>if</code>/<code>then</code>/<code>else</code>, which can sometimes return <code>Admin</code>.</li>
</ol>
<p>But if we change <code>"User"</code> in <a href="./0019/schema.cedarschema.json"><code>schema.cedarschema.json</code></a> on line 13 to <code>"Org"</code>, then <code>resource.owner</code> is always of type <code>Org</code>. As a result, the policy is accepted! The two error conditions given above seem not to have changed -- the conditional returns different types, and those types may not equal the type of <code>resource.owner</code> -- so it's puzzling what changed to make the policy acceptable.</p>
<p>The reason is that strict-mode validation is dependent on permissive-mode validation. In particular, strict-mode validation is implemented in three steps: 1/ validate and transform the policy using permissive mode; 2/ annotate the transformed policy AST with types; and 3/ check the types against more restrictive rules.</p>
<p>In the first case, when <code>resource.owner</code> is always of type <code>User</code>, the expression <code>(if ...) == resource.owner</code> has type <code>Boolean</code> in permissive mode and as a result no transformation takes place in step 1. As a result, it is rejected in step 3 due to the errors given above.</p>
<p>In the second case (after we change the schema), <code>resource.owner</code> is always of type <code>Org</code>. Under permissive mode, the <code>(if ...) == resource.owner</code> expression has singleton type <code>False</code>. That’s because the <code>(if ...)</code> expression has type <code>User|Admin</code> ("<code>User</code> or <code>Admin</code>") and <code>User|Admin</code> entities can never be equal to <code>Org</code> entities. Both the <em>singleton type</em> <code>False</code> (which only validates an expression that <em>always</em> evaluates to <code>false</code>) and <em>union types</em> like <code>User|Admin</code> are features of permissive mode and are not present in strict mode. Because of these features, step 1 will replace the <code>False</code>-typed <code>(if ...) == resource.owner</code> with value <code>false</code>, transforming the policy to be <code>permit(principal,action,resource) when { false || resource.isPublic }</code>. Since this policy does not require union types and otherwise meets strict mode restrictions, it is accepted in step 3.</p>
<p>In sum: To see why the second case is acceptable, we have to understand the interaction between permissive mode and strict mode. This is subtle and difficult to explain. Instead, we want to implement strict mode as a standalone feature, which does not depend on features only present in permissive mode.</p>
<h2 id="detailed-design-3"><a class="header" href="#detailed-design-3">Detailed design</a></h2>
<p>We propose to change strict-mode validation so that it has the following features taken from permissive mode:</p>
<ul>
<li>Singleton boolean <code>True</code>/<code>False</code> types (which have 1/ special consideration of them with <code>&amp;&amp;</code>, <code>||</code>, and conditionals, and 2/ subtyping between them and <code>Boolean</code>, as is done now for permissive mode).</li>
<li>Depth subtyping, but not width subtyping, to support examples like <code>{ foo: True } &lt;: { foo: Boolean }</code>.</li>
</ul>
<p>Strict-mode validation will continue to apply the restriction it currently applies:</p>
<ul>
<li>Arguments to <code>==</code> must have the compatibles types (i.e., an upper bound exists according to the strict - depth only - definitions of subtyping) <em>unless</em> we know that comparison will always be false, in which case we can give the <code>==</code> type <code>False</code>. The same goes for <code>contains</code>, <code>containsAll</code>, and <code>containsAny</code>.</li>
<li>Arguments to an <code>in</code> expression must be compatible with the entity type hierarchy, or we must know that the comparison is always false.</li>
<li>Branches of a conditional must have compatible types <em>unless</em> we can simplify the conditional due to the guard having a <code>True</code>/<code>False</code> type.</li>
<li>The elements of a set must have compatible types.</li>
<li>As a consequence of the two prior restrictions, union types cannot be constructed.</li>
<li>Empty set literals may not exist in a policy because we do not currently infer the type of the elements of an empty set.</li>
<li>Extension type constructors may only be applied to literals.</li>
</ul>
<p>Validating <code>Action</code> entities and template slots <code>?principal</code> and <code>?resource</code> must be done differently so as not to rely on the "top" entity type <em>AnyEntity</em>, which is essentially an infinite-width union type, used internally.
Next, we describe how we propose to handle these situations, in both permissive and strict validation.
Importantly, these changes all retain or even <em>improve</em> precision compared to the status quo -- they will <em>not</em> be the reason that policies that typechecked under the old strict mode no longer do.</p>
<h3 id="actions"><a class="header" href="#actions">Actions</a></h3>
<p>Permissive mode validation considers different <code>Action</code>s to have distinct types, e.g., <code>Action::"view"</code> and <code>Action::"update"</code> don't have the same type.
This is in anticipation of supporting distinct actions having distinct attribute sets.
The least upper bound of any two actions is the type <em>AnyEntity</em>.
Such a type supports expressions that are found in the policy scope such as <code>action in [Action::"view", Action::"edit"]</code>.
This expression typechecks because the least upper bound of <code>Action::"view"</code> and <code>Action::"edit"</code> is <em>AnyEntity</em> so the expression is type <code>Set&lt;</code><em>AnyEntity</em><code>&gt;</code>.
Since <em>AnyEntity</em> cannot be used in strict validation, the current code special-cases the above expression, treating it as equivalent to <code>action in Action::"view" || action in Action::"edit"</code>.
However, this approach is unsatisfying as it only supports literal sets of <code>Action</code> entities.</p>
<p>It turns out we can resolve this issue by making all <code>Action</code> entities have one type -- <code>Action</code> -- in both strict and permissive validation.
This change strictly <em>adds</em> precision to validation, compared to the status quo.
Expressions like <code>[Action::"view", Action::"edit"]</code> have type <code>Set&lt;Action&gt;</code> and thus do not need <em>AnyEntity</em> to be well-typed.
Expressions like <code>if principal.isAdmin then Action::"edit" else Action::"editLimited"</code> will typecheck in strict validation, since both branches have the same type (<code>Action</code>).</p>
<p>A possible drawback of this change is that it will not allow distinct actions to have distinct attribute sets (if indeed we add attributes to actions in the future).
Rather, all actions must be typeable with the same record type.
As a mitigation, for action entities that have an attribute that others do not, the attribute can be made optional.
However, two entities would not be able to have the same attribute at <em>different</em> types, e.g., <code>{ foo: String }</code> vs. <code>{ foo: Long }</code>.
Arguably, this restriction is clearer and more intuitive than what would have been allowed before.</p>
<h3 id="template-slots"><a class="header" href="#template-slots">Template slots</a></h3>
<p>There are no restrictions on what entity type can be used to instantiate a slot in a template, so the permissive typechecker also uses <em>AnyEntity</em> here.
The only restriction on the type of a slot is that it must be instantiated with an entity type that exists in the schema.
The strict validator today does not properly support validating templates, which is something we want to allow.</p>
<p>Because <em>AnyEntity</em> cannot be used in strict validation, we will modify both permissive and strict validation to precisely typecheck a template by extending the query type environment to include a type environment for template slots.
Doing so will strictly <em>improve</em> precision for permissive validation; all templates that validated before will still do so after this change.</p>
<p>Here is how the change will work.
In the same way that we typecheck a policy once for each possible binding for the types of <code>principal</code> and <code>resource</code> for a given action, we will also typecheck a template once for every possible binding for the type of any slots in that template.</p>
<p>Typechecking for every entity type may seem excessive,
but we know that a template slot can only occur in an <code>==</code> or <code>in</code> expression in the policy scope where the <code>principal</code> or <code>resource</code> is compared to the slot.
We will infer the type <code>False</code> for these expression if the slot is an entity type that cannot be <code>==</code> or <code>in</code> the principal or resource entity type, short-circuiting the rest of typechecking for that type environment.
Typechecking could be optimized by recognizing and ignoring type environments that will be <code>False</code> based only on the policy scope.</p>
<p>For example, using the schema from the motivating example, the following template will typecheck.</p>
<pre><code>permit(principal == ?principal, action == Action::"read", resource);
</code></pre>
<p>Using the usual request type environment construction, there is one environment <code>(User, Action::"read", Object)</code>.
Because this is a template containing <code>?principal</code>, we extend the environment with each possible type for the slot: <code>User</code>, <code>Org</code>, <code>Admin</code> and <code>Object</code>.
When typechecking, the validator sees <code>principal == ?principal &amp;&amp; ...</code> first in every environment which is always an equality between two entity types.
The <code>principal</code> is always a <code>User</code> while <code>?principal</code> is one of the possible slot types depending on the type environment.
In every environment where <code>?principal</code> is not <code>User</code>, the equality has type <code>False</code>, causing the <code>&amp;&amp;</code> to short-circuit to type <code>False</code>.
The rest of the policy is typechecked as usual when <code>?principal</code> is <code>User</code>.</p>
<p>This change will match the precision of the validator today, and will enable more precise typechecking if we expand where in a policy template slots may be used.
In particular, if we allowed expressions like <code>?principal.foo == 2</code> in the condition of a policy, the above approach would allow us to know precisely that <code>?principal</code> will always have a <code>foo</code> attribute, whereas the current approach using <em>AnyEntity</em> would not be able to.</p>
<h3 id="implementation-details"><a class="header" href="#implementation-details">Implementation details</a></h3>
<p>The current way we implement strict mode will change to accommodate these additions. We propose the following:</p>
<ol>
<li>Change the Rust code to implement strict mode by reusing the logic of permissive mode​ and using a flag to perform more restrictive checks. For example, when given <code>User</code> and <code>Admin</code> entity types, the code performing the least-upper-bound computation will return union type <code>User|Admin</code> in permissive mode, and will fail in strict mode. And, the code for conditionals would force branches' types to match in strict mode, but not in permissive mode. Etc.</li>
<li>When checking in strict mode, we construct a new AST that performs the needed transformations, as in step 2 today.</li>
<li>Either way, we can add type annotations. For strict mode, they could be added during the transformation; for permissive mode, no transformation is needed. No checking is done after annotations are added, since the checking is always done, regardless of mode, prior to the transformation.</li>
</ol>
<h2 id="drawbacks-3"><a class="header" href="#drawbacks-3">Drawbacks</a></h2>
<p>The main drawback of this approach is that strict-mode validation will be more restrictive. This is by design: Policies like the one in the motivating example will be rejected where before they were accepted. Accepting this RFC means we are prioritizing understandability over precision under the assumption that the lost precision will not be missed.</p>
<p>Policies that validated before but will not validate now are quite odd -- they would rely on the use of width subtyping, unions, etc. to determine that an expression will always evaluate to <code>true</code> (or <code>false</code>) and thus can be transformed away. But policies like these will be like those in the motivating example at the start of this RFC, and are probably not what the user intended in the first place. Ultimately, flagging them as erroneous is safer.</p>
<p>A secondary drawback is that this change will result in a non-trivial, and backwards-incompatible code change.
Mitigating this issue is that the backward incompatibility will be minimal in practice (per the above), and we will use verification-guided development to prove that the change is sound (i.e., will not introduce design or implementation mistakes).</p>
<h2 id="alternatives-3"><a class="header" href="#alternatives-3">Alternatives</a></h2>
<p>The proposal is, we believe, the minimal change to make strict mode self-contained, but not too different from what was there before. It also should not result in pervasive changes to the existing code. Alternative designs we considered (e.g., allowing more permissive mode features in strict mode) would be more invasive.</p>
<h2 id="updates"><a class="header" href="#updates">Updates</a></h2>
<ul>
<li>2023-11-07: The original text said that the handling of unspecified entities needed to be adjusted. However, although released implementations of Cedar type unspecified entities as <code>AnyEntity</code>, <code>==</code> and <code>in</code> expressions involving unspecified entities are typed as <code>False</code> (rather than <code>Bool</code>). This provides the same behavior as using a special <code>Unspecified</code> type, as originally proposed in this RFC.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="disallow-duplicate-keys-in-cedar-records"><a class="header" href="#disallow-duplicate-keys-in-cedar-records">Disallow duplicate keys in Cedar records</a></h1>
<h2 id="related-issues-and-prs-4"><a class="header" href="#related-issues-and-prs-4">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: related to <a href="https://github.com/cedar-policy/cedar/pull/169">cedar#169</a></li>
<li>Implementation PR(s): <a href="https://github.com/cedar-policy/cedar/pull/375">cedar#375</a></li>
</ul>
<h2 id="timeline-4"><a class="header" href="#timeline-4">Timeline</a></h2>
<ul>
<li>Started: 2023-07-14</li>
<li>Accepted: 2023-08-04</li>
<li>Landed: 2023-10-24 on <code>main</code></li>
<li>Released: 2023-12-15 in <code>cedar-policy</code> v3.0.0</li>
</ul>
<h2 id="summary-4"><a class="header" href="#summary-4">Summary</a></h2>
<p>Today, Cedar allows duplicate keys in record literals (and other record values, including <code>context</code>), with last-value-wins semantics.
This RFC proposes to disallow duplicate keys in record values, making that an error.</p>
<h2 id="basic-example-3"><a class="header" href="#basic-example-3">Basic example</a></h2>
<p>Today,</p>
<pre><code>permit(principal, action, resource)
when {
    resource.data == { foo: 2, foo: 3 }
};
</code></pre>
<p>is a valid Cedar policy. The <code>foo: 2</code> is dropped and <code>foo</code> will have the value <code>3</code> in the record literal.
In other words, in Cedar,</p>
<pre><code>{ foo: 2, foo: 3 } == { foo: 3 }
</code></pre>
<p>evaluates to <code>true</code>.</p>
<p>More precisely, Cedar's semantics does not just drop values prior to the last, but fully evaluates them before throwing them away. This has consequences in the presence of errors. For instance,</p>
<pre><code>{ foo: 1 + "hello", foo: 3 }
</code></pre>
<p>does not evaluate to <code>{ foo: 3 }</code> as you might expect based on the previous example, but rather, it results in an evaluation error.</p>
<p>This RFC proposes that all of the above expressions and policies would result in an evaluation error due to duplicate keys in a record.</p>
<h2 id="motivation-4"><a class="header" href="#motivation-4">Motivation</a></h2>
<p>There are two main motivations for this change.</p>
<p>First, in the status quo, Cedar policy ASTs actually cannot losslessly roundtrip to EST and back.
This is because the AST representation correctly allows duplicate keys in record literals, but the EST representation drops them (due to an oversight during EST design). In this way, the EST is unfaithful to Cedar semantics, and not all valid Cedar policies are expressible in the EST, which violates the EST's design goal of being lossless modulo whitespace/comments/etc.</p>
<p>More precisely, if a JSON EST contains duplicate record keys in a record literal, our JSON parser will take last-value-wins, and the internal EST representation will contain only the last value.
This results in the correct behavior on examples like <code>{ foo: 2, foo: 3 }</code>, but the incorrect behavior on examples containing errors, like <code>{ foo: 1 + "hello", foo: 3 }</code>.
It also means that roundtripping the AST representation to the EST representation and back necessarily loses information -- specifically, the values associated with all but the last instance of each key.</p>
<p>The second motivation is that the status quo makes things difficult for our Cedar formal specification and accompanying proofs.
The proofs are required to reason about "well-formed" records as a pre- and post-condition, which could be avoided if records were structurally prohibited from having duplicate keys (e.g., by using a map type instead of an association list).
The status quo also requires reasoning about the order keys appear in a record literal, meaning that the keys can't be naively sorted without preserving information about their original order.
If duplicate keys were prohibited, the order of keys wouldn't matter (but see "Unresolved questions" below).</p>
<p>Two secondary, more minor motivations for this proposal are:</p>
<ul>
<li>It would bring the Cedar language in line with our desired behavior on duplicate keys in other Cedar API surfaces. See <a href="https://github.com/cedar-policy/cedar/issues/159">cedar#159</a>.</li>
<li>Cedar records resemble other languages' struct types more than they resemble map types. The current behavior would be unexpected for struct types, and the proposed behavior would be intuitive.</li>
</ul>
<h2 id="detailed-design-4"><a class="header" href="#detailed-design-4">Detailed design</a></h2>
<p>We'd do something very like <a href="https://github.com/cedar-policy/cedar/pull/169">cedar#169</a>, except that instead of implicitly dropping all but the last value for each key (in <code>.collect()</code>), we'd be careful to emit an error when constructing an <code>Expr</code> if the record has duplicate keys.</p>
<p>In the case of record literals, the error could be caught in the CST-&gt;AST step, resulting in the user seeing a parse error rather than an evaluation error.
In the case of <code>context</code>, the error would need to be caught when constructing the <code>Context</code> object.
In the case of records in entity attributes, the error could be caught when constructing an <code>Entity</code> object.
There are no other cases, because currently, Cedar has no other way to construct a record value:
there are only record literals, and records preexisting in <code>context</code> or entity attribute values.</p>
<p>All of these cases would be caught prior to <code>is_authorized()</code> in Core, so we would not need a new category of evaluation error. No new evaluation errors would happen due to this proposal.</p>
<p>Another consequence of the above choices is that duplicate-key errors "take precedence" over (other) evaluation errors. The expression <code>{ one: 1 - "three", one: 1 }</code> will throw a duplicate key error and not a type error.</p>
<p>I don't believe this change would have a significant effect on validation or width/depth subtyping of records, but please correct me if I'm wrong.</p>
<h2 id="drawbacks-4"><a class="header" href="#drawbacks-4">Drawbacks</a></h2>
<p>This is a breaking change, not just to the Cedar API surface, but to the Cedar language (policy syntax) itself.
That's a significant drawback not to be taken lightly.
In this case, it's mitigated somewhat by the fact that we're turning previously-valid policies into errors, not changing them into a silently different behavior.
It's also mitigated by the fact that most Cedar users are probably (citation needed) not writing policies in the class that will have a behavior change -- i.e., policies with duplicate keys in record literals.
And finally, it's mitigated by the fact that Cedar's current behavior on duplicate keys was not documented in the public docs (e.g., in <a href="https://docs.cedarpolicy.com/syntax-datatypes.html#record">this section</a>), so if any policies are relying on this behavior, it's probably by accident.</p>
<h2 id="alternatives-4"><a class="header" href="#alternatives-4">Alternatives</a></h2>
<p>The main alternative is doing nothing, which of course has the reverse pros/cons of the proposal as explained in "Motivation" and "Drawbacks".</p>
<p>Another alternative, which would address the first motivation and not the second, would be to change the EST format so that it supports record literals with duplicate keys.
I believe this would require a breaking change to the EST format, and record literals would not be expressible as JSON maps, which is unfortunate because I believe that's the most natural/ergonomic.
(Devil's advocate: we could maybe find a way to support JSON maps in the common case with some escape syntax for expressing record literals that have duplicate keys. If we want to take this alternative seriously, I can investigate this.)</p>
<h2 id="unresolved-questions-1"><a class="header" href="#unresolved-questions-1">Unresolved questions</a></h2>
<h3 id="order-independence-for-record-keys"><a class="header" href="#order-independence-for-record-keys">Order-independence for record keys</a></h3>
<p>[Resolved: we won't make any further changes as part of this RFC, but may address some of this in a different RFC]</p>
<p>At first glance, one would hope that this change would be sufficient to ensure that the order of keys in a record literal (or more generally, any record value) does not matter.
However, that's not quite true -- if keys are mapped to expressions with errors, the order does matter, because only the first error encountered will be returned.
While we're making this change, should we also make a change so that we have true order-independence for Cedar record keys?
I could think of at least three ways to do that:</p>
<ol>
<li>Always evaluate all values in a record, and return potentially multiple evaluation errors rather than just the first</li>
<li>Provide no guarantee about which error the user will receive when multiple record keys have errors (nondeterministic error behavior) -- I think the formal spec currently guarantees the first error?</li>
<li>Guarantee that record values will be evaluated in lexicographic order of their keys, regardless of the order the keys appear in the policy text</li>
</ol>
<p>This issue is particularly hairy for records contained in attribute values in the entity store -- I believe these records go through a hashmap representation in our current datapath, so we lose ordering information and also duplicate keys (silently). Since the values in these records are restricted expressions, there are very few ways they can produce evaluation errors, but they still can, in the case of calls to extension functions. This is probably a potential source of difference between the errors produced in the Rust implementation and in the formal spec; I wonder why DRT hasn't caught this, particularly in the case where we drop a duplicate key that was mapped to an erroring expression. Maybe the Dafny JSON parser silently takes last-value-wins? or maybe we don't test extension values in attribute values?</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="add-basic-all-and-any-operators"><a class="header" href="#add-basic-all-and-any-operators">Add basic <code>all?</code> and <code>any?</code> operators</a></h1>
<h2 id="related-issues-and-prs-5"><a class="header" href="#related-issues-and-prs-5">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues:</li>
<li>Implementation PR(s):</li>
</ul>
<h2 id="timeline-5"><a class="header" href="#timeline-5">Timeline</a></h2>
<ul>
<li>Started: 2023-07-14</li>
<li>Accepted: 2023-11-08 (but later rejected, see below)</li>
<li>Rejected: 2024-05-21</li>
</ul>
<h2 id="summary-5"><a class="header" href="#summary-5">Summary</a></h2>
<p>This RFC proposes extending the language with <code>all?</code> and <code>any?</code> operators that allow checking if all elements or any element in a set satisfies a given predicate. The <code>all?</code> operator returns <code>true</code> if the provided predicate is true for all elements in the set. The <code>any?</code> operator returns true if the predicate is true for any element in the set.</p>
<p><strong>Update (2024-05-21)</strong>: This RFC was originally accepted and then revised to address analyzability issues. After further investigation, we found that even the revised version is not analyzable as described below, and further restrictions would be needed to make it analyzable. For example, one option is to restrict the predicates to compare set members to constants only. It is unclear if the proposed operators remain sufficiently useful with these added restrictions.  So we are rejecting the RFC at this time.</p>
<h2 id="basic-example-4"><a class="header" href="#basic-example-4">Basic example</a></h2>
<p>Consider writing a policy that allows access when all port numbers in the <code>context</code> are greater than or equal to 8000.  This can't be expressed in Cedar today.</p>
<p>With the <code>all?</code> operator, we can write this policy as follows:</p>
<pre><code>permit(principal, action, resource)
when {
  context.portNumbers.all? &gt;= 8000
};
</code></pre>
<p>The same policy can be written using the <code>any?</code> operator instead:</p>
<pre><code>permit(principal, action, resource)
unless {
  context.portNumbers.any? &lt; 8000
};
</code></pre>
<p>The two operators behave similarly (though <a href="0021-any-and-all-operators.html#extending-the-semantics">not equivalently</a>) to <code>&amp;&amp;</code> and <code>||</code>. Given negation, each can be written in terms of the other. We include both for ergonomics.</p>
<h2 id="motivation-5"><a class="header" href="#motivation-5">Motivation</a></h2>
<p>The <code>all?</code> and <code>any?</code> operators support a common use case: iterating over a set and checking if a predicate holds for any or all members of the set.</p>
<p>Cedar currently lacks a way to express this use case. The only alternative is to expand the <code>all?</code> or <code>any?</code> checks into conjunctions or disjunctions. For example:</p>
<pre><code>// Using all
["a", "ab", "abc"].all? like "a*"

// Using &amp;&amp;
("a" like "a*") &amp;&amp;
("ab" like "a*") &amp;&amp;
("abc" like "a*")
</code></pre>
<p>This manual expansion works for literal sets but cannot be applied to non-literal sets like <code>context.portNumbers</code>.</p>
<p>The new operators provide a built-in way to concisely express these universal and existential quantifications over a set.</p>
<h2 id="detailed-design-5"><a class="header" href="#detailed-design-5">Detailed design</a></h2>
<p>The Cedar syntax, semantics, and type system are all extended to support the new operators. These extensions are backward compatible, and existing policies won't be affected. In particular, <code>.any?</code>/<code>.all?</code> aren't <a href="https://docs.cedarpolicy.com/policies/syntax-grammar.html#grammar-ident">Cedar identifiers</a> so existing policies couldn't have used them as attribute or entity type names. The design of the operators is inspired by the <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_condition-single-vs-multi-valued-context-keys.html#reference_policies_condition-multi-valued-context-keys"><code>ForAllValues</code> and <code>ForAnyValue</code></a> operators in IAM and the <a href="https://docs.oasis-open.org/xacml/3.0/xacml-3.0-core-spec-os-en.html#_Toc325047251"><code>any-of</code> and <code>all-of</code></a> operators in XACML.</p>
<h3 id="extending-the-syntax"><a class="header" href="#extending-the-syntax">Extending the syntax</a></h3>
<p>This RFC proposes extending the Cedar grammar as follows:</p>
<pre><code>Access    :=
  '.' IDENT ['(' [ExprList] ')']
  | '.' QUANTIFIER Predicate
  | '[' STR ']'
QUANTIFIER := 'all?' | 'any?'
Predicate  :=
  BINOP Expr |
  'like' PAT |
  'is' Path |
  IDENT '(' [ExprList] ')'
BINOP := '&lt;' | '&lt;=' | '&gt;' | '&gt;=' | '==' | '!='
</code></pre>
<p>The extended grammar supports applying extension functions, comparisons, as well as the <code>like</code> and <code>is</code> operators to sets of values.</p>
<p>For example:</p>
<pre><code>context.ips.any? isLoopBack()
context.ips.all? isInRange(ip("192.168.0.1/24"))
resource.tags.any? like "private*"
resource.scores.all? greaterThan(principal.preference)
</code></pre>
<p>The grammar doesn't support the <code>in</code> operator supported because it is expensive to analyze. It also doesn't support operating on sets of sets (e.g., using <code>.containsAll</code>) or sets of records (e.g., using <code>has</code>), or combining multiple operators in a single <code>any?</code>/<code>all?</code> expression. Boolean combinations need to be expressed separately, outside of <code>any?</code>/<code>all?</code>.</p>
<p>For example, this expression checks if all port numbers are between 8000 and 8999:</p>
<pre><code>context.portNumbers.all? &gt;= 8000 &amp;&amp;
context.portNumbers.all? &lt;= 8999
</code></pre>
<p>The <code>any?</code>/<code>all?</code> extension adds some redundancy to the language, making it possible to express the same constraint in multiple ways.  For example:</p>
<pre><code>// These expressions check if the set context.tags
// contains the string "private":
context.tags.contains("private")
["private"].containsAny(context.tags)
context.tags.containsAny(["private"])
context.tags.containsAll(["private"])
context.tags.any? == "private"
context.tags.any? like "private"

// These expressions check if the context.tags is
// a subset of the singleton set ["private"]:
["private"].containsAll(context.tags)
context.tags.all? == "private"
</code></pre>
<p>Some of these expressions are more efficient to evaluate than others.  For example, <code>context.tags.contains("private")</code> takes constant time (a set lookup), while a straighforward implementation <code>context.tags.any? == "private"</code> takes linear time (scanning the whole set and comparing each element to <code>"private"</code>). We can consider implementing rewrite rules in Cedar's CST to AST conversion that recognize some of the less efficient expressions and rewrite them into the most efficient variant.</p>
<h3 id="extending-the-semantics"><a class="header" href="#extending-the-semantics">Extending the semantics</a></h3>
<p>The semantics of <code>all?</code> and <code>any?</code> are straightforward when there are no errors.  For example:</p>
<ul>
<li><code>E.all? BINOP E'</code> evaluates to true when <code>e BINOP E'</code> is true for every element <code>e</code> in <code>E</code>.</li>
<li><code>E.any? BINOP E'</code> evaluates to true when <code>e BINOP E'</code> is true for some element <code>e</code> in <code>E</code>.</li>
</ul>
<p>But what happens if evaluating <code>e BINOP E'</code> errors on some element <code>e</code>? In this case, the evaluation of <code>all?</code> or <code>any?</code> terminates abruptly with a distinguished <code>QuantifierError</code>.</p>
<p>The <code>QuantifierError</code> error may include additional diagnostic information, as long as this information is bounded in size and computed deterministically. For example, the <code>QuantifierError</code> error could specify the source location, or a fixed-length description of the smallest erroring value in the underlying set, according to some fixed total order on Cedar values. This error handling approach ensures that evaluating  <code>all?</code> and <code>any?</code> <em>deterministic</em>: the result is the same regardless of iteration order. It also ensures that evaluation is <em>space efficient</em>: the size of the evaluator output remains constant in policy and input size.</p>
<p>For example, consider the expression <code>[1, true].all? like "foo*"</code>. Regardless of the order in which the predicate is applied, the expression returns the same <code>QuantifierError</code>.</p>
<p>Compare this to the <a href="0021-any-and-all-operators.html#non-deterministic-error-behavior">alternative semantics</a> that just propagates the error discovered, when it is discovered. Then evaluating this expression could lead to the error that "a Long was found where a String was expected" or it could lead to the error "A Boolean was found where a String was expected." Which one depends on evaluation order, but no clear order exists because set elements are specifically unordered.</p>
<p>The proposed semantics lets us think about <code>all?</code> and <code>any?</code> in terms of their expansion to conjunctions and disjunctions. The quantified expression errors if <em>any</em> expansion would error.</p>
<p>For example:</p>
<pre><code>// Throws QuantifierError
[1, true].all? like "foo*"

// Throws a TypeError: "like" can't be applied to an integer
1 like "foo" &amp;&amp; true like "foo*"

// Throws a TypeError: "like" can't be applied to an boolean
true like "foo" &amp;&amp; 1 like "foo*"
</code></pre>
<p>The only difference is the error being thrown: <code>QuantifierError</code> for the quantified expression versus an element-specific error for the explicit expansion.</p>
<h3 id="extending-the-type-system"><a class="header" href="#extending-the-type-system">Extending the type system</a></h3>
<p>The type system needs to be extended with rules for type checking quantified expressions <code>E.all? P</code> and <code>E.any? P</code>. This should be fairly standard: we know the type of the implicit first argument to an operator or function from the type of the set <code>E</code>, and we can use this to typecheck the predicate <code>P</code>.</p>
<p>For example, the following should typecheck only when <code>resource.things</code> is a set of strings:</p>
<pre><code>resource.things.all? like "thing*"
</code></pre>
<h2 id="drawbacks-5"><a class="header" href="#drawbacks-5">Drawbacks</a></h2>
<ul>
<li>This proposal requires significant development effort. We'll need to modify the parser, the CST to AST conversion, CST/AST/EST, evaluator, validator, models, proofs, and DRT.</li>
<li>Supporting these operators will likely have a negative impact on analysis performance.</li>
</ul>
<h2 id="alternatives-5"><a class="header" href="#alternatives-5">Alternatives</a></h2>
<p>We considered three alternative designs for these operators. The first alternative is the most general design we can achieve while keeping the language analyzable and performant. The other two alternatives explore different error semantics.</p>
<p>The generalized <code>any?</code>/<code>all?</code> operators are more expressive than the basic ones.  But they are also significantly more complex to analyze, implement, and prove correct. We decided against this alternative due to its complexity. If the added expressiveness is needed for usability, the proposed basic design can be naturally extended into the general proposal.</p>
<h3 id="generalized-anyall-operators"><a class="header" href="#generalized-anyall-operators">Generalized <code>any?</code>/<code>all?</code> operators</a></h3>
<p>A generalized version of <code>any?</code>/<code>all?</code> allows evaluating arbitrary Cedar predicates on sets.</p>
<p>For example:</p>
<pre><code>context.portNumbers.all? (it &gt;= 8000 &amp;&amp; it &lt;= 8999)
principal.info.all? (it has email &amp;&amp; it.email like "*@acme.com")
</code></pre>
<h4 id="syntax"><a class="header" href="#syntax">Syntax</a></h4>
<p>The generalized operators extend the Cedar grammar as follows:</p>
<pre><code>Access    :=
  '.' IDENT ['(' [ExprList] ')']
  | '.' QUANTIFIER Predicate
  | '[' STR ']'
QUANTIFIER := 'all?' | 'any?'
Predicate  := ...
</code></pre>
<p>The <code>Predicate</code> expression specifies a subset of the <code>Expr</code> grammar. In particular, it differs from <code>Expr</code> in two ways:</p>
<ol>
<li>
<p>Predicates can use the keyword <code>it</code>. A <code>Predicate</code> defines the body of function with a single parameter, and we use <code>it</code> as the parameter name. This is similar to <a href="https://kotlinlang.org/docs/lambdas.html#it-implicit-name-of-a-single-parameter">Kotlin's <code>it</code> keyword</a>.</p>
</li>
<li>
<p>Predicates cannot contain nested <code>any?</code> or <code>all?</code> expressions. We disallow nested quantifiers for both performance and analyzability reasons. Nested quantifiers allow writing expressions that run in $O(2^n)$ time, where $n$ is the number of nested quantifiers. For example:</p>
</li>
</ol>
<pre><code>[0,1] [all (
  [0,1] [all (
    ...
      [0,1].all? (true)...]]
</code></pre>
<p>Because nested quantifiers are prohibited, there is no need to support predicates with arbitrary parameter names. The <code>it</code> keyword sufficiently extends the grammar.</p>
<h4 id="semantics"><a class="header" href="#semantics">Semantics</a></h4>
<p>The semantics of <code>all?</code> and <code>any?</code> are straightforward when there are no errors:</p>
<ul>
<li><code>E.all? P</code> evaluates to true when <code>P[e/it]</code> is true for every element <code>e</code> in <code>E</code>.</li>
<li><code>E.any? P</code> evaluates to true when <code>P[e/it]</code> is true for some element <code>e</code> in <code>E</code>.</li>
</ul>
<p>The error semantics is the same as for the <a href="0021-any-and-all-operators.html#extending-the-semantics">basic <code>any?</code>/<code>all?</code> operators</a>.  In particular, if evaluating <code>P</code> errors on some element <code>e</code>, the evaluation of <code>all?</code> or <code>any?</code> terminates abruptly with a distinguished <code>QuantifierError</code>.</p>
<p>Alternative error semantics are described <a href="0021-any-and-all-operators.html#non-deterministic-error-behavior">below</a>.</p>
<h4 id="type-rules"><a class="header" href="#type-rules">Type rules</a></h4>
<p>The type system needs to be extended with rules for type checking generalized quantified expressions <code>E.all? P</code> and <code>E.any? P</code>. This is similar to the <a href="0021-any-and-all-operators.html#extending-the-type-system">typechecking of basic <code>any?</code>/<code>all?</code> operators</a>: we know the type of <code>it</code> from the type of the set <code>E</code>, and we can use this to typecheck the predicate <code>P</code>. But in the generalized case, we also need to propagate effects through predicates.</p>
<p>For example, the following should typecheck when <code>context.limit</code> is an optional integer attribute, and <code>resource.things</code> is a set of entities with an optional integer attribute <code>.size</code>:</p>
<pre><code>context has limit &amp;&amp;
resource.things.all? (it has size &amp;&amp; it.size &lt; context.limit)
</code></pre>
<p>While the effect prior to a <code>any?</code> or <code>all?</code> is clear, what about the effect after one? The recommended solution is the simplest one: ignore the effects of <code>any?</code> and <code>all?</code> . But we could be more precise if needed.</p>
<p>For example, consider the following expression:</p>
<pre><code>resource.things.all? (context has limit &amp;&amp; it.has size &amp;&amp; it.size &lt; context.limit) &amp;&amp;
context.limit &gt; 5
</code></pre>
<p>Here, the redundant use of <code>context.limit</code> in the <code>all?</code> could carry an effect outside to the <code>&gt;</code> expression.</p>
<p>This extra precision isn't necessary in the sense that we can always rewrite expressions to avoid relying on it. For example, we can rewrite the above expression as follows:</p>
<pre><code>context has limit &amp;&amp;
resource.things.all? (it has size &amp;&amp; it.size &lt; context.limit) &amp;&amp;
context.limit &gt; 5
</code></pre>
<h4 id="drawbacks-6"><a class="header" href="#drawbacks-6">Drawbacks</a></h4>
<ul>
<li>This alternative requires major development effort compared to the simplified operators. We'll need to implement more extensive modifications to the parser, the CST to AST conversion, CST/AST/EST, evaluator, validator, models, proofs, and DRT.</li>
<li>The generalized <code>any?</code> and <code>all?</code> operators may encourage writing complex expressions with poor performance. For example, <code>context.portNumbers.any? (if it == 8010 then true else false)</code> is $O(n)$ versus $O(1)$ for <code>context.portNumbers.contains(8010)</code>.  Note that the basic proposal doesn't suffer as much from this drawback because it doesn't support using conditionals with <code>any?</code>/<code>all?</code>.</li>
<li>Supporting these operators will likely have a negative impact on analysis performance, especially for complex predicates and predicates that use the <code>in</code> operator (which needs special handling).</li>
</ul>
<h3 id="non-deterministic-error-behavior"><a class="header" href="#non-deterministic-error-behavior">Non-deterministic error behavior</a></h3>
<p>Given <code>E.all? P</code> and <code>E.any? P</code>, we apply <code>P</code> to elements of <code>E</code> in arbitrary order, terminating on the first error and returning that error as the result. This alternative provides more precise error messages than the proposed approach.</p>
<p>But the downside is that the same policy could produce different errors depending on iteration order. For example, <code>[1, true].all? like "foo"</code> may result in a type error that says <code>like</code> cannot be applied to an integer or a boolean. In other words, Cedar semantics would become non-determinstic.</p>
<p>We decided against this semantics for three reasons:</p>
<ul>
<li>Violates Cedar's design as a deterministic language. Error non-determinism would be visible to <code>is_authorized</code> callers.</li>
<li>Applications may also become non-deterministic if they examine errors and act on them.</li>
<li>Non-determinism complicates models and proofs.</li>
</ul>
<p>Keeping deterministic semantics is important for Cedar as an authorization language.</p>
<h3 id="treating-errors-as-false"><a class="header" href="#treating-errors-as-false">Treating errors as <code>false</code></a></h3>
<p>Given <code>E.all? P</code> and <code>E.any? P</code>, we apply <code>P</code> to elements of <code>E</code> in any order, treating errors as false and continuing evaluation on the remaining elements. Note that this is how <code>is_authorized</code> handles policy evaluation errors: they are turned into false and ignored.</p>
<p>With this approach, <code>any?</code> and <code>all?</code> become total functions: they never error. For example, <code>["one", 1].any? &lt; 2</code> evaluates to true because there is one element for which the predicate holds. And <code>["one", 1].all? &lt; 2</code> is simply false, because <code>"one" &lt; 2</code> is treated as false.</p>
<p>The key advantage of this semantics is that it is more amenable to SMT-based analysis than either of the above alternatives.  Both error-propagating alternatives need more complex and larger encodings.</p>
<p>We decided against this semantics because it breaks the interpretation of <code>all?</code> and <code>any?</code> as shorthands for conjunctions and disjunctions. If we expand <code>["one", true].all? &lt; 2</code> to a conjunction, the result always errors rather than evaluating to false. This discrepancy between the quantified and expanded forms might be confusing and undesirable.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="cedar-schema-syntax"><a class="header" href="#cedar-schema-syntax">Cedar Schema Syntax</a></h1>
<h2 id="related-issues-and-prs-6"><a class="header" href="#related-issues-and-prs-6">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues:</li>
<li>Implementation PR(s): <a href="https://github.com/cedar-policy/cedar/pull/347">cedar#347</a> (cancelled), <a href="https://github.com/cedar-policy/cedar/pull/557">cedar#557</a> (merged)</li>
</ul>
<h2 id="timeline-6"><a class="header" href="#timeline-6">Timeline</a></h2>
<ul>
<li>Started: 2023-07-24</li>
<li>Accepted: 2023-10-02</li>
<li>Landed: 2024-02-19 on <code>main</code> (<a href="https://github.com/cedar-policy/cedar/pull/557">#557</a>)</li>
<li>Released: 2024-03-08 in <code>cedar-policy</code> v3.1.0</li>
</ul>
<h2 id="summary-6"><a class="header" href="#summary-6">Summary</a></h2>
<p>This document proposes a custom syntax for Cedar schemas. The syntax was developed with the following goals in mind:</p>
<ul>
<li>Use the same concepts in both the JSON-based and custom syntax, allowing them to be naturally inter-converted</li>
<li>Reuse Cedar policy syntax as much as possible, to help with intuition</li>
<li>When no Cedar policy syntax analogue exists, leverage ideas from other programming languages that favor readability</li>
<li>Use as few syntactic concepts as possible; similar ideas in the schema should look similar syntactically</li>
<li>Support converting back and forth between the JSON-based schema without losing information</li>
</ul>
<p>This is <em>not</em> a proposal to <em>replace</em> the JSON-based syntax; the aim is to provide an additional syntax that better satisfies the goals above. The JSON syntax is appropriate in many circumstances, such as when constructing schemas systematically. Adopting this proposal would put schemas on the same footing as Cedar policies, which have a custom and a JSON syntax.</p>
<h2 id="basic-example-5"><a class="header" href="#basic-example-5">Basic example</a></h2>
<p>Here is the proposed syntax for the <a href="https://github.com/cedar-policy/cedar-examples/blob/main/tinytodo/tinytodo.cedarschema.json">TinyTodo schema</a>, whose auto-formatted JSON version is 160 lines long.</p>
<pre><code>entity Application;
entity User in [Team,Application] { name: String };
entity Team in [Team,Application];
entity List in [Application] {
    owner: User,
    name: String,
    readers: Team,
    editors: Team,
    tasks: Set&lt;{name: String, id: Long, state: String}&gt;
};

action CreateList, GetLists
    appliesTo { principal: [User], resource: [Application] };

action GetList, UpdateList, DeleteList, CreateTask, UpdateTask, DeleteTask, EditShares
    appliesTo { principal: [User], resource:[List] };
</code></pre>
<h2 id="motivation-6"><a class="header" href="#motivation-6">Motivation</a></h2>
<p>Cedar schemas for non-toy applications are hard to read and write. The root cause of the difficulty is the use of JSON:</p>
<ul>
<li>JSON has low information density. For three applications we’ve modeled — <a href="https://github.com/cedar-policy/cedar-examples/blob/main/tinytodo/tinytodo.cedarschema.json">TinyTodo</a>, <a href="https://github.com/cedar-policy/cedar-examples/blob/main/cedar-example-use-cases/document_cloud/schema.json">Document Cloud</a>, and <a href="https://github.com/cedar-policy/cedar-examples/blob/main/cedar-example-use-cases/github_example/schema.json">GitHub</a> — schemas span 4-5 pages.</li>
<li>JSON does not support comments. This means that any design intent for a schema cannot be expressed inline.</li>
</ul>
<p>We believe that a custom syntax for Cedar schemas can help. It can be more information-dense, support comments, and leverage familiar syntactic constructs. We think customers will be happier with a custom syntax: we regularly hear favorable reviews of Cedar's custom policy syntax, as compared to a JSON-based syntax.</p>
<h2 id="detailed-design-6"><a class="header" href="#detailed-design-6">Detailed Design</a></h2>
<p>In what follows we first present the syntax by example. A full grammar is given at the end.</p>
<h3 id="comments"><a class="header" href="#comments">Comments</a></h3>
<p>Cedar schemas can use line-ending comments in the same style as Cedar, e.g., <code>// this is a comment</code>.</p>
<h3 id="namespace-format"><a class="header" href="#namespace-format">Namespace format</a></h3>
<pre><code>namespace My::Namespace {
  ...
}
</code></pre>
<p>A Schema can have zero or more namespace declarations. The contents of each (<code>...</code> above) comprise entity, action, and common-type declarations, all of which are unordered; i.e., they are all allowed to mutually refer to one another (but see discussion on common types below). The recommended style is to put entity declarations first, followed by action declarations, with common type declarations interspersed as needed. Entity, action, and common types referenced in the same namespace in which they are defined need not be prefixed by that namespace.</p>
<p>Entity, action, and common-type declarations can appear on their own, outside of any namespace; in that case they are implicitly within the empty namespace.</p>
<h3 id="entity-declarations"><a class="header" href="#entity-declarations">Entity declarations</a></h3>
<p>Here is an example illustrating the entity declaration syntax.</p>
<pre><code>entity User in [Group] {
    personalGroup: Group,
    delegate?: User,
    blocked: Set&lt;User&gt;,
};
entity Document {
    owner: User,
    isPrivate: Boolean,
    publicAccess: String,
    viewACL: DocumentShare,
    modifyACL: DocumentShare,
    manageACL: DocumentShare
};
entity DocumentShare;
entity Public in [DocumentShare];
</code></pre>
<p>The first declaration indicates that <code>User</code> is an entity type, can be a member of the <code>Group</code> type, and has two attributes: <code>personalGroup</code> with entity type <code>Group</code>, and <code>blocked</code> with type <code>Set&lt;User&gt;</code>.</p>
<p>To allow syntactic parity with common <code>type</code> declarations, discussed below, we can optionally add <code>=</code> just before the <code>{ ... }</code> defining an entity's attributes, e.g., <code>entity Dog = { name: String }</code> rather than <code>entity Dog { name: String }</code>. Allowing <code>=</code> also supports using a common type name as the entity's shape, and also allows a future extension in which an entity's shape is a type other than a record.</p>
<p>Entity declarations may or may not have the <code>in ...</code> component, and they may or may not have attributes. A singleton list can be expressed without brackets, e.g., <code>entity User in Group = ...</code> Optional attributes are specified in the style of Typescript, with a <code>?</code> after their name. The last element of an the attribute list can optionally include a comma.</p>
<p>Entity types that share a definition can be declared together. For example, the following declares two entity types <code>User</code> and <code>Team</code>, both of which can be members of <code>Team</code> and both of which have a <code>name</code> attribute.</p>
<pre><code>entity User, Team in [Team] { name: String };
</code></pre>
<p>Since the JSON-based format does not support groups, this creates a challenge for back-and-forth translation. Our suggested solution is to add an optional <code>groupid</code> attribute to an entity declaration in the JSON. Those entities that are in the same group will be put together when translating to the custom syntax (after confirming that they indeed have the same type), and when translating to JSON such a group ID will be automatically generated.</p>
<h3 id="action-declarations"><a class="header" href="#action-declarations">Action declarations</a></h3>
<p>Here is an example illustrating the action declaration syntax.</p>
<pre><code>action ReadActions;
action WriteActions;
action CreateDocument
    appliesTo { principal: [User], resource: [Drive] };
action DeleteDocument in [WriteActions]
    appliesTo { principal: [User], resource: [Document] };
action ViewDocument in [ReadActions] appliesTo {
    principal: [User,Public],
    resource: Document,
    context: {
        network: ipaddr,
        browser: String
    }
};
</code></pre>
<p>A declared action indicates either none, one, or both of the following:</p>
<ol>
<li>What action groups it is a member of, using <code>in</code></li>
<li>What principal, resource, and context types it may be coupled with in a request (if any), using <code>appliesTo</code></li>
</ol>
<p>Specifying <code>[]</code> for the <code>in</code> component is equivalent to omitting <code>in</code> entirely. An action that has no <code>appliesTo</code> component essentially names an action group: having no possible principal and/or resource types means there’s no way to submit a legal request with the action.</p>
<p>The <code>appliesTo</code> specificiation uses record syntax, where the "attributes" of the record may be any combination of <code>principal</code>, <code>resource</code>, and <code>context</code>, with the following constraints.</p>
<ul>
<li>If <code>principal</code> and/or <code>resource</code> is given, the accompanying type must be either
<ul>
<li>a single entity type, or</li>
<li>a <em>non-empty</em> list of entity types</li>
</ul>
</li>
<li>If a <code>principal</code> or <code>resource</code> element is not given, that means that this request component is <em>unspecified</em>, i.e., corresponding to the <code>None</code> option in the <code>principal</code> or <code>resource</code> component of a <a href="https://docs.rs/cedar-policy/2.4.0/cedar_policy/struct.Request.html"><code>Request</code></a>.</li>
<li>If <code>context</code> is given, the accompanying type must be a record type. If it is not given, the type <code>{}</code> is assumed.</li>
<li>At least one of <code>principal</code>, <code>resource</code>, or <code>context</code> must be included if <code>appliesTo</code> is present; i.e., writing <code>appliesTo { }</code> is not allowed.</li>
</ul>
<p>Here are two additional examples that follow these rules:</p>
<pre><code>action ViewDocument in ReadActions appliesTo {
    resource: Document,
    context: {}
};
action Ping appliesTo {
    context: {
        source: ipaddr,
        dest: ipaddr
    }
};
</code></pre>
<p>Since actions are entities, action names are entity IDs, which can be arbitrary strings. Thus we admit the following more general syntax as well.</p>
<pre><code>action "Delete Document $$" in ["Write Actions"] appliesTo {
    principal: [User],
    resource: [Document]
};
</code></pre>
<p>We anticipate future support for attributes as part of action entities. If/when they are supported, we can specify action attributes after the <code>appliesTo</code> part as an inline record using Cedar syntax following an <code>attributes</code> keyword. For example, here’s an extension of <code>ViewDocument</code> with action attributes.</p>
<pre><code>action ViewDocument in [ReadActions]
  appliesTo {
    principal: [User,Public],
    resource: Document,
    context: {
        network: ipaddr,
        browser: String
    }
  }
  attributes {
    version: 1,
    group: "meta"
  };
</code></pre>
<p>As with <code>entity</code> declarations, since the JSON-based format does not support groups, we can add an optional <code>groupid</code> attribute to an action declaration in the JSON. Those actions that are in the same group will be put together when translating to the custom syntax (after confirming that they indeed have the same type), and when translating to JSON such a group ID will be automatically generated.</p>
<h3 id="common-types"><a class="header" href="#common-types">Common types</a></h3>
<p>You can define names for types (as in Typescript, OCaml, Haskell, and many other languages) and then use them in <code>action</code> and <code>entity</code> declarations. Here is an example:</p>
<pre><code>type authcontext = {
    ip: ipaddr,
    is_authenticated: Boolean,
    timestamp: Long
};
entity Ticket {
  who: String,
  operation: Long,
  request: authcontext
};
action view appliesTo { context: authcontext };
action upload appliesTo { context: authcontext };
</code></pre>
<p>Note the use of <code>=</code> for <code>type</code> declarations, but the lack of (required) <code>=</code> for <code>entity</code> declarations; the <code>=</code> is needed because the definining type may not be a record, e.g., <code>type time = Long</code>.</p>
<p>As with <code>entity</code> and <code>action</code> declarations, the name implicitly includes the surrounding namespace as a prefix.</p>
<p>While common types can be declared anywhere within a namespace and safely referenced by entity and action declarations, they cannot refer to one another, to avoid introducing definitional cycles. (To allow mutual reference, we could make declaration order matter: <code>entity</code>, <code>action</code>, and other <code>type</code> declarations cannot refer to a common type before it is defined.)</p>
<p><em>Much later note, May 2024: In the fullness of time we relaxed the above restriction and allowed common types to refer to one another, as long as there are no definitional cycles. See <a href="https://github.com/cedar-policy/cedar/pull/766">cedar#766</a>.</em></p>
<h3 id="disambiguating-types-in-custom-syntax"><a class="header" href="#disambiguating-types-in-custom-syntax">Disambiguating Types in Custom Syntax</a></h3>
<p>Cedar has four kinds of type name:</p>
<ol>
<li>Primitive types, e.g., <code>Long</code>, <code>String</code>, etc.</li>
<li>Extension types, currently just <code>ipaddr</code> and <code>decimal</code></li>
<li>Entity types</li>
<li>Common types</li>
</ol>
<p>The first two are built in, and could potentially change in the future. The last two are schema-declarable; they have an associated namespace prefix, but references within the defining namespace can drop the prefix.</p>
<p>In the current JSON syntax, common types may not overlap with primitive types; e.g., declaring a common type <code>Long</code> is disallowed. However, common types are permitted to overlap with extension types; e.g., declaring common type <code>ipaddr</code> is allowed. This works in the JSON because specifying an extension type requires an explicit <code>"type"</code> designator, as in the following:</p>
<pre><code>"addr": {
    "ip": { "type": "Extension", "name": "ipaddr" },
}
</code></pre>
<p>If we <em>also</em> had defined a common type <code>ipaddr</code> we would reference it by writing</p>
<pre><code>"addr": {
    "myip": { "type": "ipaddr" },
}
</code></pre>
<p>Common types may also overlap with entity types, for similar reasons: To reference an entity type you must write <code>{ "type": "Entity", "name": "Foo" }</code> while to reference a common type you'd just write <code>{ "type": "Foo" }</code>.</p>
<p>The custom syntax does not require such designators, for readability, so we need a way to <strong>disambiguate type name references</strong> when necessary.</p>
<p>When two different kinds of type definitions are in separate namespaces, we rely on the namespace resolution rules to disambiguate. For example, suppose we defined the following schema:</p>
<pre><code>type email_address = String; // (1)
namespace Foo {
    entity email_address { addr: String }; // (2)
    entity User { email: email_address }; // (3)
}
</code></pre>
<p>Here, in the definition of <code>User</code>, the unqualified type <code>email_address</code> at (3) resolves to the <em>entity</em> definition at (2), because it is in the closest enclosing scope.</p>
<p>When two different kinds of type definitions are in the <em>same</em> namespace, we propose the following five rules:</p>
<ol>
<li>Issue a warning (for both syntaxes) when a schema defines the same typename twice (within a namespace)</li>
<li>Disallow overlap of extension and primitive type names</li>
<li>Resolve name references in a priority order</li>
<li>Reserve <code>__cedar</code> as a namespace to disambiguate extension/primitive types from others</li>
<li>Handle entity/common typename overlaps in translation</li>
</ol>
<p>These rules aim to address several (additional) tenets</p>
<ul>
<li>Conflicting type names are an exception to be discouraged, rather than a norm, for readability and clarity</li>
<li>Schemas should not break when new extension types are added to Cedar</li>
<li>Backward-incompatible changes should be minimized</li>
</ul>
<h4 id="rule-1-issue-a-warning-for-both-syntaxes-when-a-schema-defines-the-same-typename-twice"><a class="header" href="#rule-1-issue-a-warning-for-both-syntaxes-when-a-schema-defines-the-same-typename-twice">Rule 1: Issue a warning (for both syntaxes) when a schema defines the same typename twice</a></h4>
<p>Defining an entity type with the same name as a primitive or extension type, or an entity and common type with the same name (within the same namespace), is unlikely to be a good idea. Though they can be technically disambiguated in the JSON syntax, the potential for confusion is nontrivial. None of the rules that follow need to be understood, and conversion to/from JSON and custom syntax is assured, if defined types are all kept distinct.</p>
<h4 id="rule-2-disallow-overlap-of-extension-and-primitive-type-names"><a class="header" href="#rule-2-disallow-overlap-of-extension-and-primitive-type-names">Rule 2: Disallow overlap of extension and primitive type names</a></h4>
<p>Right now, all primitive types have different names than extension types. We propose that it should always be that way.  Though the flexibility is there in today’s JSON schema to allow overlap, we see no good reason to allow it. Because we are currently the sole purveyor of extension types, this rule is easy to implement.</p>
<h4 id="rule-3-resolve-name-references-in-a-priority-order"><a class="header" href="#rule-3-resolve-name-references-in-a-priority-order">Rule 3: Resolve name references in a priority order</a></h4>
<p>When the schema references a type name (without a namespace prefix), it should resolve in the following order:</p>
<ol>
<li>common type</li>
<li>entity type</li>
<li>primitive</li>
<li>extension type</li>
</ol>
<p>For example, suppose we declared a common type <code>type ipaddr = Long;</code> If the schema later referred to <code>ipaddr</code>, then that reference would be to this common type definition, not the extension type, since the common type is higher in the order. This ordering ensures that <strong>future-added extension types will not break existing schemas</strong>. For example, if we added a future extension type <code>date</code>, then schemas that define an entity or common type of the same name would have the same semantics as before: they would refer to the schema-defined type, not the new extension type.</p>
<p>In tabular form, this priority order is depicted below. We write n/a for the case that the two kinds of type can never share the same name (due to the status quo and rule 2).</p>
<p>|	|common	|entity	|primitive	|extension	|
|---	|---	|---	|---	|---	|
|common	|	|	|	|	|
|entity	|common	|	|	|	|
|primitive	|n/a	|entity	|	|	|
|extension	|common	|entity	|n/a	|	|</p>
<p>The next two rules consider how to disambiguate conflicting types.</p>
<h4 id="rule-4-reserve-__cedar-as-a-namespace-to-disambiguate-extensionprimitive-types-from-others"><a class="header" href="#rule-4-reserve-__cedar-as-a-namespace-to-disambiguate-extensionprimitive-types-from-others">Rule 4: Reserve <code>__cedar</code> as a namespace to disambiguate extension/primitive types from others</a></h4>
<p>If a schema defines a common or entity type that overlaps with an extension type, there is no way to refer to extension type — the common or entity type always take precedence. This is particularly problematic if a new extension type overlaps with an existing definition, and an update to the schema might wish to use both.</p>
<p>To rectify this problem, we propose reserving the namespace <code>__cedar</code> and allowing it to be used as a prefix for both primitive and extension types. This way, an entity type <code>ipaddr</code> can be referred to directly, and the extension type <code>ipaddr</code> can be referred to as <code>__cedar::ipaddr</code>. Likewise, this allows one to (say) define an entity type <code>String</code> that can be be referenced distinctly from <code>__cedar::String</code> (though this practice should be discouraged!).</p>
<h4 id="rule-5-handle-entitycommon-typename-overlaps-in-translation"><a class="header" href="#rule-5-handle-entitycommon-typename-overlaps-in-translation">Rule 5: Handle entity/common typename overlaps in translation</a></h4>
<p>If a schema defines an entity type and a common type with the same name, the references to that name will resolve to the common type, and there will be no way to reference the entity type in the custom syntax. Per rule 1, users will be warned of this.</p>
<p>Custom syntax users can rectify the situation by changing either the common type or entity type to a different name (or placing them in different namespaces). JSON syntax users can refer to both types distinctly, but will be warned that translation to the custom syntax will not be possible without changing the name. Translation tools can easily make this name change automatically.</p>
<p>Note that translation from JSON to custom syntax is only problematic when a schema defines both a common and entity type of the same name. Translation tools can easily address this issue by renaming the common type (and offering to change the type name in the original JSON)</p>
<p>Evaluating these rules against our added tenets above, we can see:</p>
<ul>
<li>Conflicting type names are discouraged by issuing a warning when there is overlap</li>
<li>Due to the choice in priority order, schemas will not break when new extension types are added</li>
<li>Only rule 4 (introducing the <code>__cedar</code> reserved namespace) is backward incompatible, and it is very unlikely to affect existing schemas.</li>
</ul>
<h4 id="rejected-alternative-designs-for-disambiguation"><a class="header" href="#rejected-alternative-designs-for-disambiguation">Rejected alternative designs for disambiguation</a></h4>
<p>One alternative design we considered was to use prefixes on typename references to indicate the kind of type, e.g., extension types could be optionally prefixed with <code>+</code>, e.g., <code>+ipaddr</code> and <code>+decimal</code>, and entity types could be optionally prefixed with <code>&amp;</code>, e.g., <code>&amp;User</code> and <code>&amp;My::Namespace::List</code>. However, we rejected this design because it would be unfamiliar to users (especially the use of <code>+</code>), and doesn't discourage the use of overlapping type names.</p>
<p>Another alternative we considered was to forbid type-name overlaps entirely. However, rejected this design because it is strongly backward-incompatible, and also because it could lead to surprise if a future definition of an extension type happened to match a common or entity type in use in an existing schema.</p>
<h3 id="mockup-document-cloud"><a class="header" href="#mockup-document-cloud">Mockup: Document Cloud</a></h3>
<p>Here is a version of the <a href="https://github.com/cedar-policy/cedar-examples/blob/main/cedar-example-use-cases/document_cloud/schema.json">Document Cloud</a> schema.</p>
<pre><code>namespace DocCloud {
    entity User in [Group] {
        personalGroup: Group,
        blocked: Set&lt;User&gt;
    };
    entity Group in [DocumentShare] { 
        owner: User 
    };
    entity Document {
        owner: User,
        isPrivate: Boolean,
        publicAccess: String,
        viewACL: DocumentShare,
        modifyACL: DocumentShare,
        manageACL: DocumentShare
    };
    entity DocumentShare;
    entity Public in [DocumentShare];
    entity Drive;

    action CreateDocument, CreateGroup 
        appliesTo { principal: [User], resource: [Drive] };
    action ViewDocument 
        appliesTo { principal: [User,Public], resource: [Document] };
    action DeleteDocument, ModifyDocument, EditIsPrivate, AddToShareACL, EditPublicAccess 
        appliesTo { principal: [User], resource: [Document] };
    action ModifyGroup, DeleteGroup 
        appliesTo { principal: [User], resource: [Group] };
}
</code></pre>
<h3 id="mockup-github-model"><a class="header" href="#mockup-github-model">Mockup: GitHub Model</a></h3>
<p>Here is a version of the <a href="https://github.com/cedar-policy/cedar-examples/blob/main/cedar-example-use-cases/github_example/schema.json">GitHub</a> schema.</p>
<pre><code>namespace GitHub {
    entity User in [UserGroup,Team];
    entity UserGroup in [UserGroup];
    entity Repository {
        readers: UserGroup,
        triagers: UserGroup,
        writers: UserGroup,
        maintainers: UserGroup,
        admins: UserGroup   
    };
    entity Issue {
        repo: Repository,
        reporter: User
    };
    entity Org {
        members: UserGroup,
        owners: UserGroup,
        memberOfTypes: UserGroup
    };
    action pull, fork, push, add_reader, add_triager, add_writer, add_maintainer, add_admin 
        appliesTo { principal: [User], resource: [Repository] };
    action delete_issue, edit_issue, assign_issue 
        appliesTo { principal: [User], resource: [Issue] };
}
</code></pre>
<h3 id="grammar"><a class="header" href="#grammar">Grammar</a></h3>
<p>Here is a grammar for the proposed schema syntax.</p>
<p>The grammar applies the following the conventions. Capitalized words stand for grammar productions, and lexical tokens are given in all-caps. When productions or tokens match those in the Cedar policy grammar, we use the same names (e.g., <code>IDENT</code> and <code>Path</code>).</p>
<p>For grammar productions it uses <code>|</code> for alternatives, <code>[]</code> for optional productions, <code>()</code> for grouping, and <code>{}</code> for repetition of a form zero or more times.</p>
<p>Tokens are defined using regular expressions, where <code>[]</code> stands for character ranges; <code>|</code> stands for alternation; <code>*</code> , <code>+</code> , and <code>?</code> stand for zero or more, one or more, and zero or one occurrences, respectively; <code>~</code> stands for complement; and <code>-</code> stands for difference. The grammar ignores whitespace and comments.</p>
<pre><code>Schema    := {Namespace}
Namespace := ('namespace' Path '{' {Decl} '}') | {Decl}
Decl      := Entity | Action | TypeDecl
Entity    := 'entity' Idents ['in' EntOrTyps] [['='] RecType] ';'
Action    := 'action' Names ['in' (QualName | '[' [QualNames] ']')] [AppliesTo] [ActAttrs]';'
TypeDecl  := 'type' IDENT '=' Type ';'
Type      := PRIMTYPE | Path | SetType | RecType
EntType   := Path
SetType   := 'Set' '&lt;' Type '&gt;'
RecType   := '{' [AttrDecls] '}'
AttrDecls := Name ['?'] ':' Type [',' | ',' AttrDecls]
AppliesTo := 'appliesTo' '{' AppDecls '}'
ActAttrs  := 'attributes' '{' AttrDecls '}'
AppDecls  := ('principal' | 'resource') ':' EntOrTyps [',' | ',' AppDecls]
           | 'context' ':' RecType [',' | ',' AppDecls]
QualName      := Name | Path '::' STR
QualNames := QualName {',' QualName }
Path      := IDENT {'::' IDENT}
EntTypes  := Path {',' Path}
EntOrTyps := EntType | '[' [EntTypes] ']'
Name      := IDENT | STR
Names     := Name {',' Name}
Idents    := IDENT {',' IDENT}

IDENT     := ['_''a'-'z''A'-'Z']['_''a'-'z''A'-'Z''0'-'9']* - PRIMTYPE
STR       := Fully-escaped Unicode surrounded by '"'s
PRIMTYPE  := 'Long' | 'String' | 'Bool'
WHITESPC  := Unicode whitespace
COMMENT   := '//' ~NEWLINE* NEWLINE
</code></pre>
<h2 id="drawbacks-7"><a class="header" href="#drawbacks-7">Drawbacks</a></h2>
<p>There are several reasons not to develop a custom syntax:</p>
<h3 id="multiple-formats-can-raise-cognitive-burden"><a class="header" href="#multiple-formats-can-raise-cognitive-burden">Multiple formats can raise cognitive burden</a></h3>
<p>Adding another schema format raises the bar for what customers need to know. They may ignore one format at first, but eventually they may need to learn both. For example, if one team uses the JSON format and another uses the custom format, but then the teams merge, they will each end up having to read/update the other's format. They may also fight about which format to move to.</p>
<p>Mitigating this problem is that it's easy and predictable to convert between the two formats, since the syntactic concepts line up very closely. The features you lose when converting from the new format to the JSON one would be 1/ any comments, and 2/ any use of intermingling of <code>action</code>, <code>entity</code>, and <code>type</code> declarations, since they must all be in their own sections in the JSON. Otherwise the features line up very closely and the only difference is syntax. We would expect to write conversion tools as part of implementing the new syntax (which are easily achieved by parsing in the new format and pretty-printing in JSON).</p>
<p>Another mitigating point is that it's early days for Cedar, and we can promote the custom syntax as the preferred choice. JSON should be used when writing tooling to auto-author or manipulate schemas, e.g., as part of a GUI. We have a <a href="https://docs.cedarpolicy.com/json-format.html">JSON syntax for Cedar policies</a> for similar reasons, but it's the custom syntax that is front and center.</p>
<h3 id="requirement-of-good-tooling"><a class="header" href="#requirement-of-good-tooling">Requirement of good tooling</a></h3>
<p>As a practical matter, having a custom schema syntax will require that we develop high-quality tools to help authors write correct schemas.</p>
<p>Parse error messages need to be of good quality, and report common issues such as missing curly braces, missing semi-colons, incorrect keywords, etc. A formatting tool can help ensure standardized presentation. An IDE plugin can put these things together to provide interactive feedback. For the JSON syntax, IDE plugins already exist to flag parse errors and to format documents uniformly.</p>
<p>However, JSON plugins do not understand the semantics of Cedar schemas, so they cannot provide hints about semantic errors (e.g., that setting <code>principalTypes</code> to <code>[]</code> for an <code>action</code> effectively means the <code>action</code> cannot be used in a request). We could develop a linting tool that flags these issues, and it could be applied to both syntaxes.</p>
<p>Note that the problem of matching up curly braces in JSON-formatted schemas is more acute than in the custom syntax, since it's common to have deep nesting levels where matching is hard to eyeball. For example, in the <code>TinyTodo</code> JSON schema, we have up to seven levels of direct nesting of curly braces, whereas the custom syntax has only three, and these levels are more visually isolated because of the other syntax in between them.</p>
<h3 id="greater-implementation-cost"><a class="header" href="#greater-implementation-cost">Greater implementation cost</a></h3>
<p>Supporting a new syntax is an extra implementation cost, including the new tools mentioned above, now and going forward. More code/tools means more potential for bugs.</p>
<p>Mitigating this problem: The Rust internals already parse the JSON schema to a data structure, so adding a new format only involves adding a parser to this data structure and not, for example, making changes to the validator. We can use property-based testing to ensure that both formats are interconvertible, and correctly round-trip, i.e., that <em>parse(pretty-print(AST)) == AST</em>.</p>
<h2 id="alternatives-6"><a class="header" href="#alternatives-6">Alternatives</a></h2>
<p>One alternative would be to <em>replace</em> the current JSON-based sytnax with the one in this proposal. This proposal would avoid the "cognitive burden" drawback mentioned above, but would be a disruptive, backward-incompatible change, and would lose the JSON format's benefits of existing tooling and easier programmatic schema construction.</p>
<p>Another alternative would be to adopt a <a href="https://en.wikipedia.org/wiki/YAML">Yaml</a>-based syntax. This approach would meet our goals of greater information density and support for comments, and it would come with some existing tooling (such as IDE extensions). A downside of Yaml is that it provides <em>more</em> than we need, with a lack of conciseness leading to confusing. We could make our own parser for a subset of Yaml we wish to support for schemas, but that may lead to a confusing user experience. Yaml's indentation-sensitive parsing also means that an indentation mistake will be silently accepted, leading to a confusing user experience. Our custom syntax is whitespace-insensitive, and having total control over the grammar means better context for error messages.</p>
<h2 id="appendix-a---appliesto-conversion-table"><a class="header" href="#appendix-a---appliesto-conversion-table">Appendix A - AppliesTo Conversion Table</a></h2>
<p>The relationship of <code>appliesTo</code> clauses between JSON schemas and this new syntax are non-obvious when unspecified entities or actions with no targets are involved.
This appendix details a conversion table for the purposes of specification.</p>
<h3 id="both-unspecified"><a class="header" href="#both-unspecified">Both Unspecified</a></h3>
<p>The following JSON schemas all set <code>principal</code> and <code>resource</code> to be <em>unspecified</em>, and leave the <code>context</code> as the empty record. They all map to the same schema</p>
<pre><code>"actions" : {
  "read" : {
   }
}
</code></pre>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : null
  }
}
</code></pre>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
    }
  }
}
</code></pre>
<p>This means that both <code>principal</code> and <code>resource</code> are <em>unspecified</em> and that <code>context</code> is the empty record. This becomes:</p>
<pre><code>action read { 
  context : {}
};
</code></pre>
<p>We must include the <code>context : {}</code> as <code>action A {};</code> is not valid in the grammar.</p>
<h3 id="missing-bothyes-context"><a class="header" href="#missing-bothyes-context">Missing Both/Yes Context</a></h3>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "context" : A
    }
  }
}
</code></pre>
<p>This means that both <code>principal</code> and <code>resource</code> are <em>unspecified</em> and that <code>context</code> has type A. This becomes:</p>
<pre><code>action read appliesTo {
  context : A
};
</code></pre>
<h3 id="missing-principaltypes-no-context"><a class="header" href="#missing-principaltypes-no-context">Missing <code>principalTypes</code> /No Context</a></h3>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "resourceTypes" : [A]
    }
 }
}
</code></pre>
<p>This means that <code>principal</code> is <em>unspecified</em>, but <code>resource</code> is specified. <code>context</code> is the empty record. Becomes: (Including the empty context would also be valid)</p>
<pre><code>action read {
  resource : [A]
};
</code></pre>
<h3 id="missing-principaltypes-yes-context"><a class="header" href="#missing-principaltypes-yes-context">Missing <code>principalTypes</code> /Yes Context</a></h3>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "resourceTypes" : [A]
      "context" : B
    }
 }
}
</code></pre>
<p>This means that <code>principal</code> is <em>unspecified</em>, but <code>resource</code> is specified. <code>context</code> has type <code>B</code>. Becomes:</p>
<pre><code>action read {
  resource : [A],
  context : B
};
</code></pre>
<h3 id="missing-resourcetypesno-context"><a class="header" href="#missing-resourcetypesno-context">Missing <code>resourceTypes</code>/No Context</a></h3>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "principalTypes" : [A]
    }
  }
}
</code></pre>
<p>This means that <code>resource</code> is <em>unspecified</em>, but <code>principal</code> is specified. <code>context</code> is the empty record. Becomes: (Including the empty context would also be valid).</p>
<pre><code>action read appliesTo {
  principal: [A]
}
</code></pre>
<h3 id="missing-resourcetypesyes-context"><a class="header" href="#missing-resourcetypesyes-context">Missing <code>resourceTypes</code>/Yes Context</a></h3>
<pre><code>"actions" : {
  "read" : {
    "applieTo" : {
      "principalTypes" : [A],
      "context" : B
    }
  }
}
</code></pre>
<p>This means that <code>resource</code> is <em>unspecified</em>, but <code>principal</code> is specified. <code>context</code> has type B. Becomes:</p>
<pre><code>action read appliesTo {
  principal: [A],
  context: B
};
</code></pre>
<h3 id="non-applicable-actions"><a class="header" href="#non-applicable-actions">Non-Applicable Actions</a></h3>
<p>The following <em>all</em> collapse to the same schema object. They all involve action types which are not applicable. Specifying that you are applicable to some <code>principal</code> P and not applicable to any resources is equivalent to not being applicable to any principals or resources.</p>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "principalTypes" : [],
      "resourceTypes" : []
    }
  }
}
</code></pre>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "principalTypes" : [],
      "resourceTypes" : [A]
    }
  }
}
</code></pre>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "principalTypes" : [A],
      "resourceTypes" : []
    }
  }
}
</code></pre>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "principalTypes" : [],
      "resourceTypes" : [],
      "context" : A
    }
  }
}
</code></pre>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "principalTypes" : [A],
      "resourceTypes" : [],
      "context" : B
    }
  }
}
</code></pre>
<pre><code>"actions" : {
  "read" : {
    "appliesTo" : {
      "principalTypes" : [],
      "resourceTypes" : [A],
      "context" : B
    }
  }
}
</code></pre>
<p>All of the above map to the following:</p>
<pre><code>action read;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="port-cedar-formalization-to-lean"><a class="header" href="#port-cedar-formalization-to-lean">Port Cedar formalization to Lean</a></h1>
<h2 id="related-issues-and-prs-7"><a class="header" href="#related-issues-and-prs-7">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: N/A</li>
<li>Implementation PR(s): <a href="https://github.com/cedar-policy/cedar-spec/pull/138">https://github.com/cedar-policy/cedar-spec/pull/138</a></li>
</ul>
<h2 id="timeline-7"><a class="header" href="#timeline-7">Timeline</a></h2>
<ul>
<li>Started: 2023-10-12</li>
<li>Accepted: 2023-10-24</li>
<li>Landed: 2023-10-26 on <code>main</code></li>
<li>Released: The Dafny formalization was deprecated in <code>cedar-spec</code> v3.1.0 (released 2024-03-08)</li>
</ul>
<h2 id="summary-7"><a class="header" href="#summary-7">Summary</a></h2>
<p>This RFC proposes to port our current Cedar models and proofs (written in <a href="https://dafny.org/">Dafny</a>) to an alternative verification tool (<a href="https://lean-lang.org/">Lean</a>) that is better suited for meta-theory proofs, like Cedar’s validation soundness proof.</p>
<p><strong>Note</strong>: The changes proposed in this RFC do not impact the <a href="https://github.com/cedar-policy/cedar"><code>cedar-policy/cedar</code></a> repository or any of its associated Rust crates. The proposed changes are restricted to the formalization available in <a href="https://github.com/cedar-policy/cedar-spec"><code>cedar-policy/cedar-spec</code></a>.</p>
<h2 id="motivation-7"><a class="header" href="#motivation-7">Motivation</a></h2>
<p>Following a <a href="https://www.amazon.science/blog/how-we-built-cedar-with-automated-reasoning-and-differential-testing">verification-guided development process</a>, we use proofs to gate the release of Cedar’s core components. To release a new version, the Rust implementation of each component is differentially tested against its Dafny model, which is formally verified against key security and correctness properties.</p>
<p>We chose Dafny for its balance of usability and ability to automatically prove basic security properties of Cedar's authorizer. But proving Cedar's meta-theoretic properties (such as validator soundness) is less suited for Dafny’s automation (e.g., see <a href="https://github.com/cedar-policy/cedar-spec/issues/35"><em>this issue</em></a> and associated PRs). For these proofs to be robust in terms of performance and maintenance, they need to be highly detailed, favoring the use of an <a href="https://en.wikipedia.org/wiki/Proof_assistant"><em>interactive theorem prover</em></a>. We propose porting Cedar to Lean, an interactive theorem prover that is well suited for large-scale proofs about meta-theory.</p>
<h2 id="detailed-design-7"><a class="header" href="#detailed-design-7">Detailed design</a></h2>
<p>Cedar consists of three core components: (1) the evaluator, (2) authorizer, and (3) validator. The evaluator interprets Cedar policies, and the authorizer combines the results of evaluating multiple policies into an authorization decision. Cedar’s security theorems prove basic properties of the authorizer (e.g., deny overrides allow). The validator is a tool for working with Cedar policies. It type checks a policy against a schema. To assure correctness, we prove a validator soundness theorem which guarantees that if the validator accepts a policy, evaluating that policy on a valid input can never cause a type error.</p>
<p>All core components of Cedar are modeled in Dafny and have proofs.  There are ~6,000 lines of modeling code.  The proofs for the authorizer and evaluator are small:  the largest is ~200 LOC.  The validation soundness proof is ~2,000 LOC.</p>
<p>For each component, we plan to port the model first and start differentially testing it against the Rust implementation, and then port the proofs. The Dafny and Lean code will co-exist while we work on the port. Once the Lean validator proofs are complete, we will archive the Cedar Dafny folder.</p>
<p>We believe it is best to do the port now while our development is relatively small, and before we begin working on proving other meta-theoretic properties, like soundness of the partial evaluator (which is not yet modeled in Dafny).</p>
<h2 id="drawbacks-8"><a class="header" href="#drawbacks-8">Drawbacks</a></h2>
<p>We will need to support both Dafny and Lean proofs for a period of time, to ensure that Cedar remains sound and there are no gaps.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="precomputed-entity-attributes"><a class="header" href="#precomputed-entity-attributes">Precomputed Entity Attributes</a></h1>
<h2 id="related-issues-and-prs-8"><a class="header" href="#related-issues-and-prs-8">Related issues and PRs</a></h2>
<ul>
<li>This RFC is mostly directly taken from <a href="https://github.com/cedar-policy/rfcs/pull/28">RFC 28</a>;
it splits out the changes from RFC 28 that relate to precomputed entity
attributes, without the larger changes in RFC 28 regarding <code>EntityDataSource</code>.</li>
<li>This RFC is also the successor to <a href="https://github.com/cedar-policy/rfcs/pull/23">RFC 23</a>.</li>
<li>Implementation PR: <a href="https://github.com/cedar-policy/cedar/pull/430">cedar#430</a></li>
</ul>
<h2 id="timeline-8"><a class="header" href="#timeline-8">Timeline</a></h2>
<ul>
<li>Started: 2023-10-24 (predecessor <a href="https://github.com/cedar-policy/rfcs/pull/28">#28</a> started on 2023-10-03, and predecessor <a href="https://github.com/cedar-policy/rfcs/pull/23">#23</a> started on 2023-07-18)</li>
<li>Accepted: 2023-11-14</li>
<li>Landed: 2023-11-16 on <code>main</code></li>
<li>Released: 2023-12-15 in <code>cedar-policy</code> v3.0.0</li>
</ul>
<h2 id="summary-8"><a class="header" href="#summary-8">Summary</a></h2>
<p>Internally, Cedar entity objects will store their attribute values as
precomputed <code>Value</code>s, rather than in <code>RestrictedExpression</code> form.
This entails some minor breaking changes to the Cedar public API, but provides
important efficiency gains.</p>
<h2 id="motivation-8"><a class="header" href="#motivation-8">Motivation</a></h2>
<ol>
<li>
<p>Today, every <code>is_authorized()</code> request re-evaluates all of the attributes in the
<code>Entities</code>; they are stored as restricted expressions and evaluated to <code>Value</code>
on every call to <code>is_authorized()</code>. (See
<a href="https://github.com/cedar-policy/cedar/issues/227">cedar#227</a>.)
This is inefficient.</p>
</li>
<li>
<p>Today, <code>Entities::evaluate()</code> is implemented on <code>main</code> and provides a way to
mitigate this issue, but it is opt-in and we'd rather have it be the default
behavior.
Notably, as of this writing, <code>Entities::evaluate()</code> is not released yet, so we
can make changes in this area without breaking our users.</p>
</li>
</ol>
<h2 id="detailed-design-8"><a class="header" href="#detailed-design-8">Detailed design</a></h2>
<p>This RFC has <del>three</del> two components: (a third component was severed and moved to
Alternative A after discussion)</p>
<h3 id="component-1-store-attributes-as-precomputed-values"><a class="header" href="#component-1-store-attributes-as-precomputed-values">Component 1: Store attributes as precomputed <code>Value</code>s</a></h3>
<p>We redefine <code>Entities</code> and <code>Entity</code> to hold attributes as <code>Value</code>s instead of as
restricted expressions.
This addresses the first point in <a href="0034-precomputed-entity-attributes.html#motivation">Motivation</a>.</p>
<p>This change is breaking for the public API in two (small) ways:</p>
<ul>
<li><code>Entity::new()</code>, <code>Entities::from_json_*()</code>, and friends can take the same
inputs, but will need to sometimes return an evaluation error due to errors
evaluating the entity attributes (particularly, errors from evaluating extension
functions for attribute values of type <code>ipaddr</code> or <code>decimal</code>).
Today, <code>Entity::new()</code> never returns an error, and the <code>Entities</code> functions can
return <code>EntitiesError</code> but not an evaluation error.</li>
<li>Conversely, <code>Entity::attr()</code> need not return an error anymore, as all of the
attributes will already be evaluated. (If we are very concerned about backward
compatibility, we could keep the current signature and just never return <code>Err</code>.
Currently, this RFC is proposing we change the signature to not contain
<code>Result</code>, since we're already making the related breaking change to
<code>Entity::new()</code>.)</li>
</ul>
<p>Accepting these breaking changes allows us to give users the best-performing
behavior by default.
For alternatives that are less breaking, see <a href="0034-precomputed-entity-attributes.html#alternatives">Alternatives</a>.</p>
<h3 id="component-2-remove-no-longer-necessary-interface-to-precompute-values"><a class="header" href="#component-2-remove-no-longer-necessary-interface-to-precompute-values">Component 2: Remove no-longer-necessary interface to precompute <code>Value</code>s</a></h3>
<p>We remove <code>Entities::evaluate()</code>, as all <code>Entities</code> are now stored in their
evaluated form by default.
This addresses the second point in <a href="0034-precomputed-entity-attributes.html#motivation">Motivation</a>.</p>
<p>This is not a breaking change because <code>Entities::evaluate()</code> has not yet been
released in any Cedar release.</p>
<h2 id="drawbacks-9"><a class="header" href="#drawbacks-9">Drawbacks</a></h2>
<ul>
<li>This RFC represents some breaking changes for users upgrading to a new major
version of Cedar. All breaking changes come with some cost in terms of user
experience for existing users. This RFC contends that the benefit outweighs the
cost in this case.</li>
</ul>
<h2 id="alternatives-7"><a class="header" href="#alternatives-7">Alternatives</a></h2>
<h3 id="alternative-a"><a class="header" href="#alternative-a">Alternative A</a></h3>
<p>In addition to what is currently proposed in this RFC, we could add the
following change, allowing users to construct entities using precomputed
<code>Value</code>s.</p>
<p><strong>Motivation</strong></p>
<p>Today, <code>Entity::new()</code> requires callers to pass in attribute values as
<code>RestrictedExpression</code>.
For some callers, evaluating these <code>RestrictedExpression</code>s is an unnecessary
source of runtime evaluation errors (and performance overhead).</p>
<p><strong>Detailed design</strong></p>
<p>We add new constructors for <code>Entities</code> and <code>Entity</code> which take <code>Value</code>s
instead of <code>RestrictedExpression</code>s.
These constructors would work without throwing evaluation errors, in contrast to
the existing constructors after the changes described in the main part of this
RFC.</p>
<p>This change requires that we expose <code>Value</code> in our public API in some manner
(probably via a wrapper around the Core implementation, as we do for many other
Core types).
Note that today, <code>EvalResult</code> plays the role of <code>Value</code> in our public API, but
conversion between <code>EvalResult</code> and <code>Value</code> is relatively expensive (<code>O(n)</code>).
We could either:</p>
<ul>
<li>expose <code>Value</code> but leave <code>EvalResult</code> alone. This provides maximum backwards
compatibility, but might cause confusion, as <code>Value</code> and <code>EvalResult</code>
would be conceptually similar, but slightly different and not interchangeable.</li>
<li>consolidate <code>EvalResult</code> and <code>Value</code> into a single representation, called
<code>Value</code> and based on the Core <code>Value</code>. This provides maximum API cleanliness
but requires the most breaking changes.</li>
<li>expose <code>Value</code>, but keep <code>EvalResult</code> as a type synonym for <code>Value</code>. This
is almost the same as the above option, but keeps the <code>EvalResult</code> type name
around, even though it makes breaking changes to the structure of
<code>EvalResult</code>. This might reduce confusion for users who are migrating, as
they only have to adapt to the changes to <code>EvalResult</code> and not rename
<code>EvalResult</code> to <code>Value</code> in their own code; but, it might increase confusion
for future users, who will see two names for the same thing.</li>
<li>not expose <code>Value</code> and just use <code>EvalResult</code>, even in the new constructors.
This provides maximum backwards compatibility, like the first option, and
also avoids the possible confusion generated by the first option, but comes
at a notable performance cost (due to the inefficient
<code>EvalResult</code>-to-<code>Value</code> conversion required under the hood) and might
generate a different kind of confusion as <code>EvalResult</code> is an awkward name in
the context of these constructors.</li>
</ul>
<p><strong>Commentary</strong></p>
<p>The sub-proposal in this alternative is severable and could be its own RFC, or
perhaps a change that doesn't rise to the level of requiring an RFC.
We have the freedom to do it any time in the future (after the rest of the RFC
is accepted and implemented) if we don't want to do it now.</p>
<p>@mwhicks1 opinion, which I tend to agree with, is that this alternative is
probably more trouble than it's worth -- that it provides only marginal benefit
to users at the cost of cluttering our API, both with additional constructors,
and with the public <code>Value</code> type.</p>
<p>If we don't take this alternative, users will have to still construct <code>Entity</code>
and <code>Entities</code> via restricted expressions, using constructors which can throw
errors.
But, we would be able to avoid having to expose <code>Value</code> or make changes to
<code>EvalResult</code>, at least for now.</p>
<h3 id="alternative-b"><a class="header" href="#alternative-b">Alternative B</a></h3>
<p>In addition to what is currently proposed in the current RFC, we could provide
the status-quo definitions of <code>Entities</code> and <code>Entity</code> under new names: e.g.,
<code>UnevaluatedEntities</code> and <code>UnevaluatedEntity</code> (naming of course TBD).
This is very unlikely to be of any use to new users, but existing users really
wanting the old error behavior could use these types and functions instead of
<code>Entities</code> and <code>Entity</code>.</p>
<p>To me, this provides little benefit, at the expense of more confusion and more
APIs to maintain. It also doesn't make any of the changes more back-compatible;
for users, migrating their code to use these renamed types and functions may be
just as much work as adopting the actual breaking changes proposed in this RFC.</p>
<h3 id="alternative-c"><a class="header" href="#alternative-c">Alternative C</a></h3>
<p>Instead of changing <code>Entities</code> and <code>Entity</code> as suggested in the current RFC, we
could provide new versions of these types -- say, <code>EvaluatedEntities</code> and
<code>EvaluatedEntity</code> -- which have the behaviors proposed in the current RFC.  This
avoids making any breaking changes to existing types and functions.</p>
<p>The downsides of this alternative include:</p>
<ul>
<li>Existing users don't get the improved performance by default (see
<a href="0034-precomputed-entity-attributes.html#motivation">Motivation</a>). They have to opt-in by migrating their code to these
new types and functions.</li>
<li>Whether or not we officially deprecate the existing <code>Entities</code> and <code>Entity</code>,
new users may incorrectly assume that they should default to using those types,
as they have the most-intuitive / least-qualified names, and types like
<code>EvaluatedEntities</code> might appear to be for special cases.</li>
<li>If we do not officially deprecate the existing <code>Entities</code> and <code>Entity</code>, we are
stuck maintaining more APIs indefinitely. These APIs are also somewhat redundant
and provide multiple ways to do approximately the same thing, some more
optimally than others.</li>
<li>If we do officially deprecate the existing <code>Entities</code> and <code>Entity</code> we end up
in a final state where we only have <code>EvaluatedEntities</code> and no other kind of
<code>Entities</code>, which is a kinda ugly and nonsensical API from a naming standpoint
-- not aesthetically pleasing.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="annotations-for-cedar-schemas"><a class="header" href="#annotations-for-cedar-schemas">Annotations for Cedar Schemas</a></h1>
<h2 id="related-issues-and-prs-9"><a class="header" href="#related-issues-and-prs-9">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues:</li>
<li>Implementation PR(s): https://github.com/cedar-policy/cedar/tree/feature/shaobo/rfc48</li>
</ul>
<h2 id="timeline-9"><a class="header" href="#timeline-9">Timeline</a></h2>
<ul>
<li>Started: 2024-02-05</li>
</ul>
<h2 id="summary-9"><a class="header" href="#summary-9">Summary</a></h2>
<p>Like Cedar policies, users may want to associate arbitrary, machine readable metadata with Schema objects.
We solved this problem in Cedar policies by allowing for <em>annotations</em>: arbitrary key/value pairs that are attachable to policies.
This could be extended to Cedar schemas, allowing users to attach attributes an entity type/common type/action declaration and attribute declaration.</p>
<h2 id="basic-example-6"><a class="header" href="#basic-example-6">Basic example</a></h2>
<p>Here is a basic example for doc comments.</p>
<pre><code>@doc("this is the namespace")
namespace TinyTodo {
    @doc("a common type representing a task")
    type Task = {
        @doc("task id")
        "id": Long,
        "name": String,
        "state": String,
    };
    @doc("a common type representing a set of tasks")
    type Tasks = Set&lt;Task&gt;;

    @doc("an entity type representing a list")
    @docComment("any entity type is a child of type `Application`")
    entity List in [Application] = {
        @doc("editors of a list")
        "editors": Team,
        "name": String,
        "owner": User,
        @doc("readers of a list")
        "readers": Team,
        "tasks": Tasks,
    };

    @doc("actions that a user can operate on a list")
    action DeleteList, GetList, UpdateList appliesTo {
        principal: [User],
        resource: [List]
    };
}
</code></pre>
<p>The <code>@id("...")</code> notation is similar to the notation used for policy annotations.</p>
<h2 id="motivation-9"><a class="header" href="#motivation-9">Motivation</a></h2>
<p>Users should be allowed to associate machine readable metadata with objects in a Schema.
While we could create special syntax for associating particular kinds of metadata, we cannot
predict all of the metadata uses that users will have.
Thus providing a flexible system that users can adapt to their needs is preferable.
This proposal re-uses the same syntax from Cedar Policies, creating a unified syntax.</p>
<h2 id="detailed-design-9"><a class="header" href="#detailed-design-9">Detailed design</a></h2>
<h3 id="semantics-1"><a class="header" href="#semantics-1">Semantics</a></h3>
<p>Attributes have <strong>no</strong> impact on validation decisions.
Attributes are arbitrary key/value pairs where:</p>
<ul>
<li>'key' is a valid Cedar identifier</li>
<li>'value' is a Cedar string</li>
</ul>
<p>The Cedar spec takes no opinion or stance on the interpretation of annotations.
The interpretation is entirely up to users of Cedar.</p>
<h3 id="cedar-schema-syntax-1"><a class="header" href="#cedar-schema-syntax-1">Cedar Schema Syntax</a></h3>
<p>Attributes in Cedar Schemas will mirror the syntax used for attributes in a policy: informally that's <code>@&lt;key&gt;("value")</code>.
Formally the following rule is added to the Cedar grammar:</p>
<pre><code>Annotation := '@' IDENT '(' STR ')'
Annotations := {Annotations}
</code></pre>
<p>With an arbitrary number of them being able to prepend to a namespace declaration, entity type declaration, common type declaration, action declaration, and an attribute declaration.</p>
<p>Thus the full schema syntax becomes:</p>
<pre><code>Schema      := {Namespace}
Namespace   := (Annotations 'namespace' Path '{' {Decl} '}') | {Decl}
Decl        := Entity | Action | TypeDecl
Entity      := Annotations 'entity' Idents ['in' EntOrTyps] [['='] RecType] ';'
Action      := Annotations 'action' Names ['in' (Name | '[' [Names] ']')] [AppliesTo] [ActAttrs]';'
TypeDecl    := Annotations 'type' IDENT '=' Type ';'
Type        := PRIMTYPE | IDENT | SetType | RecType
EntType     := Path
SetType     := 'Set' '&lt;' Type '&gt;'
RecType     := '{' [AttrDecls] '}'
AttrDecls   := Annotations Name ['?'] ':' Type [',' | ',' AttrDecls]
AppliesTo   := 'appliesTo' '{' AppDecls '}'
ActAttrs    := 'attributes' '{' AttrDecls '}'
AppDecls    := ('principal' | 'resource') ':' EntOrTyps [',' | ',' AppDecls]
             | 'context' ':' RecType [',' | ',' AppDecls]
Path        := IDENT {'::' IDENT}
EntTypes    := Path {',' Path}
EntOrTyps   := EntType | '[' [EntTypes] ']'
Name        := IDENT | STR
Names       := Name {',' Name}
Idents      := IDENT {',' IDENT}
Annotation  := '@' IDENT '(' STR ')
Annotations := Annotation {Annotations}

IDENT       := ['_''a'-'z''A'-'Z']['_''a'-'z''A'-'Z''0'-'9']* - PRIMTYPE
STR         := Fully-escaped Unicode surrounded by '"'s
PRIMTYPE    := 'Long' | 'String' | 'Bool'
WHITESPC    := Unicode whitespace
COMMENT     := '//' ~NEWLINE* NEWLINE
</code></pre>
<h3 id="json-syntax"><a class="header" href="#json-syntax">JSON Syntax</a></h3>
<p>None of the three top-level constructs (EntityTypes, Actions, CommonTypes) in JSON schemas allow for arbitrary key/value pairs.
This means a new key can be safely added while preserving backwards compatibility.
The same fact also applies to entity attribute declarations.
This proposal reserves the <code>annotations</code> key at the top level of each of those constructs, which contains an Object, containing each annotation key as an Object key, associated with the annotation string.
The only oddness here is Common Types, whose toplevel is a regular type. While this should still be backwards compatible, it will look a little odd to have annotations in some types and not in others.</p>
<p>A corresponding JSON schema for the above example is as follows.</p>
<pre><code class="language-JSON">{
    "": {
    "annotations": {
        "doc": "this is the namespace"
    },
    "commonTypes": {
        "Task": {
        "annotations": {
            "doc": "a common type representing a task"
        },
        "type": "Record",
        "attributes": {
            "id": {
            "type": "Long",
            "annotations": {
                "doc": "task id"
            },
            },
            "name": {
            "type": "String"
            },
            "state": {
            "type": "String"
            }
        }
        },
        "Tasks": {
        "type": "Set",
        "element": {
            "type": "Task"
        }
        }
    },
    "entityTypes": {
        "Application": {},
        "List": {
        "annotations": {
            "doc": "an entity type representing a list",
            "docComment": "any entity type is a child of type `Application`"
        },
        "memberOfTypes": [
            "Application"
        ],
        "shape": {
            "type": "Record",
            "attributes": {
            "editors": {
                "type": "Team"
            },
            "name": {
                "type": "String"
            },
            "owner": {
                "type": "User"
            },
            "readers": {
                "type": "Team"
            },
            "tasks": {
                "type": "Tasks"
            }
            }
        }
        }
    },
    "actions": {
        "CreateList": {
         "annotations": {
            "doc": "actions that a user can operate on a list"
        },
        "appliesTo": {
            "resourceTypes": [
            "Application"
            ],
            "principalTypes": [
            "User"
            ]
        }
       }
    }
  }
}
</code></pre>
<h2 id="drawbacks-10"><a class="header" href="#drawbacks-10">Drawbacks</a></h2>
<ol>
<li>Complexity: adds more complexity to schema</li>
<li>Oddness around syntax for Common Types in JSON form</li>
<li>By not taking a stance on annotation meanings, it makes it harder for a standard to form around them (ex: for doc strings)</li>
<li>Multi-line docstrings are technically valid but awkward.</li>
</ol>
<h2 id="alternatives-8"><a class="header" href="#alternatives-8">Alternatives</a></h2>
<h3 id="take-a-stance"><a class="header" href="#take-a-stance">Take a stance</a></h3>
<p>Reverse our decision around annotations and start taking stances on what annotations mean.
This lets us standardize certain annotations, like <code>doc</code>.
This probably can't happen unless we also do this for policies, which we've said we don't want to do.</p>
<h3 id="doc-strings-as-comments"><a class="header" href="#doc-strings-as-comments">Doc Strings as comments</a></h3>
<p>Instead of annotations, we could add "doc-strings" as a first class feature.
Could look like this:</p>
<pre><code>/# Stop users from accessing a high security document unless:
/#  A) The principal and user are at the same location
/#  B) The principal has a job level greater than  4
forbid(principal, action, resource) when {
    resource.security_level == "HIGH"
unless {
    (resource.location == principal.location) || (principal.job_level &gt; 4 )
};
</code></pre>
<p>This has nice and easy multi-line syntax, but is special cased and not as general.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reserve-identifiers-for-internal-use"><a class="header" href="#reserve-identifiers-for-internal-use">Reserve Identifiers for Internal Use</a></h1>
<h2 id="related-issues-and-prs-10"><a class="header" href="#related-issues-and-prs-10">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: https://github.com/cedar-policy/cedar/issues/920</li>
<li>Implementation PR(s): https://github.com/cedar-policy/cedar/pull/969</li>
</ul>
<h2 id="timeline-10"><a class="header" href="#timeline-10">Timeline</a></h2>
<ul>
<li>Started: 2024-02-14</li>
<li>Accepted: 2024-06-10</li>
<li>Landed: 2024-07-15 on <code>main</code> (<a href="https://github.com/cedar-policy/cedar/pull/969">#969</a>)</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-10"><a class="header" href="#summary-10">Summary</a></h2>
<p>This RFC extends the reservation of the <code>__cedar</code> namespace in schema in <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0024-schema-syntax.md">RFC24</a> and
proposes reserving all namespaces and identifiers where the first element is <code>__cedar</code>,
forbidding their use in Cedar policies, schema, and entity data so that they can be used by future Cedar language features.</p>
<h2 id="basic-example-7"><a class="header" href="#basic-example-7">Basic example</a></h2>
<p>Under this RFC the names <code>__cedar</code>, <code>__cedar::Long</code>, and <code>__cedar::namespace::User</code> will all become invalid in all contexts.</p>
<p>These would be rejected in a policy</p>
<pre><code class="language-cedar">permit(principal == __cedar::User::"alice", actions, resource);
</code></pre>
<p>in a schema</p>
<pre><code>namespace __cedar {
    entity User;
}
</code></pre>
<p>and in entity data</p>
<pre><code class="language-json">[
    {
        "uid": { "__entity": {
            "type": "__cedar::User",
            "id": "alice"
        }},
        "attrs": {},
        "parents": []
    }
]
</code></pre>
<p>In this entity data example, the <code>__entity</code> JSON key does not demonstrate the new reserved namespace mechanism.
It is a place were we already assign special significance to some identifiers starting with <code>__</code> in entity data.</p>
<h2 id="motivation-10"><a class="header" href="#motivation-10">Motivation</a></h2>
<p>In designing <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0024-schema-syntax.md">RFC24</a> we found that we needed to disambiguate user defined identifiers from built-in primitive and extension types.
We accomplished this by reserving only the <code>__cedar</code> namespace inside of schema,
but we anticipate that we may need more reserved namespaces in more contexts in the future.</p>
<h2 id="detailed-design-10"><a class="header" href="#detailed-design-10">Detailed design</a></h2>
<p>We will update the <a href="https://docs.cedarpolicy.com/policies/syntax-grammar.html#grammar-path">namespace grammar</a> to the following to exclude namespaces and identifiers starting with <code>__cedar</code>.</p>
<pre><code>Path ::= IDENT {'::' TRAILING_NAMESPACE_IDENT}
IDENT ::= INNER_IDENT - '__cedar'
TRAILING_NAMESPACE_IDENT ::= ['_''a'-'z''A'-'Z']['_''a'-'z''A'-'Z''0'-'9']* - RESERVED
RESERVED ::= 'true' | 'false' | 'if' | 'then' | 'else' | 'in' | 'like' | 'has'
</code></pre>
<p>This primarily applies to entity types names.
In the case where an entity type isn't qualified with a namespace, the leading identifier is just the entity type, so we would forbid an unqualified type <code>__cedar</code>.
It also applies anywhere else namespaces may appear, including the top-level <code>namespace</code> element in a schema file, qualified references to common types in a schema file, and extension function names in policies.</p>
<p>It also applies where a standalone identifier is expected.
For example, an entity attribute could not be <code>__cedar</code>.
Reserving this single attribute is not own it's own particularly useful, but we may later extend the attribute grammar to accept namespace paths.</p>
<h2 id="drawbacks-11"><a class="header" href="#drawbacks-11">Drawbacks</a></h2>
<p>This is a significant breaking change.
Anyone using the <code>__cedar</code> namespace will need to update their policies, schema, and entity data to use an unreserved namespace.
The nature of this breaking change fortunately allows for migration away from reserved namespaces before the change is released,
and the break will manifest immediately on attempting to parse an affected policy, schema, or entity.</p>
<h2 id="alternatives-9"><a class="header" href="#alternatives-9">Alternatives</a></h2>
<h3 id="a-larger-breaking-change"><a class="header" href="#a-larger-breaking-change">A larger breaking change</a></h3>
<p>We could make a larger breaking change by reserving identifiers starting with <code>__</code> instead of just <code>__cedar</code>.
For example, we would additional forbid referencing an entity <code>__tiny_todo::User</code>.</p>
<p>We don't currently see an immediate need for this more aggressive change, and it increases the likelihood a current user will be affected.
We may also find that consumers of Cedar who expose the policy language to their users want to reserve namespaces for their own use.
They could of course choose a namespace with any leading characters, but they may prefer the uniformity between <code>__cedar::Long</code> and, for example, <code>__tiny_todo</code>.</p>
<h3 id="no-breaking-change"><a class="header" href="#no-breaking-change">No breaking change</a></h3>
<p>We can avoid a breaking change to Cedar by updating the Grammar to allow for a new identifier that is currently invalid, and then reserve that identifier.
For example, we could reserve <code>$cedar</code> or <code>cedar$</code> (other options for characters include <code>%</code> or <code>!</code>).
It would would be an error to use this identifier in any way that isn't explicitly permitted by the Cedar spec.</p>
<p>Taking this option would require an update to the schema grammar proposed in <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0024-schema-syntax.md">RFC24</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="enumerated-entity-types"><a class="header" href="#enumerated-entity-types">Enumerated Entity Types</a></h1>
<h2 id="timeline-11"><a class="header" href="#timeline-11">Timeline</a></h2>
<ul>
<li>Started: 2024-02-20</li>
<li>Accepted: 2024-03-20</li>
<li>Landed: TBD</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-11"><a class="header" href="#summary-11">Summary</a></h2>
<p>Extend schemas to support declared enumerations of entity-typed values, analogous to how schemas can currently be used to enumerate a finite list of <code>Action</code>-typed values.</p>
<h2 id="basic-example-8"><a class="header" href="#basic-example-8">Basic example</a></h2>
<p>An enumerated entity type is declared as a normal entity type, but includes the keyword <code>enum</code> followed by the list of legal entity UIDs. Here is a simple example:</p>
<pre><code>entity User;
entity Color enum ["Red", "Blue", "Green"];
entity Task {
    owner: User,
    name: String,
    status: Color
};
action UpdateTask
    appliesTo { principal: [User], resource: [Task] };
</code></pre>
<p>These data definitions could be used in policies such as</p>
<pre><code>permit(
    principal,
    action == Action::"UpdateTask",
    resource)
when {
    principal == resource.owner &amp;&amp;
    resource.status != Color::"Red"
};
</code></pre>
<h2 id="motivation-11"><a class="header" href="#motivation-11">Motivation</a></h2>
<p>Enumerated types are useful when you have a fixed set of possible values, and the only thing you want to do with the values is compare them for equality. While you could effectively treat an entity type as an enumeration now, without declaring it in a schema, you gain some benefits by declaring it:</p>
<ul>
<li>The validator can error on uses of illegal enumerated values, e.g., flagging the typo <code>resource.status != Color::"red"</code> in the <code>when</code> clause in the basic example.</li>
<li>When using a policy analyzer, it can always generate request and entity store instances where the enumerated entity type has declared-valid values, rather than random UIDs.</li>
<li>When using an IDE or web-based policy builder, the enumeration can inform auto-completion suggestions. For the basic example above, in an auto-completing IDE writing <code>resource.status != </code> ... would pop up the three options.</li>
</ul>
<h2 id="detailed-design-11"><a class="header" href="#detailed-design-11">Detailed design</a></h2>
<p>An enumerated entity <code>Foo</code> is declared by writing</p>
<pre><code>entity Foo enum [ … ];
</code></pre>
<p>where <code>[</code> … <code>]</code> is a non-empty list of allowed values, expressed as strings.</p>
<p>In the JSON format for schemas, you would write</p>
<pre><code>"entityTypes": {
    ...
    "Foo": {
        "enum": [ … ]
    },
    ...
}
</code></pre>
<p>You can use an enumerated entity type anywhere you can use a normal entity type. Since an enumerated entity cannot have attributes, nor can it have ancestors in the entity hierarchy, all you can do with it is test it for equality (e.g., with <code>==</code> or <code>contains</code>).</p>
<p>The policy validator confirms that any enumerated entity literal in a policy is valid. The request validator does likewise. The entity store validator confirms that enumerated entities <em>do not</em> appear in the store, or if they do, they have no attributes or ancestors. It also confirms that the declared enumerated entity type has no invalid values, and references to entities of the enumerated type are valid. The schema-based entity parser likewise confirms that parsed-in enumerated entity values are valid.</p>
<p>As another example, consider the following.</p>
<pre><code>entity Application enum [ "TinyTodo" ];
entity User in [ Application ];
action CreateList
    appliesTo { principal: [User], resource: [Application] };
</code></pre>
<p>This is a generalization of our TinyTodo example from RFC 24, where we can refine the definition of <code>Application</code> to indicate that it has a single value, <code>Application::"TinyTodo"</code>. This allows the validator to catch typos in policies, such as the following.</p>
<pre><code>permit(
    principal,
    action in [Action::"CreateList"],
    resource == Application::"TinyTODO"
);
</code></pre>
<p>Likewise the request validator would flag a request with <code>Application::"TinyTODO"</code> as its resource, and it would flag the passed-in entity store if it contained such an illegal value.</p>
<h3 id="notes"><a class="header" href="#notes">Notes</a></h3>
<p>As a convention, our example enumerated entity names, like <code>Color::"Red"</code> or <code>Application::"TinyTodo"</code>, all begin with an uppercase letter. We choose to consider this approach good style, but not to mandate it.</p>
<p>We require entity enumerations to be given as a non-empty list of strings, like <code>["Red", "Blue"]</code>, but we could also allow them to be specified as identifiers, like <code>[ Red, Blue ]</code>. Doing so would be similar to the handling of attributes, which can be specified as identifiers, <code>principal.owner</code>, or as strings, <code>principal["owner"]</code>. However, entity enumerations can only be <em>referenced</em> as strings, e.g., as <code>Color::"Red"</code> not <code>Color::Red</code>. Specifying them as strings, only, makes this connection a little stronger.</p>
<p>We do not permit declaring empty enumerations. Allowing them would add complication to policy analysis (to consider the exceptional case), but would be essentially useless: You could never create an entity of type <code>Foo</code>, where <code>Foo</code> is uninhabited, and while you could write <code>expr is Foo</code>, this expression is always <code>false</code>.</p>
<p>That an entity is an enumeration is specified as a refinement when declaring the entity type, e.g., writing <code>entity Application;</code> declares the <code>Application</code> entity type, while writing <code>entity Application enum ["TinyTodo"];</code> declares the <code>Application</code> entity type and then refines it to say that only the <code>"TinyTodo"</code> entity ID is well defined. An alternative syntax that is more intuitive to some readers is <code>entity enum Application ["TinyTodo"]</code>. This syntax is similar to Java-style syntax, <code>enum Application { TinyTodo }</code>. However, this approach could create some confusion: <code>enum</code> is currently a valid entity type, so it's legal to write <code>entity enum;</code> in schemas today. Moreover, if we eventually take Alternative C, below, we may allow <code>enum</code> to be accompanied by other type refinements, such as <code>in</code> and attribute declarations. For example, we could one day be able to write <code>entity Application in [Application] enum ["TinyTodo", "Office"]</code> (or swapping their order, <code>entity Application enum ["TinyTodo", "Office"] in [Application]</code>), and might prefer the uniformity of that to <code>entity enum Application ["TinyTodo", "Office"] in [Application]</code>.</p>
<h2 id="drawbacks-12"><a class="header" href="#drawbacks-12">Drawbacks</a></h2>
<p>One reason not to do this is that it's not particularly full featured---you cannot do anything useful with an enumerated entity value in a policy other than compare it for equality. We consider more full-featured extensions in the alternatives below, but these have drawbacks of their own. The functionality could be easily extended later, depending on how things play out.</p>
<h2 id="alternatives-10"><a class="header" href="#alternatives-10">Alternatives</a></h2>
<h3 id="alternative-a-enumerated-primitive-values"><a class="header" href="#alternative-a-enumerated-primitive-values">Alternative A: Enumerated primitive values</a></h3>
<p>We previously proposed, in <a href="https://github.com/cedar-policy/rfcs/blob/enums/text/0013-schema-enums.md">RFC 13</a>, declaring a finite set of primitive values (strings, numbers, etc.) as an enumerated type. The <a href="https://github.com/cedar-policy/rfcs/pull/13#issuecomment-1786170514">killer objection to the RFC</a> is that it introduces subtyping (you want to use the enumerated type of string as both the enumeration and the string, e.g., with <code>like</code>), which is a significant complication for policy analysis. The present proposal is not problematic for analysis as enumerated entities can be encoded like any entity, but with added ground constraints limiting what form their UIDs can take on.</p>
<h3 id="alternative-b-enumeration-as-a-distinct-concept"><a class="header" href="#alternative-b-enumeration-as-a-distinct-concept">Alternative B: Enumeration as a distinct concept</a></h3>
<p>Rather than specify a particular entity type as an enumeration, we could define a new concept of enumeration as another kind of primitive type. Here is a notional schema:</p>
<pre><code>enum type Color = Red | Blue | Green;
entity Task {
  name: String,
  status: Color
};
</code></pre>
<p>Here is a notional policy:</p>
<pre><code>permit(
    principal,
    action == Action::"UpdateTask",
    resource)
when {
    resource.status != Color.Red
};
</code></pre>
<p>This syntax is similar to what's provided for Java <code>enum</code>s.</p>
<p>The benefit of this approach is that it may feel a little more natural than representing a concept, like a color, as a set of legal entity values. It would also be easy to encode this approach in a policy analysis.</p>
<p>The main drawback of this approach is that it introduces a new primitive type to the language that does not make much sense without schemas. Recall that for Cedar, validation with a schema is <em>optional</em>. We'd allow users to include any random enumerated identifiers (like Scheme-style <em>symbols</em>) in policies which, without validation, would fail equality checks at run-time.</p>
<p>The proposed approach that lists particular entity values as an enumeration makes no change to the language, leveraging the existing entity type concept. So policies without schemas still make sense. With the added schema, there is additional benefit when validating and constructing reasonable policies.</p>
<h3 id="alternative-c-enumerated-entities-with-hierarchy"><a class="header" href="#alternative-c-enumerated-entities-with-hierarchy">Alternative C: Enumerated entities with hierarchy</a></h3>
<p>Enumerated entities as proposed are limited in their functionality and specificity. We could extend them. For example:</p>
<pre><code>entity Application enum [ "TinyTodo" ];
entity RequestEntity enum [ "Principal", "Resource" ] in [ Application ];
entity User in [ Application ];
action CreateList
    appliesTo { principal: [User], resource: [Application] };
action GetLists
    appliesTo { principal: [User, RequestEntity::"Principal"],
                resource: [Application]};
</code></pre>
<p>This differs from some earlier examples in the following ways:</p>
<ol>
<li>Enumerated entities can have parents that are enumerated entity values, and can be parents of other enumerated entity values; both cases are shown in the definition of <code>RequestEntity</code></li>
<li>Enumerated entities can appear as <em>singleton types</em>, e.g., as <code>RequestEntity::"Principal"</code> in the definition of action <code>GetLists</code>.</li>
</ol>
<p>Both of these extensions are similar to what's available for <code>Action</code>s right now, but generalized to arbitrary entity types. You could also imagine enumerated entity types having attributes, as has been anticipated for <code>Action</code>s.</p>
<p>One drawback of this Alternative is that it creates added complication for both the validator (e.g., to handle singleton types) and the analyzer (e.g., to deal with the more general hierarchy constraints).</p>
<p>Another drawback is that it adds complication to the entity store: Once you add hierarchy constraints and attributes, you need to create actual entities to include with policy requests, by extracting them from the schema at request-time. The RFC as proposed does not require that.</p>
<p>The good news is that this Alternative is a strict generalization of the RFC as proposed, which means if we agree to the current proposal we can later upgrade to some or all of this Alternative without incurring a breaking change.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="explicit-unspecified-entities"><a class="header" href="#explicit-unspecified-entities">Explicit Unspecified Entities</a></h1>
<h2 id="related-issues-and-prs-11"><a class="header" href="#related-issues-and-prs-11">Related issues and PRs</a></h2>
<ul>
<li>Related RFCs: <a href="https://github.com/cedar-policy/rfcs/pull/35">RFC35</a>, <a href="https://github.com/cedar-policy/rfcs/pull/47">RFC47</a></li>
<li>Implementation PR(s):</li>
</ul>
<h2 id="timeline-12"><a class="header" href="#timeline-12">Timeline</a></h2>
<ul>
<li>Started: 2024-02-27</li>
<li>Accepted: 2024-05-28</li>
<li>Landed: 2024-06-19 on <code>main</code> (<a href="https://github.com/cedar-policy/cedar/pull/983">#983</a>)</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-12"><a class="header" href="#summary-12">Summary</a></h2>
<p>Cedar currently supports <em>unspecified entities</em>, which are entities of a special, unique type that have no attributes, and are not ancestors or descendants of any other entity in the store. Unspecified entities are intended to act as placeholders for entities that don’t influence authorization (see examples below).</p>
<p>The current implementation of unspecified entities results in several corner cases in our code (especially the validator), which have been difficult to maintain (see discussion on <a href="https://github.com/cedar-policy/cedar/pull/603">this recent PR</a>). The concept of unspecified entities is (in our opinion) confusing for users, and will only become more confusing once we stabilize the partial evaluation experimental feature, which allows “unknown” entities that are subtly different from “unspecified” entities.</p>
<p>This RFC proposes to drop Cedar support for unspecified entities, instead recommending that users create their own application-specific entity types that act like unspecified entities.</p>
<h2 id="basic-example-9"><a class="header" href="#basic-example-9">Basic example</a></h2>
<p>Consider a "createFile" action that can be used by any <code>User</code>, as encoded in the following policy:</p>
<pre><code>permit(principal is User, action == Action::"createFile", resource);
</code></pre>
<p>When making an authorization request for this action, the principal should be a <code>User</code>, and the context can store information about the file to create, but it is unclear what the resource should be.
In fact, given the policy above, the resource <em>doesn't matter</em>.
In this case, a Cedar user may want to make the authorization request with a “dummy” resource; as of Cedar version 3.x, this is what <strong>unspecified entities</strong> are for.</p>
<p>Now consider a "createAccount" action. It's unclear what principal <em>or</em> resource should be used with this action. The approach above can be extended to this case too: make the action apply to an unspecified principal and resource. But now "unspecified" entities are being used to represent multiple distinct concepts: a file store, (unidentified) users creating an account, and a system that manages accounts.</p>
<p>This RFC proposes that users should instead explicitly create these "dummy" entities in an application-specific manner. For this example, the user should create entities of three types: <code>FileSystem</code>, <code>UnauthenticatedUser</code>, and <code>AccountManager</code>. The first will act as the principal for a "createFile" request, and the second and third will act as the principal and resource for a "createAccount" request.</p>
<p>This is (arguably) the approach we used in the <a href="https://github.com/cedar-policy/cedar-examples/tree/release/3.0.x/tinytodo">TinyTodo application</a>: we made a special <code>Application::“TinyTodo”</code> entity to act as the resource for the “CreateList” and “GetLists” actions.
This alternative is also in line with <a href="https://cedar-policy.slack.com/archives/C0547KH7R19/p1706656288284189">our previous suggestion</a> to use an application-specific <code>Unauthenticated</code> type to represent "unauthenticated" users, rather than using unspecified entities.</p>
<h2 id="motivation-12"><a class="header" href="#motivation-12">Motivation</a></h2>
<p>Unspecified entities are a confusing concept, as evidenced by messy special casing in our own code and multiple RFCs to refine their behavior (<a href="https://github.com/cedar-policy/rfcs/pull/35">RFC35</a>, <a href="https://github.com/cedar-policy/rfcs/pull/47">RFC47</a>).
We expect that this concept will only become more confusing once we stabilize the partial evaluation experimental feature, which allows “unknown” entities that are subtly different from "unspecified" entities, despite sharing similar names.</p>
<p>Unspecified entities also lead to two sharp corners in our public API:</p>
<ol>
<li>Omitting a <code>appliesTo</code> field in the schema (or setting it to null) means that an action applies only to unspecified entities, while using an empty list means that it applies to no entities. There is no way to say that an action applies to both unspecified entities and other types of entities. For more discussion, see <a href="https://github.com/cedar-policy/rfcs/pull/35">RFC35</a>. (Note: RFC35 has been closed in favor of the current RFC.)</li>
<li>It is unclear how we should create <code>Request</code>s that use both unspecified and unknown entities. This has not been an issue so far since partial evaluation and its APIs are experimental, but we are looking to stabilize them soon. Currently the best (although not ideal) proposal is to use a builder pattern for <code>Request</code>s (e.g., <code>request.principal(Some(User::"alice"))</code> sets the principal field of a request). To set a field to be “unspecified” users could pass in <code>None</code> instead of <code>Some(_)</code>; to set a field to be unknown users would not call the field constructor at all.</li>
</ol>
<h3 id="aside-unspecified-vs-unknown"><a class="header" href="#aside-unspecified-vs-unknown">Aside: Unspecified vs. unknown</a></h3>
<p>Unspecified and unknown entities are both pre-defined "dummy" entities that act like any other entity, as long as they are unused or only used in a trivial way (e.g., <code>principal == principal</code>).
If a policy uses an <em>unknown entity</em> in a non-trivial way, then evaluation will produce a residual.
If a policy uses an <em>unspecified entity</em> in a non-trivial way, then evaluation will produce an error.</p>
<h2 id="detailed-design-12"><a class="header" href="#detailed-design-12">Detailed design</a></h2>
<h3 id="status-quo"><a class="header" href="#status-quo">Status quo</a></h3>
<p>As of Cedar v3.x, the only way to construct an unspecified entity is by passing <code>None</code> as a component when building a <a href="https://docs.rs/cedar-policy/latest/cedar_policy/struct.Request.html"><code>Request</code></a>.
So a request for the "createFile" action above might look like:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>{
    principal: Some(User::"alice"),
    action: Some(Action::"createFile"),
    resource: None,
    ...
}
<span class="boring">}</span></code></pre></pre>
<p>In the schema, the only way to say that an action applies to an unspecified entity is by omitting the relevant <code>appliesTo</code> field.
For example, the following schemas specify that the "createFile" action applies (only) to an unspecified resource.</p>
<p>Cedar schema syntax (<a href="https://github.com/cedar-policy/rfcs/blob/main/text/0024-schema-syntax.md">RFC 24</a>):</p>
<pre><code>action createFile
  appliesTo { principal: [User] };
</code></pre>
<p>Cedar schema JSON syntax:</p>
<pre><code class="language-json">"createFile": {
    "appliesTo": {
        "principal": ["User"]
    }
}
</code></pre>
<h3 id="proposal"><a class="header" href="#proposal">Proposal</a></h3>
<p>The proposal is simple: stop allowing the syntax above. The <code>Request</code> constructor will no longer accept optional arguments and schemas will no longer support missing <code>appliesTo</code> fields. The <code>Request</code> constructor API will be changed to require an <code>EntityUid</code> (instead of <code>Option&lt;EntityUid&gt;</code>) for the principal/action/resource, requiring code changes in programs using Cedar's Rust APIs. The schema APIs will not change, but omitting an <code>appliesTo</code> field will result in a parse error.</p>
<h3 id="relation-to-rfc35"><a class="header" href="#relation-to-rfc35">Relation to RFC35</a></h3>
<p>This RFC combines nicely with the (accepted) <a href="https://github.com/cedar-policy/rfcs/pull/53">RFC53 (Enumerated Entity Types)</a>, which allows users to fix the instances for a particular entity type. This means that custom "unspecified" entities can be easily restricted to a small set of possible entities. For example, RFC53 allows specifying that only <code>Application::"TinyTodo"</code> is valid, and no other <code>Application::"eid"</code>.</p>
<h3 id="upgrade-strategy"><a class="header" href="#upgrade-strategy">Upgrade strategy</a></h3>
<p>We appreciate that this RFC proposes a breaking change for Cedar's users, and the upgrade path is non-trivial  because it requires users to look carefully at their applications, and decide what they should use <em>instead</em> of unspecified entities.
To help, while implementing this RFC, we plan to develop a <strong>blog post</strong> with examples of applications where you may have used an "unspecified" entity, and what we think you should use instead (suggestions for examples are welcome!).</p>
<p>We also plan to provide APIs (hidden behind a flag, like our experimental features) for the following operations, with the same API and behavior that was available in 3.x.</p>
<ul>
<li>Parsing a schema in the Cedar schema format</li>
<li>Parsing a schema in the Cedar JSON schema format</li>
<li>Constructing a request</li>
</ul>
<p>This will allow services that build on top of Cedar (e.g., <a href="https://aws.amazon.com/verified-permissions/">Amazon Verified Permissions</a>) to handle this upgrade for their customers invisibly.
The implementation will follow the approach outlined in <a href="0055-remove-unspecified.html#alternative-b---maintain-the-status-quo-but-clean-up-the-implementation">Alternative B</a>.
However, <em>we will not maintain these APIs indefinitely</em> so you will need to support the new changes eventually. Please reach out to us if there's a way that we can help.</p>
<h2 id="alternatives-11"><a class="header" href="#alternatives-11">Alternatives</a></h2>
<h3 id="alternative-a---predefine-a-special-unspecified-entity-type"><a class="header" href="#alternative-a---predefine-a-special-unspecified-entity-type">Alternative A - Predefine a special "unspecified" entity type</a></h3>
<p>Continue to support unspecified entities, but re-brand them as "default" entities, with the intuition that you should use them when you want <em>some default value</em> to pass into an authorization request.
This alternative proposes to give an explicit name to the unspecified entity type (<code>__cedar::Default</code>) and to require this name to be used in requests and schemas that use this type.</p>
<p>Under this proposal, the schema definition for the "createFile" action from above would look like:</p>
<pre><code>action createFile
  appliesTo { principal: [User], resource: [__cedar::Default] };
</code></pre>
<p>and a (pseudo-syntax) request for this action might be:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>{
    principal: EntityUid(User::"alice"),
    action: EntityUid(Action::"createFile"),
    resource: Default,
    ...
}
<span class="boring">}</span></code></pre></pre>
<p>where the type of the <code>Request</code> constructor is:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum RequestEntity {
    Default,
    Unknown,
    EntityUid(EntityUid)
}

pub fn new(
        principal: RequestEntity,
        action: RequestEntity,
        resource: RequestEntity,
        context: Context,
        schema: Option&lt;&amp;Schema&gt;,
    ) -&gt; Result&lt;Self, RequestValidationError&gt;
...
<span class="boring">}</span></code></pre></pre>
<p>(<em>Note</em>: the <code>Unknown</code> variant may be hidden behind the "partial-eval" experimental flag, depending on when this RFC is implemented.)</p>
<p>Users will not be allowed to include entities of type <code>__cedar::Default</code> in the store, which ensures that these entities will never have attributes or ancestors/descendants, which are properties we will rely on during validation.
Users will not be allowed to reference the type <code>__cedar::Default</code> in their policies (so neither <code>principal == __cedar::Default::"principal"</code> nor <code>principal is __cedar::Default</code> are allowed).
Users do not need to add <code>__cedar::Default</code> to their schemas (and it will be an error if they do) because <code>__cedar::Default</code> is defined automatically.
Finally, users cannot create entity uids with type <code>__cedar::Default</code>, which prevents using default entities with the <code>RequestEntity::EntityUid</code> constructor.</p>
<h4 id="naming-specifics"><a class="header" href="#naming-specifics">Naming specifics</a></h4>
<p>The names <code>RequestEntity</code> and <code>__cedar::Default</code> are both subject to change.</p>
<p>For the latter, we have agreed that we want to use the <code>__cedar</code> prefix (reserved as part of <a href="https://github.com/cedar-policy/cedar/pull/557">cedar#557</a> in v3.1), but the exact type name is up for debate.
Options we've considered include:</p>
<ul>
<li><code>None</code></li>
<li><code>Null</code></li>
<li><code>Ghost</code></li>
<li><code>Dummy</code></li>
<li><code>Empty</code></li>
<li><code>Irrelevant</code></li>
<li><code>Generic</code></li>
</ul>
<p>Here are some options we’ve ruled out:</p>
<ul>
<li><code>Any</code>: possibility to confuse the scope condition <code>principal</code> with <code>principal is __cedar::Any</code>. The first applies to any principal, while the latter applies to only the default entity.</li>
<li><code>Arbitrary</code>: same issue as "any"</li>
<li><code>Unspecified</code>: potential for confusion with partial evaluation "unknown"</li>
<li><code>Mock</code>: implies that this entity type should be used for debugging/testing</li>
</ul>
<h4 id="discussion-notes"><a class="header" href="#discussion-notes">Discussion notes</a></h4>
<p>We considered this alternative seriously, and it even became the main proposal for a period of time.
But ultimately we decided that this alternative feels like a temporary solution, and we would eventually want to get rid of unspecified/default entities anyways.</p>
<p>Here's a nice (lightly edited) summary from @max2me:</p>
<blockquote>
<p>Both the main proposal and Alternative A are breaking changes, so I'd rather go a step forward and require customers to update schema, code, and policies once for the benefit of a brighter future (Alternative A would require customers to update just schema and code, yet all the same testing will have to occur).</p>
<p>My concerns with Alternative A:</p>
<ul>
<li>Lack of symmetry -- you omit something in the policy and yet explicitly mention it in the authorization code and schema. This leads to a fragmented experience of working with Cedar as a technology.</li>
<li>Surprise factor -- I suspect that most customers who leave principal/resource unscoped in policies will not realize that in addition to all the entities they reference in their code, there is a hidden default type.</li>
</ul>
<p>In my opinion, occasional duplication of policies and the need to define your own default type is a small cost to pay for the overall simplicity and cohesiveness of the system.</p>
</blockquote>
<h3 id="alternative-b---maintain-the-status-quo-but-clean-up-the-implementation"><a class="header" href="#alternative-b---maintain-the-status-quo-but-clean-up-the-implementation">Alternative B - Maintain the status quo, but clean up the implementation</a></h3>
<p>Pre-define the <code>__cedar::Default</code> entity type as in Alternative A, but do not allow users to reference it directly.
Instead, update the underlying implementation to use the new type while leaving the current API as-is.
We took this approach in the <a href="https://github.com/cedar-policy/cedar-spec/tree/main/cedar-lean">Lean model</a> to avoid special handling for unspecified entities, and it seems to have worked out well.
Differential testing has given us confidence that it leads to the same behavior as our current implementation.</p>
<p><em>Note</em>: This alternative should result in no changes from the user’s perspective. If it does result in changes (e.g., to validation results) then this was unintentional behavior of our current implementation, and should be treated as a bug fix.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-multiplication-in-cedar"><a class="header" href="#general-multiplication-in-cedar">General multiplication in Cedar</a></h1>
<h2 id="related-issues-and-prs-12"><a class="header" href="#related-issues-and-prs-12">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: related to <a href="https://github.com/cedar-policy/rfcs/pull/50">RFC 50</a></li>
<li>Implementation PR(s): <a href="https://github.com/cedar-policy/cedar/pull/702">cedar#702</a></li>
</ul>
<h2 id="timeline-13"><a class="header" href="#timeline-13">Timeline</a></h2>
<ul>
<li>Started: 2024-03-07</li>
<li>Accepted: 2024-03-15</li>
<li>Landed: 2024-03-20 in <code>cedar-policy</code></li>
<li>Released: 2024-03-29 in <code>cedar-policy</code> v3.1.2</li>
</ul>
<h2 id="summary-13"><a class="header" href="#summary-13">Summary</a></h2>
<p>Allow multiplication of arbitrary expressions (that evaluate to Long), not just
multiplication of an expression by a constant.</p>
<h2 id="basic-example-10"><a class="header" href="#basic-example-10">Basic example</a></h2>
<pre><code>permit(principal, action, resource) when {
    context.foo * principal.bar &gt;= 100
};
</code></pre>
<h2 id="motivation-13"><a class="header" href="#motivation-13">Motivation</a></h2>
<p>Today, Cedar only supports multiplication of two operands if (at least) one
operand is a constant.
In the more general n-ary (chained) multiplication case, Cedar requires that at
most one operand is a non-constant, but allows the constants and non-constant to
appear in any order.</p>
<ul>
<li>This creates some confusion for Cedar users. No other popular programming
language has this restriction on multiplication.</li>
<li>This leads to bugs and confusing behavior. To enforce this restriction,
Cedar's internal AST node for multiplication only supports multiplying an
expression by a constant. But this requires the Cedar parser to re-associates
(and re-order) operands in a chained multiplication, which leads to confusion
and problems as described in <a href="https://github.com/cedar-policy/rfcs/pull/50">RFC 50</a>.</li>
<li>This limits the power of Cedar by preventing users from writing policies
involving multiplication where neither operand is known at policy-authoring
time.</li>
</ul>
<p>This RFC proposes to relax all of these restrictions and allow multiplication
of arbitrary expressions (that evaluate to Long).
In other words, multiplication will be treated just like addition: <code>*</code> will be
valid in all positions and situations where <code>+</code> is valid today.</p>
<h2 id="detailed-design-13"><a class="header" href="#detailed-design-13">Detailed design</a></h2>
<p>This will actually simplify the evaluator code, validator code, and internal AST.
Multiplication will become an ordinary <code>BinaryOp</code>, and no longer need a special
AST node.
The evaluator and validator can handle multiplication in the same way as
addition and in the same code paths.</p>
<p>With this RFC, the policy parser becomes strictly more permissive:
All policies that currently parse will still parse, plus additional policies
that used to produce parse errors will now parse as well.
There are edge cases where evaluations that do not overflow today could result
in overflows after this RFC -- see Drawbacks below.</p>
<h2 id="drawbacks-13"><a class="header" href="#drawbacks-13">Drawbacks</a></h2>
<p>One motivation for the original restriction on multiplication was to make SMT
analysis of Cedar policies easier.
However, presuming that the SMT analysis uses bitvector theory to analyze
operations on Cedar Longs, multiplication by a general expression is not much
more expensive than multiplication by an arbitrary constant (ignoring special
cases such as 0 or constant powers of 2).
Some multiplication expressions will be expensive to analyze (computationally),
but that is already true for some other kinds of Cedar expressions that don't
involve multiplication.
In general, we'd prefer to use a linter to warn users about (these and other)
expensive expressions, rather than use restrictions on the Cedar language.</p>
<p>This RFC firmly closes the door on changing Cedar's default numeric type to
bignum. However, that door is already basically closed.
Also, we could still introduce bignums as an extension type (with their own
separate multiplication operation) in the future.</p>
<p>This RFC has essentially no interaction with any other currently pending or
active RFC, except for <a href="https://github.com/cedar-policy/rfcs/pull/50">RFC 50</a> which it replaces and makes obsolete.</p>
<p>There are edges cases where evaluations that do not overflow today could result
in overflows after this RFC.
One example is an expression <code>CONST * CONST * context.value</code> for large <code>CONST</code>
when <code>context.value == 0</code>.
Today's parser will produce the internal AST <code>(mul (mul context.value CONST) CONST)</code>
which will not overflow when <code>context.value == 0</code>, while this RFC would produce
the internal AST <code>(mul (mul CONST CONST) context.value)</code> which would overflow
even when <code>context.value == 0</code>.
This is because, like <a href="https://github.com/cedar-policy/rfcs/pull/50">RFC 50</a>, this RFC proposes to left-associate
multiplication and not to reorder operands, in contrast to the current Cedar
parser.</p>
<p>This edge case seems very unlikely for users to hit (as it requires a
multiplication by two large constants), and this RFC's proposed behavior is
undoubtedly more intuitive, as multiplication is left-associative in most
programming languages.</p>
<h2 id="alternatives-12"><a class="header" href="#alternatives-12">Alternatives</a></h2>
<p><a href="https://github.com/cedar-policy/rfcs/pull/50">RFC 50</a> is one alternative which fixes some issues with chained multiplication
without (significantly) relaxing Cedar's restrictions on multiplication
operations.
This RFC's proposal leads to simpler evaluation and validation code than RFC 50,
and also makes the Cedar language simpler and easier to understand for users.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="extended-has-operator"><a class="header" href="#extended-has-operator">Extended <code>has</code> Operator</a></h1>
<h2 id="related-issues-and-prs-13"><a class="header" href="#related-issues-and-prs-13">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues:</li>
<li>Implementation PR(s):</li>
</ul>
<h2 id="timeline-14"><a class="header" href="#timeline-14">Timeline</a></h2>
<ul>
<li>Started: 2024-04-05</li>
<li>Accepted: 2024-05-21</li>
<li>Landed: TBD</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-14"><a class="header" href="#summary-14">Summary</a></h2>
<p>This RFC proposes to extend the syntax of the <code>has</code> operator to check for the presence of all attributes in an access path.</p>
<h2 id="basic-example-11"><a class="header" href="#basic-example-11">Basic example</a></h2>
<p>Suppose that entites of type <code>User</code> have an optional <code>contactInfo</code> attribute of type <code>{email: String, address?: {street?: String, zip?: String, country: String}}</code>. To safely access the <code>zip</code> field of a user in a policy, we write a chain of <code>has</code> checks as follows:</p>
<pre><code>permit(
  principal is User,
  action == Action::"preview",
  resource == Movie::"Blockbuster"
) when {
  principal has contactInfo &amp;&amp;
  principal.contactInfo has address &amp;&amp;
  principal.contactInfo.address has zip &amp;&amp;
  principal.contactInfo.address.zip == "90210"
};
</code></pre>
<p>This RFC proposes to extend the syntax of the <code>has</code> operator so that this chain of checks can be written more succinctly as follows:</p>
<pre><code>permit(
  principal is User,
  action == Action::"preview",
  resource == Movie::"Blockbuster"
) when {
  principal has contactInfo.address.zip &amp;&amp;
  principal.contactInfo.address.zip == "90210"
};
</code></pre>
<p>The expression <code>principal has contactInfo.address.zip</code> evaluates to true when all the attributes in the given access path are present.</p>
<h2 id="motivation-14"><a class="header" href="#motivation-14">Motivation</a></h2>
<p>Long chains of <code>has</code> checks are tedious to write and hard to read. The extended <code>has</code> operator replaces these chains with a single constraint that is easier to read and write.</p>
<h2 id="detailed-design-14"><a class="header" href="#detailed-design-14">Detailed design</a></h2>
<p>This RFC proposes to desugar the new <code>has</code> syntax into the corresponding chain of basic <code>has</code> checks in the CST -&gt; AST and EST -&gt; AST converter.  This requires extending the parser, CST, and EST to support the new syntax; and changing the CST -&gt; AST and EST -&gt; AST converters to implement the desugaring. It should be possible to share the core desugaring code between the two converters.</p>
<p>No other components need to change. In particular, validator, evaluator, and Lean models remain the same.</p>
<h3 id="extending-the-syntax-1"><a class="header" href="#extending-the-syntax-1">Extending the syntax</a></h3>
<p>We extend the grammar as follows:</p>
<pre><code>Relation ::= ... | Add 'has' (IDENT['.' IDENT]* | STR) |  ...
</code></pre>
<p>Note that this extension works only for attribute names that are valid Cedar identifiers. It cannot be used with attribute names that are not valid Cedar identifiers. For example, we cannot write <code>principal has "contact info".address.zip</code>; this check has to be expressed as <code>principal has "contact info" &amp;&amp; principal["contact info"] has address.zip</code>. Arbitrary attribute names can be supported in the future if there is demand for it.</p>
<h3 id="desugaring-the-extended-syntax"><a class="header" href="#desugaring-the-extended-syntax">Desugaring the extended syntax</a></h3>
<p>The following Lean code shows how to perform the desugaring given an expression, an attribute, and a list of attribute:</p>
<pre><code>def desugarHasChainStep
  (acc : Expr × Expr)
  (attr : Attr) : Expr × Expr :=
  (Expr.getAttr acc.fst attr,
   Expr.and acc.snd (Expr.hasAttr acc.fst attr))

def desugarHasChain
  (x : Expr)
  (attr : Attr)
  (attrs : List Attr) : Expr :=
  (attrs.foldl
    desugarHasChainStep
      (Expr.getAttr x attr,
       Expr.hasAttr x attr)).snd
</code></pre>
<p>Here are some examples of desugared ASTs:</p>
<pre><code>#eval desugarHasChain (Expr.var .principal) "contactInfo" []

Expr.hasAttr (Expr.var .principal) "contactInfo"

#eval desugarHasChain (Expr.var .principal) "contactInfo" ["address"]

Expr.and
  (Expr.hasAttr (Expr.var .principal) "contactInfo")
  (Expr.hasAttr
    (Expr.getAttr (Expr.var .principal) "contactInfo")
    "address")

#eval desugarHasChain (Expr.var .principal) "contactInfo" ["address", "zip"]

Expr.and
  (Expr.and
    (Expr.hasAttr (Expr.var .principal) "contactInfo")
    (Expr.hasAttr
      (Expr.getAttr (Expr.var .principal) "contactInfo")
      "address"))
  (Expr.hasAttr
    (Expr.getAttr
      (Expr.getAttr (Expr.var .principal) "contactInfo")
      "address")
    "zip")
</code></pre>
<h2 id="drawbacks-14"><a class="header" href="#drawbacks-14">Drawbacks</a></h2>
<ol>
<li>
<p>This feature requires extending the grammar, CST, EST, CST -&gt; AST, and CST -&gt; EST converters. This extension will be a breaking change to the EST. We have to either modify the EST <code>hasAttr</code> node to include an additional List argument, or introduce a separate node to represent the extended syntax. Either change may break code that operates on the EST.</p>
</li>
<li>
<p>If we choose <em>not</em> to modify the EST, and implement a CST -&gt; EST conversion using the above algorithm, then the EST loses information.  It will no longer be possible to recover the original policy syntax from the EST.</p>
</li>
</ol>
<h2 id="alternatives-13"><a class="header" href="#alternatives-13">Alternatives</a></h2>
<p>We considered several variants of the extended syntax that would support arbitrary attribute names. For example, <code>principal has contactInfo."primary address".zip</code> or <code>principal has ["contactInfo"]["primary address"]["zip"]</code>.</p>
<p>We decided that the alternatives were less intuitive and readable. If needed, we can support arbitrary attribute names in the future without causing any further breaking changes to the EST.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="embedded-attribute-maps"><a class="header" href="#embedded-attribute-maps">Embedded attribute maps</a></h1>
<h2 id="related-issues-and-prs-14"><a class="header" href="#related-issues-and-prs-14">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: <a href="https://github.com/cedar-policy/cedar/issues/305">#305</a></li>
<li>Supercedes <a href="https://github.com/cedar-policy/rfcs/pull/66">RFC 66</a></li>
<li>Implementation PR(s): (leave this empty)</li>
</ul>
<h2 id="timeline-15"><a class="header" href="#timeline-15">Timeline</a></h2>
<ul>
<li>Started: 2024-05-29</li>
<li>Accepted: 2024-07-26</li>
<li>Rejected: 2024-09-11; see RFC 82</li>
</ul>
<h2 id="summary-15"><a class="header" href="#summary-15">Summary</a></h2>
<p>This RFC proposes to extend the Cedar type system with the ability to include <em>embedded attribute maps</em> (EA-maps for short) in entity types, with the primary goal of supporting a full-featured encoding for <em>tags</em>. For evaluation purposes, EA-maps have the same programming interface as records: keys are like record attributes and values are like attribute values. The difference is in how they are validated: the keys of EA-maps need not be enumerated in advance, as is required with record attributes, and all values must have the same type. Moreover, EA-maps are treated by the validator as second-class, meaning valid usage scenarios are somewhat restricted.</p>
<p>The main body of this RFC proposes that EA-map keys must be <em>literals</em> when used to look up a key's value, just like record attributes, but Alternative A generalizes this proposal to allow keys to be dynamically computed. Alternative A thus adds expressive power but also implementation cost.</p>
<h3 id="basic-example-12"><a class="header" href="#basic-example-12">Basic example</a></h3>
<p>Here is a schema defining two entities, each of which contains embedded attribute maps (EA-maps, for short), used to implement tags.</p>
<pre><code>entity User = {
  jobLevel: Long,
  authTags: { ?: Set&lt;String&gt; },
};
entity Document = {
  owner: User,
  policyTags: { ?: Set&lt;String&gt; },
};
</code></pre>
<p>The <code>User</code> and <code>Document</code> entities each have an attribute of type <code>{ ?: Set&lt;String&gt; }</code>, an EA-map, implementing tags whose values are sets of strings. The syntax for EA-map types evokes a record, per the curly braces, but without named attributes; by providing just a <code>?</code> followed by a colon and a type, we indicate an unspecified number of optional attributes that have values of that type (here, <code>Set&lt;String&gt;</code>).</p>
<p>Here's a policy that conforms to this schema:</p>
<pre><code>permit (
  principal is User,
  action == Action::"writeDoc",
  resource is Document)
when {
  document.owner == principal ||
    (principal.jobLevel &gt; 6 &amp;&amp;
    resource.policyTags has "write" &amp;&amp;
    principal.authTags has "write" &amp;&amp;
    resource.policyTags["write"].containsAny(principal.authTags["write"]))
};
</code></pre>
<p>This policy states that for a <code>User</code> to carry out the <em>writeDoc</em> action on a <code>Document</code>, the user must own the document, or else the user's job level must be at least 6 and the document and the user must each have a <code>write</code> tag in their EA-maps, where at least one of the user's write-tag's values must be present in the document's write-tag's values.</p>
<h2 id="detailed-design-15"><a class="header" href="#detailed-design-15">Detailed design</a></h2>
<p>Neither the Cedar evaluator/authorizer, the JSON format for entities, nor the JSON or natural syntax for policies needs to change to support embedded attribute maps. This is because the notion of EA-map only arises at validation time, not evaluation time. At evaluation time, EA-maps are represented as records and support the same operations. In other words, for policy writers who do not use validation, there is no need for EA-maps: You can just use records. To support changes to the validator, the Cedar schema format, the validator, and the schema-based entity parser need to change to account for a new <code>{ ?: T }</code> type.</p>
<h3 id="schema"><a class="header" href="#schema">Schema</a></h3>
<p>EA-maps have type <code>{ ?: T }</code>, where <code>T</code> is the type of values. Only entity attributes can be given type <code>{ ?: T }</code>, and <code>T</code> cannot directly mention another EA-maps type.</p>
<p>We extend schemas as follows to support the new EA-maps type. Here's the natural syntax:</p>
<pre><code>Entity           := 'entity' Idents ['in' EntOrTyps] [['='] EntityRecType] ';'
EntityRecType    := '{' [EntityAttrDecls] '}'
EntityAttrDecls  := Name ['?'] ':' [Type | EAMapsType] [',' | ',' EntityAttrDecls]
EAMapsType       := '{' '?' ':' Type '}'
Type             := PRIMTYPE | Path | SetType | RecType
</code></pre>
<p>In essence: We alter the definition of entity types to include attributes with type <code>{ ?: T }</code>, where <code>T</code> is any type not mentioning another EA-maps type. Not shown here are the productions for <code>RecType</code> and <code>AttrDecls</code>, which apply to records rather than entities. These productions are unchanged---normal records may not include attributes with <code>{ ?: T }</code> types.</p>
<p>The JSON syntax for schemas specifies EA-maps as records with a <code>default</code> element, rather than an <code>attributes</code> element. Doing so leverages the analogy that EA-maps are like records in which all attributes are optional, with the same type. Here's our introductory example schema in this format:</p>
<pre><code>"entityTypes": {
    "User" : {
        "shape" : {
            "type" : "Record",
            "attributes" : {
                "jobLevel" : {
                    "type" : "Long"
                },
                "authTags" : {
                    "type" : "Record",
                    "default": {
                        "type" : "Set",
                        "element": { "type": "String" }
                    }
                }
            }
        }
    },
    "Document" : {
        "shape" : {
            "type" : "Record",
            "attributes" : {
                "owner" : {
                    "type" : "Entity",
                    "name" : "User"
                },
                "policyTags" : {
                    "type" : "Record",
                    "default": {
                        "type" : "Set",
                        "element": { "type": "String" }
                    }
                }
            }
        }
    }
}
</code></pre>
<p>Legal schemas only allow records with <code>default</code> to appear as direct entity attributes, and likewise restricts the <code>type</code> associated with <code>default</code> to not include <code>default</code>-containing record types. Records with a <code>default</code> element cannot also have an <code>attributes</code> element (and so cannot have named attributes).</p>
<h3 id="policies-entities-and-evaluation"><a class="header" href="#policies-entities-and-evaluation">Policies, entities, and evaluation</a></h3>
<p>EA-maps support all of the same operations as records. Suppose that <code>E</code> is an expression of type <code>{ ?: T }</code>. Then expression <code>E has F</code> will check whether <code>E</code> has key <code>F</code>, evaluating to <code>true</code> if so and <code>false</code> otherwise. Expression <code>E.F</code> or <code>E["F"]</code> will retrieve the value associated with key <code>F</code> if <code>F</code> is present, signaling an error if it is not.</p>
<p>As a result, within the evaluator we can represent EA-maps as records, so the evaluator code does not need to change. In particular, EA-maps with keys <code>F1</code> ... <code>Fn</code> and associated values <code>V1</code> .. <code>Vn</code> are internally represented as records <code>{ F1: V1, ..., Fn: Vn }</code>. Similarly, EA-maps are represented as records in the JSON entity format. For example, here is entity representing <code>User::"Alice"</code> which conforms to our example schema:</p>
<pre><code>    {
        "uid": { "type": "User", "id": "alice" },
        "attrs": {
            "jobLevel": 5,
            "authTags": {
                "write": ["blue", "red"],
                "read": ["blue", "red", "green"]
            }
        },
        "parents": []
    }
</code></pre>
<p>Note that there is no way to represent a EA-maps <em>literal</em>. That is, you cannot write something like <code>{ write: ["blue", "red"]}</code> in a policy, like you might for a record literal. This is because EA-maps are always attached to entities, and entities themselves have no literal syntax.</p>
<h3 id="validating-policies"><a class="header" href="#validating-policies">Validating policies</a></h3>
<p>We extend the way the policy validator handles optional record attributes in order to support embedded attribute maps.</p>
<h4 id="capabilities"><a class="header" href="#capabilities">Capabilities</a></h4>
<p>Background: While typechecking an expression involving records or entities with optional attributes, the validator tracks <em>capabilities</em>. These represent the attribute-accessing expressions that are sure to succeed. If <code>principal</code> has type <code>User</code> and <code>User</code> has an optional <code>Boolean</code> attribute <code>sudo</code>, then the expression <code>principal.sudo</code> only validates if <code>principal.sudo</code> is present in the <em>current capability set</em>. Capabilities are added to that set by a preceding expression of the form <code>principal has sudo</code>, e.g., as in <code>principal has sudo &amp;&amp; principal.sudo</code>.</p>
<p>Capability tracking must be generalized to support EA-maps. In particular, an entity attribute of type <code>{ ?: T }</code> should be treated as a record with optional attributes, and <code>has</code> checks on its keys should update the capability set. For our introductory example, consider the following expression</p>
<pre><code>  resource.policyTags has "write" &amp;&amp; // (1)
  principal.authTags has "write" &amp;&amp;  // (2)
  resource.policyTags["write"].containsAny(principal.authTags["write"]) // (3)
</code></pre>
<p>After the subexpression (1), <code>resource.policyTags.write</code> should be added to the current capability set. After subexpression (2), <code>principal.authTags.write</code> should be added to it. Finally, when validating subexpression (3), the expression <code>resource.policyTags["write"]</code> will be considered valid since <code>resource.policyTags.write</code> is in the current capability set and it will be given type <code>Set&lt;String&gt;</code>, as <code>resource.policyTags</code> has type <code>{ ?: Set&lt;String&gt; }</code>. The expression <code>principal.authTags["write"]</code> is handled similarly. If either of the <code>has</code> subexpressions (1) or (2) were omitted, subexpression (3) would not validate due to the missing capability set entries.</p>
<h4 id="limited-operations"><a class="header" href="#limited-operations">Limited operations</a></h4>
<p>EA-maps' second-class status means that they can only be used as part of checking expressions <code>E has F</code> and projection expressions <code>E.F</code> or <code>E[F]</code>, where <code>E</code> has type <code>{ ?: T }</code>. The validator should disallow these expressions with type <code>{ ?: T }</code> in other contexts; e.g., the following should be disallowed:</p>
<pre><code>resource.policyTags == principal.authTags
[resource.policyTags, principal.authTags]
{foo: principal.authTags}
(if principal.isAdmin then principal.authTags else principal.authTags).write
</code></pre>
<p>(Note that the last case is disallowed because <code>principal.authTags</code> is not <em>directly</em> part of a <code>.</code> sub-expression -- it is returned from the <code>if</code> first. However, the usual short-circuiting mechanism would allow an <code>if</code> expression with a constant condition.)</p>
<h3 id="validating-and-parsing-entities"><a class="header" href="#validating-and-parsing-entities">Validating and parsing entities</a></h3>
<p>The Cedar authorizer's <code>is_authorized</code> function can be asked to validate that entities in a request are consistent with a provided schema. Extending validation to work with EA-maps is straightforward. The type rule is basically thus:</p>
<pre><code>v1: T ... vn: T
---------------------------------
{ f1: v1, ..., fn: vn } : { ?: T }
</code></pre>
<p>In particular, when asked to determine if a record has type <code>{ ?: T }</code>, we confirm that all values in the record have type <code>T</code>. By the nature of restrictions on schemas, the validator will only ever consider <code>{ ?: T }</code> types associated with entity attributes.</p>
<p>Similarly, schema-based parsing considers schemas when parsing in entities, and it can confirm when parsing that attributes labeled as <code>Record</code> in the JSON but defined as <code>{ ?: T }</code> in the schema have the appropriate shape.</p>
<h3 id="permissive-validation"><a class="header" href="#permissive-validation">Permissive Validation</a></h3>
<p>Permissive validation supports subtyping, which we extend so as to allow EA-maps' value types to be treated co-variantly:</p>
<pre><code>{ ?: T } &lt;: { ?: U }    iff T &lt;: U
</code></pre>
<p>We might consider adding rules that permit subtyping between records and EA-maps, but doing so introduces some complications with width subtyping. We could choose to grant EA-maps first-class status under permissive validation. For example, we could allow EA-maps values to appear anywhere, e.g., in <code>Set</code>s or records, and we could allow equality between EA-maps values. We choose not to do these things for now.</p>
<h2 id="drawbacks-15"><a class="header" href="#drawbacks-15">Drawbacks</a></h2>
<h3 id="non-dynamic-keys"><a class="header" href="#non-dynamic-keys">Non-dynamic keys</a></h3>
<p>EA-maps keys must be written in policies as literals. For example, you cannot write the following policy expression (using our example schema from above):</p>
<pre><code>principal.authTags has context.key &amp;&amp;
principal.authTags[context.key] == context.value
</code></pre>
<p>Supporting such <em>dynamic keys</em> is more work, but doable. With them, EA-maps would be strictly more powerful than existing encodings/workarounds for tags (the main use-case for EA-maps). We sketch the needed implementation work in Alternative A, below, and a comparison to workarounds further below.</p>
<h3 id="second-class-status"><a class="header" href="#second-class-status">Second-class status</a></h3>
<p>Only entity attributes are permitted to have type <code>{ ?: T }</code>, which eliminates the possibility of <code>{ ?: T }</code> literals and EA-maps directly containing other EA-maps. We also forbid using <code>==</code> and operations other than <code>has</code> and projection on <code>{ ?: T }</code>-typed expressions.</p>
<p>These restrictions are present for two reasons. First, second-class status ensures EA-maps are efficiently <em>analyzable</em>. Allowing first-class EA-maps values would require supporting equality between EA-maps values (directly or indirectly). Supporting equality would require a policy analysis to model EA-maps as arrays imbued with the extensionality axioms, which are known to be expensive. Second, second-class status means that we cannot introduce EA-maps literals, which means we do not need to introduce new syntax for EA-maps, which would be essentially the same as record literal syntax, leading to possible user confusion. Nor do we need to consider how we might treat record literals as equivalent to <code>{ ?: T }</code> values.</p>
<p>The use-cases that we are aware of do not suffer due to these limitations. If you wanted EA-maps to contain other EA-maps, or you wanted to store EA-maps in the <code>context</code> record, you can create specific entity types containing only those EA-maps. For example:</p>
<pre><code>entity User {
    roles: Set&lt;String&gt;,
    roleTags: { ?: StringTags },
};
entity StringTags {
    tags: { ?: String }
};
</code></pre>
<p>In effect, the <code>User</code>'s <code>roleTags</code> is equivalent to <code>{ ?: { ?: String } }</code>, but we have added a level of indirection by expressing the inner <code>{ ?: String }</code> value as an entity with a <code>{ ?: String }</code> attribute.</p>
<h3 id="implementation-effort"><a class="header" href="#implementation-effort">Implementation effort</a></h3>
<p>The implementation effort for adding EA-maps is non-trivial, as it will require changing the Rust code, the Lean models and proofs, and the differential test generators. It will also affect any component that leverages the schema and validator algorithms, such as schema-based parsing, and the policy analyzer.</p>
<p>That said, these changes are relatively straightforward:</p>
<ul>
<li>The validator changes are a straightforward extension to the handling of records with optional attributes. The extension to subtyping for permissive validation is also simple.</li>
<li>Changes to entity validation and schema-based parsing are fairly localized: They must consider the new EA-maps type when validating/parsing JSON <code>Record</code>-labeled entities.</li>
<li>The policy analyzer can model <code>{ ?: T }</code> attributes as uninterpreted functions because it never needs to consider equality between <code>{ ?: T }</code> values. Equality between entities is <em>nominal</em> -- we just consider the entity UID, not the contents of an entity's mapped-to attribute record (the only place that EA-maps can exist).</li>
<li>There are <em>no</em> changes to the evaluator or partial evaluator: From an evaluation perspective, <code>{ ?: T }</code> attributes are just attributes containing records whose attributes all have values of type <code>T</code>.</li>
</ul>
<h2 id="alternatives-14"><a class="header" href="#alternatives-14">Alternatives</a></h2>
<h3 id="alternative-a-ea-maps-with-dynamic-keys"><a class="header" href="#alternative-a-ea-maps-with-dynamic-keys">Alternative A: EA-maps with dynamic keys</a></h3>
<p>Supporting dynamic keys (see "Drawbacks: Non-dynamic keys" above), requires a few extensions to the main proposal: to the policy grammar, evaluator (and partial evaluator), validator, and analysis.</p>
<h4 id="policy-grammar-and-evaluator"><a class="header" href="#policy-grammar-and-evaluator">Policy grammar and evaluator</a></h4>
<p>We change the <a href="https://docs.cedarpolicy.com/policies/syntax-grammar.html#relation">grammar for <code>has</code></a> so that the given attribute can be a <a href="https://docs.cedarpolicy.com/policies/syntax-grammar.html#member"><code>Member</code></a>, rather than an <code>IDENT</code>:</p>
<pre><code>Relation ::= ... | Add 'has' (Member | STR)
</code></pre>
<p>Here, if <code>Member</code> is just an identifier like <code>foo</code> then it is interpreted as a key name. Otherwise it is treated as an expression that should be evaluated to a string, which is the name of the key.</p>
<p>For completeness here is the current <code>Member</code> grammar:</p>
<pre><code>Member ::= Primary {Access}
Access ::= '.' IDENT ['(' [ExprList] ')'] | '[' STR ']'
Primary ::= LITERAL
           | VAR
           | Entity
           | ExtFun '(' [ExprList] ')'
           | '(' Expr ')'
           | '[' [ExprList] ']'
           | '{' [RecInits] '}'
</code></pre>
<p>We also change <a href="https://docs.cedarpolicy.com/policies/syntax-grammar.html#access">attribute access</a> to allow <code>Member</code> to appear within brackets. The semantics is that we evaluate <code>Member</code> to a string, and then use that string to access the attribute.</p>
<pre><code>Access ::= '.' IDENT ['(' [ExprList] ')'] | '[' STR ']' | '[' Member ']'
</code></pre>
<p>It may be that <code>Member</code> is a bit too expressive. If so, we may consider making key-computing expressions simpler, e.g., <code>foo.bar.baz</code>, and not <code>User::"foo".bar.baz</code> or <code>{ foo: "bar" }.foo</code>.</p>
<p>We can allow this extended syntax and evaluation semantics to apply to normal record and entity attributes as well. The validator will prevent it, however, so it will only be possible for non-validated policies.</p>
<h4 id="validator"><a class="header" href="#validator">Validator</a></h4>
<p>The validator must change to further extend capability tracking from what we've described above to include dynamically contructed attribute names. This should be straightforward. When the validator sees something like <code>principal.tags has resource.name</code> then this would generate the capability <code>principal.tags[resource.name]</code> that would allow a follow-on expression <code>principal.tags[resource.name]</code> to validate.</p>
<p>In addition, it's now possible that an attribute-constructing expression could access a bogus attribute, so those expressions must be validated as well. E.g., when validating <code>principal.tags has resource.name</code> or <code>principal.tags[resource.name]</code>, the validator must confirm that <code>resource</code> indeed has a <code>name</code> attribute.</p>
<p>Because expressions like <code>principal has context.name</code> are now grammatically legal, the validator must be updated to consider them fully. In partcular, the validator should only allow <code>F</code> to be an expression when writing <code>E has F</code> or <code>E[F]</code> if <code>E</code> has type <code>{ ?: T }</code>---it will not be allowed when <code>E</code> has a normal record or entity type.</p>
<h4 id="analysis"><a class="header" href="#analysis">Analysis</a></h4>
<p>The policy analyzer's logical encoding must be generalized to account for keys being specified as expressions rather than as literals. Because we are encoding EA-maps as uninterpreted functions, this presents no problem: it doesn't matter whether the key given to the function is a literal string or an expression that evaluates (is equivalent) to a string. That said, counterexample generation could be a little more involved.</p>
<h4 id="summary-16"><a class="header" href="#summary-16">Summary</a></h4>
<p>There is a tradeoff here. Alternative A is more work to implement than the RFC as given, but not significantly more. And it carries a significant benefit: It enables this notion of EA-maps to be strictly more expressive than both of the workarounds given below, which are modeling EA-maps as optional attributes, and modeling EA-maps as sets of key-value pairs. Anything you can do with either of those workarounds you can do with Alternative A. As a result, policy writers will be encouraged to always use EA-maps directly, which will be easier to manage for policy readers.</p>
<h3 id="alternative-b-open-records"><a class="header" href="#alternative-b-open-records">Alternative B: Open records</a></h3>
<p>Previously, <a href="https://github.com/cedar-policy/rfcs/pull/66">RFC 66</a> proposed <em>open records</em> as a generalization of records suitable for encoding tags. Open records are essentially the same as EA-maps, but they are less restrictive, conferring first-class status on values. However, and so they add far more complication to the implementation effort. See that RFC for further discussion.</p>
<h3 id="alternative-c-maps"><a class="header" href="#alternative-c-maps">Alternative C: Maps</a></h3>
<p>Another prior RFC, <a href="https://github.com/cedar-policy/rfcs/pull/27">RFC 27</a>, proposed to create <code>map&lt;T&gt;</code> types as alternative types for records whose attributes all have the same type <code>T</code>, and whose attributes can be dynamically constructed (like dynamic keys for Alternative A, above). That RFC's <code>map&lt;T&gt;</code> type is quite similar to this RFC's <code>{ ?: T }</code> type except that maps are not second-class, and support dynamic keys. Supporting maps would lead to even greater implementation challenges than open records, per discussion on both of those prior RFCs.</p>
<h3 id="alternative-d-different-syntax"><a class="header" href="#alternative-d-different-syntax">Alternative D: Different syntax</a></h3>
<p>Rather than give EA-maps the type <code>{ ?: T }</code>, we could give them the type <code>EMap&lt;T&gt;</code> instead. The drawback is that this type may more strongly suggest that EA-maps can be first class, though they are not. Similarly, we could give EA-maps the type <code>Map&lt;K,V&gt;</code> but require <code>K</code> to always have type <code>String</code>. Doing so may be disappointing to users in that <code>K</code> cannot be anything other than <code>String</code>, and (once again) <code>Map</code> values are not first-class. Both proposals fail to evoke the analogy with records, i.e., that EA-maps are a set of key/value pairs, with values all having the same type.</p>
<p>To avoid potential confusion we could give EA-maps type <code>{ T }</code> instead of <code>{ ?: T }</code>. The latter syntax could be confusing because <code>{ "?": T }</code> is already a legal type for a record with a required attribute <code>"?"</code> (thus allowing expressions like <code>context["?"] == resource.foo</code>). It might be surprising to users that surrounding <code>?</code> in quotes would change the meaning of the type, since types like <code>{ "name": Long }</code> and <code>{ name: Long }</code> are equivalent. Using syntax <code>{ T }</code> would eliminate the potential for a confused interpretation. Nevertheless, the potential for it already exists. Types <code>{ isPrivate?: Bool }</code> and <code>{ "isPrivate?": Bool }</code> are not the same: The former indicates an optional attribute <code>isPrivate</code> whereas the latter indicates a required attribute <code>"isPrivate?"</code>. Given this, we prefer syntax <code>{ ?: T }</code> since it more directly evokes that EA-maps are a kind of record with all-optional attributes, and is no more confusing than the status quo.</p>
<h3 id="workaround-records-with-optional-attributes"><a class="header" href="#workaround-records-with-optional-attributes">Workaround: Records with optional attributes</a></h3>
<p>We could avoid adding EA-maps entirely and work around their absence.</p>
<p>A direct workaround is to implement EA-maps as a record type that enumerates every legal tag as an optional attribute. Then, every time you create a policy that mentions a tag key as a literal, the validator will complain if that key is not in the schema. So, add the key to the schema, and the new policy will validate along with the old ones.</p>
<p>The drawback of this approach is that changing the schema on the fly to extend the list of valid keys could be expensive. If policies are being constructed on the fly, e.g., by a service's users, a schema update to support a new tag used by a new policy would technically require re-validating existing policies, whereas with EA-maps <code>{ ?: T }</code> we can leave the schema alone and avoid re-validation entirely.</p>
<p>Schemas are also simpler with <code>{ ?: T }</code> types, rather than a long list of optional attributes, and better communicate intent.</p>
<h3 id="workaround-tags-as-sets-of-keyvalue-pairs"><a class="header" href="#workaround-tags-as-sets-of-keyvalue-pairs">Workaround: Tags as sets of key/value pairs</a></h3>
<p>Another way to implement tags, rather than as EA-maps, is as sets of key-value pairs. For example, <code>principal.tags</code> could have type <code>Set&lt;{ key:String, value:String }&gt;</code> and a tag check would involve an expression like <code>principal.tags.contains({ key: "priority", value: "green" })</code>.</p>
<p>This approach has the benefit that keys can be dynamic. E.g., you can write</p>
<pre><code>principal.tags.contains(context.tagvalue)
</code></pre>
<p>where <code>context.tagvalue</code> can be dynamically determined. However, with this encoding of tags you cannot write expressions such as <code>resource.tags["project"] == principal.tags["project"]</code>
or
<code>resource.tags["projects"].contains(principal.tags["project"])</code>. We find this to be a strong limitation, as customers often want to exprss policies that relate the tags of principals to those of resources. Note that <a href="https://github.com/cedar-policy/rfcs/pull/21">RFC 21</a> would lift this limitation through the introduction of the <code>any?</code> and <code>all?</code> operators, but it was rejected due to problems with logically encoding these operators during policy analysis.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="disallow-shadowing-definitions-in-the-empty-namespace"><a class="header" href="#disallow-shadowing-definitions-in-the-empty-namespace">Disallow shadowing definitions in the empty namespace</a></h1>
<h2 id="related-issues-and-prs-15"><a class="header" href="#related-issues-and-prs-15">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: Successor to <a href="https://github.com/cedar-policy/rfcs/pull/64">RFC 64</a></li>
<li>Implementation PR(s):</li>
</ul>
<h2 id="timeline-16"><a class="header" href="#timeline-16">Timeline</a></h2>
<ul>
<li>Started: 2024-06-26</li>
<li>Accepted: 2024-08-01</li>
<li>Landed: 2024-08-26 on <code>main</code> (<a href="https://github.com/cedar-policy/cedar/pull/1147">#1147</a>)</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-17"><a class="header" href="#summary-17">Summary</a></h2>
<p>In schemas, disallow definitions of entity types, common types, and actions that
would shadow definitions of other entity types, common types, or actions in the
empty namespace.</p>
<h2 id="basic-example-13"><a class="header" href="#basic-example-13">Basic example</a></h2>
<p>Borrowing and slightly tweaking the example from <a href="https://github.com/cedar-policy/rfcs/pull/64">RFC 64</a>:</p>
<pre><code>entity User {
    email: String,
};

namespace Demo {
    entity User {
        id: String,
    };

    entity Account {
        owner: User,
    };
}
</code></pre>
<p>Today, this schema is accepted, and <code>Account.owner</code> is assumed to be
<code>Demo::User</code> and not the empty-namespace <code>User</code>.
As noted in <a href="https://github.com/cedar-policy/rfcs/pull/64">RFC 64</a>, there is no way for the user to indicate that they intend
<code>Account.owner</code> to be the empty-namespace <code>User</code>.
Rather than add syntax to enable this (as proposed in <a href="https://github.com/cedar-policy/rfcs/pull/64">RFC 64</a>), this RFC
proposes to make this situation an error -- disallowing declaring a <code>User</code> type
in the <code>Demo</code> namespace when one already exists in the empty namespace.</p>
<h2 id="motivation-15"><a class="header" href="#motivation-15">Motivation</a></h2>
<p>Name shadowing is complicated and confusing; schemas using name shadowing may
look like they are doing one thing when they are actually doing another.
For Cedar policy and schema authors, this can cause misunderstandings and make
it more difficult to write correct schemas and policies.
By disallowing shadowing in the most egregiously ambiguous cases -- when the
name being shadowed was declared in the empty namespace -- we nudge users to
make the schema clearer, for instance by renaming a type, or moving a
conflicting empty-namespace declaration into a new namespace.</p>
<h2 id="detailed-design-16"><a class="header" href="#detailed-design-16">Detailed design</a></h2>
<p>We disallow shadowing a type or action in the empty namespace with a new
declaration in a nonempty namespace.</p>
<ul>
<li>For entity and common types, we disallow this shadowing regardless of whether
the shadowed declaration is an entity or common type, and regardless of whether
the shadowing declaration is an entity or common type.</li>
<li>For actions, we only disallow shadowing other actions.
We continue to allow an action to have the same name as an entity or common
type (in the same namespace or in the empty namespace).
That is not "shadowing", as there is no place in a schema where it's ambiguous
whether you're referring to an action or an entity/common type.</li>
</ul>
<p>This RFC does not disallow shadowing altogether; in particular, it does not
disallow shadowing a entity typename with a common typename in the same namespace,
as originally proposed in <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0024-schema-syntax.md">RFC 24</a> (see "Disambiguating Types in Custom Syntax",
and in particular Rule 5 in that section):</p>
<pre><code>// Allowed today, and still allowed after this RFC
namespace NS {
    entity User {
        id: String,
    }
    type User = User;
    // or, more confusingly, type User = String;
}
</code></pre>
<p>This RFC also does not disallow shadowing the names of primitive or extension
types, where you can still refer to the shadowed type using <code>__cedar</code>, again as
explained in <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0024-schema-syntax.md">RFC 24</a>.
Conceptually, primitive and extension types are not declared in the empty
namespace; they are declared in the <code>__cedar</code> namespace, and implicitly imported
as part of a prelude.
That is how we could explain (e.g. in the Cedar docs) why the rule is different
for shadowing entity/common types and shadowing primitive/extension types.
(Internally, another reason for continuing to allow shadowing
primitive/extension types, is that we want to be able to introduce new extension
types without any possibility of breaking existing schemas.)</p>
<p>This RFC does not change anything about <a href="https://github.com/cedar-policy/cedar/issues/579">cedar#579</a>.
We still plan to implement <a href="https://github.com/cedar-policy/cedar/issues/579">cedar#579</a>, which allows users to refer to types in
the empty namespace, in cases where they are not shadowed.</p>
<p>This RFC does apply the new restriction uniformly in both the human and JSON
schema syntaxes.
The motivation and situation is the same in both syntaxes for the case of an
entity typename shadowing an entity typename, and for the case of a common
typename shadowing a common typename.
For the case of an entity typename shadowing a common typename or vice versa,
this RFC still proposes to disallow in both syntaxes, even though these
situations are not ambiguous in the JSON syntax, which distinguishes between
entity type and common type references.
See <a href="https://github.com/cedar-policy/rfcs/pull/70#discussion_r1659120108">this RFC discussion thread</a>.</p>
<h2 id="drawbacks-16"><a class="header" href="#drawbacks-16">Drawbacks</a></h2>
<h3 id="drawback-1"><a class="header" href="#drawback-1">Drawback 1</a></h3>
<p>The motivation section for <a href="https://github.com/cedar-policy/rfcs/pull/64">RFC 64</a> claimed that</p>
<blockquote>
<p>Users justifiably expect that they can refer to any declared typename (in any
namespace) from any position in the schema, by writing a fully qualified name.
The fact that <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0024-schema-syntax.md">RFC 24</a> did not provide a way to refer to typenames in the empty
namespace by using some kind of fully qualified name seems like an oversight,
and should be corrected for consistency.</p>
</blockquote>
<p>This RFC does not address that motivation, and effectively counterclaims that
users don't actually expect this.</p>
<h3 id="drawback-2"><a class="header" href="#drawback-2">Drawback 2</a></h3>
<p>If <a href="https://github.com/cedar-policy/rfcs/pull/69">RFC 69</a> or something similar are eventually accepted, the error in this RFC
may not be so easily avoided, if the empty-namespace definition is part of a
third-party library being imported by the user.
In that case, the user couldn't easily rename the empty-namespace type or move
it into a nonempty namespace.</p>
<p>To address this drawback, we should guide library authors to not declare library
types or actions in the empty namespace (and instead, e.g., declare them in a
namespace named after the library).
We could even codify that rule, requiring that all libraries have a name and all
declarations in the library live in the corresponding namespace, or alternately,
implicitly prefixing all library declarations with the library name as a
toplevel namespace.
Many existing package systems have similar rules or mechanisms.</p>
<h2 id="alternatives-15"><a class="header" href="#alternatives-15">Alternatives</a></h2>
<p><a href="https://github.com/cedar-policy/rfcs/pull/64">RFC 64</a> proposed instead introducing new schema syntax to allow users to refer
to entity and common types in the empty namespace whose names are shadowed by
declarations in the current namespace.
(RFC 64 could be naturally extended to actions as well.)</p>
<p>Introducing new schema syntax is a major change, and in the discussion on
<a href="https://github.com/cedar-policy/rfcs/pull/64">RFC 64</a> we have been, to date as of this writing, unable to agree on a syntax for
this which is clear and acceptable to everyone.
On the RFC thread and in offline discussions, the leading candidates for such a
syntax are currently (as of this writing) <code>::User</code>, <code>root User</code>, or
<code>__cedar::Root::User</code> (reusing the <code>__cedar</code> namespace reserved in <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0052-reserved-namespaces.md">RFC 52</a>).
But it seems apparent that none of these options are immediately intuitive to
all users; if we were to introduce such a syntax, we run the risk of
complicating the schema syntax only to not actually clarify the situation
because the new syntax is still unclear.</p>
<p>Finally, this shadowing situation is viewed as an unlikely edge case in general,
and certainly one that can easily be avoided by users (by renaming types/actions
or moving empty-namespace declarations into a namespace).
It seems expedient to resolve this in the easiest, clearest way possible.
This RFC proposes that disallowing the premise is easier and clearer than
designing and implementing new schema syntax that will only be used in an
unlikely edge case.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="trailing-commas"><a class="header" href="#trailing-commas">Trailing Commas</a></h1>
<h2 id="related-issues-and-prs-16"><a class="header" href="#related-issues-and-prs-16">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: https://github.com/cedar-policy/cedar/issues/1024</li>
<li>Implementation PR(s):</li>
</ul>
<h2 id="timeline-17"><a class="header" href="#timeline-17">Timeline</a></h2>
<ul>
<li>Started: 2024-06-26</li>
<li>Accepted: 2024-09-10</li>
<li>Landed: TBD</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-18"><a class="header" href="#summary-18">Summary</a></h2>
<p>The Cedar grammar (both policies and schemas) should accept trailing
commas whenever possible.</p>
<h2 id="basic-example-14"><a class="header" href="#basic-example-14">Basic example</a></h2>
<p>Currently, this is a parse error:</p>
<pre><code>permit(principal, action, resource) when {
    { foo : 3, bar : 2, } == context  
};
</code></pre>
<p>This RFC would make it not a parse error.
It would also change this is several places beyond records.</p>
<h2 id="motivation-16"><a class="header" href="#motivation-16">Motivation</a></h2>
<p>In general, allowing trailing commas makes editing easier.
Re-arranging, deleting, and copy-pasting code into/from a comma
separated grammar element will no longer require adjusting commas.</p>
<p>Example:</p>
<pre><code>{
    "managers": ["Dave", "Shelly", "Chris"],
    "projects" : {
        "Alpha" : {
            "zones" : ["A", "B"]
        },
        "Beta" : {
            "zones" : ["D", "F"]
        }
    }
}
</code></pre>
<p>The <code>Beta</code> project cannot simply be deleted from this record, and
likewise, new fields cannot be simply pasted into any level of the
objects, without adjusting commas.</p>
<p>Many languages allow for trailing commas, including:</p>
<ul>
<li>Rust</li>
<li>Python</li>
<li>Java,</li>
<li>Go</li>
<li>JavaScript</li>
<li>OCaml</li>
</ul>
<p>(Frustratingly: not JSON!)</p>
<p>In addition, it will make our schema grammar and policy grammar more
consistent, as the schema grammar allows trailing commas in many places.</p>
<h2 id="detailed-design-17"><a class="header" href="#detailed-design-17">Detailed design</a></h2>
<h3 id="cedar-policy-grammar"><a class="header" href="#cedar-policy-grammar">Cedar Policy Grammar</a></h3>
<p>We want to allow trailing commas in the following expressions:</p>
<ol>
<li>scopes: <code>permit(principal, action, resource, )</code></li>
<li>sets: <code>[1,2,3,]</code></li>
<li>records: <code>{ foo : 1, bar : 3, }</code></li>
<li>all method/function calls: <code>.contains(3,)</code>, <code>ip("10.10.10.10",)</code></li>
</ol>
<p>In the grammar:</p>
<p>The following grammar rules change:</p>
<pre><code>Scope ::= Principal ',' Action ',' Resource
</code></pre>
<p>becomes:</p>
<pre><code>Scope ::= Principal ',' Action ',' Resource ','?
</code></pre>
<pre><code>EntList ::= Entity {',' Entity}
</code></pre>
<p>becomes:</p>
<pre><code>EntList ::= Entity {',' | ',' Entity} ','?
</code></pre>
<pre><code>ExprList ::= Expr {',' Expr}
</code></pre>
<p>becomes:</p>
<pre><code>ExprList ::= Expr {',' | ',' Expr} ','?
</code></pre>
<pre><code>RecInits ::= (IDENT | STR) ':' Expr {',' (IDENT | STR) ':' Expr}
</code></pre>
<p>becomes:</p>
<pre><code>RecInits ::= (IDENT | STR) ':' Expr {',' | ',' (IDENT | STR) ':' Expr}
</code></pre>
<h3 id="cedar-schema-grammar"><a class="header" href="#cedar-schema-grammar">Cedar Schema Grammar</a></h3>
<p>The schema grammar already allows trailing commas in several places
(such as record types and entity lists), but not everywhere:</p>
<p>We want to allow trailing commas in the following expressions:</p>
<ol>
<li>membership lists: <code>entity Photo in [Account, Album,];</code></li>
<li>Multi-entity declarations: <code>entity Photo,Video;</code></li>
<li>Record types: <code>{ foo : Long, bar : String, }</code> (currently allowed)</li>
<li>Multi-action declarations: <code>action foo,bar,;</code></li>
<li>Apply specs: <code>appliesTo { principal : ["A"], resource: ["B"],"</code>
(currently allowed)</li>
</ol>
<pre><code>EntTypes  := Path {',' Path}
</code></pre>
<p>becomes:</p>
<pre><code>EntTypes  := Path {',' | ',' Path}
</code></pre>
<pre><code>Names     := Name {',' Name}
</code></pre>
<p>becomes:</p>
<pre><code>Names     := Name {',' | ',' Name} ','?
</code></pre>
<pre><code>Idents    := IDENT {',' IDENT}
</code></pre>
<p>becomes:</p>
<pre><code>Idents    := IDENT {',' | ',' IDENT}
</code></pre>
<h3 id="backwards-compatibility"><a class="header" href="#backwards-compatibility">Backwards Compatibility</a></h3>
<p>This change is fully backwards compatible.</p>
<h2 id="drawbacks-17"><a class="header" href="#drawbacks-17">Drawbacks</a></h2>
<ul>
<li>Trailing commas are potentially confusing.</li>
</ul>
<h2 id="alternatives-16"><a class="header" href="#alternatives-16">Alternatives</a></h2>
<ul>
<li>Keep status quo: this is a non critical change</li>
</ul>
<h2 id="unresolved-questions-2"><a class="header" href="#unresolved-questions-2">Unresolved questions</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="entity-slice-validation"><a class="header" href="#entity-slice-validation">Entity Slice Validation</a></h1>
<h2 id="related-issues-and-prs-17"><a class="header" href="#related-issues-and-prs-17">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues:</li>
<li>Implementation PR(s):</li>
</ul>
<h2 id="timeline-18"><a class="header" href="#timeline-18">Timeline</a></h2>
<ul>
<li>Started: 2024-08-01</li>
</ul>
<h2 id="summary-19"><a class="header" href="#summary-19">Summary</a></h2>
<p>This RFC introduces "Entity Slicing Validation" (ESV), which consists of</p>
<ol>
<li>An additional validation check, and</li>
<li>A generic entity slicing algorithm</li>
</ol>
<p>The two are connected by the concept of a "level," which defines the depth from root variables (like <code>principal</code> and <code>resource</code>) at which entity dereferencing operations may safely take place in policies. The validation check ensures that policies never dereference beyond the given level. The slicing algorithm determines what entities are needed to safely decide an authorization request when evaluating policies valid at a given level.</p>
<h2 id="basic-example-15"><a class="header" href="#basic-example-15">Basic example</a></h2>
<p>Consider the following <a href="https://github.com/cedar-policy/cedar-examples/blob/release/3.2.x/tinytodo/policies.cedar">policies</a>, taken from the <a href="https://github.com/cedar-policy/cedar-examples/tree/release/3.2.x/tinytodo">TinyTodo example application:</a></p>
<pre><code>// Policy 1: A User can perform any action on a List they own
permit (
  principal,
  action,
  resource is List
)
when { resource.owner == principal };

// Policy 2: A User can see a List if they are either a reader or editor
permit (
    principal,
    action == Action::"GetList",
    resource
)
when { principal in resource.readers || principal in resource.editors };

// Policy 4: Admins can perform any action on any resource
permit (
  principal in Team::"Admin",
  action,
  resource
);
</code></pre>
<p>We suppose (per the <a href="https://github.com/cedar-policy/cedar-examples/blob/release/3.2.x/tinytodo/tinytodo.cedarschema">schema</a>, not shown) that <code>principal</code> always has entity type <code>User</code>, and <code>resource</code> always has entity type <code>List</code>. These policies are valid at level 1, meaning that variables <code>principal</code>, <code>action</code>, <code>resource</code> and <code>context</code> are only <em>directly</em> dereferenced, i.e., any entities they reference are not themselves dereferenced.</p>
<p>For example, in policy 1, the expression <code>resource.owner == principal</code> directly dereferences <code>resource</code> by accessing the contents of its <code>owner</code> attribute. In policy 2, expression <code>principal in resource.readers</code> directly dereferences <code>resource</code> to retrieve the contents of its <code>readers</code> attribute, and also directly dereferences <code>principal</code> to retrieve its ancestors, to see whether one might be equal to the contents of <code>resource.readers</code>. Policy 4 also directly dereferences <code>principal</code> to access its ancestors, to see if one is <code>Team::"admin"</code>.</p>
<p>Because these policies are valid at level 1, applications submitting authorization requests only need to provide entity data for entities provided as variables, and nothing else. For example, say we want to evaluate the request (<code>User::"Aaron"</code>, <code>Action::"GetList"</code>, <code>List::"Objectives"</code>, <code>{}</code>). Then we would only need to provide entity data (direct attributes and ancestors) for <code>User::"Aaron"</code>, <code>Action::"GetList"</code>, and <code>List::"Objectives"</code>. There is no need to provide data for entities referenced from these entities. For example, suppose the <code>readers</code> attribute of <code>List::"Objectives"</code> is <code>Team::"interns"</code>; there is no need to provide data for <code>Team::"interns"</code> because we know it will never, itself, be dereferenced when evaluating these policies. There is also no need to provide entity data for other entities directly mentioned in policies, e.g., <code>Team::"Admin"</code>.</p>
<p>Now suppose we wanted to extend our TinyTodo policies with the following:</p>
<pre><code>// Policy 6: No access if not high rank and at location DEF, 
// or at resource's owner's location
forbid(
    principal,
    action,
    resource is List
) unless {
   principal.joblevel &gt; 6 &amp;&amp; principal.location like "DEF*" ||
   principal.location == resource.owner.location
};
</code></pre>
<p>This policy does <em>not</em> validate at level 1. That is because the expression <code>resource.owner.location</code> is only valid at level 2: It requires dereferencing <code>resource</code> to retrieve the entity in the <code>owner</code> attribute, and then requires dereferencing that entity to obtain the contents of its <code>location</code> attribute. As a result, if we only provided the <code>principal</code> and <code>resource</code> entity data, as described above, evaluating policy 6 could produce an evaluation error since data may not be provided for <code>resource.owner</code>.</p>
<p>All of the Cedar example policy sets validate with level-based validation, either at level 1 or 2; see the Appendix for details.</p>
<h2 id="motivation-17"><a class="header" href="#motivation-17">Motivation</a></h2>
<p>Currently, Cedar provides no support for slicing. Users are required to either be inefficient and produce their entire entity store as a slice, or derive their own ad-hoc slicing algorithm. We'd like to provide an out-of-the-box solution that addresses many user's needs. Entity slicing in general is a problem very tied to the specifics of application/deployment. It's likely impossible to have a fully general solution. This RFC is attempting to provide a solution for entity slicing that works for the 80% case, while acknowledging that it won't work for everyone.</p>
<p>Additionally, there are some application scenarios where the actors writing the policies and the people performing slicing are not the same people, and thus the slicers need to impose some kind of restrictions on policy authors.</p>
<p>This RFC has a close connection to <a href="https://github.com/cedar-policy/rfcs/pull/74">RFC 74: Entity Slicing using Data Tries</a>, which also seeks to provide a sound foundation for entity slicing. We discuss the relationship between them in the Alternatives below; ultimately, we believe they are complementary and should coexist.</p>
<h2 id="detailed-design-18"><a class="header" href="#detailed-design-18">Detailed design</a></h2>
<h3 id="entity-dereferences"><a class="header" href="#entity-dereferences">Entity dereferences</a></h3>
<p>An "Entity Dereference" is any operation that requires directly accessing an entity’s data. The following is an exhaustive list of entity dereferencing operations</p>
<ol>
<li><code>e1 in e2</code> dereferences <code>e1</code> (but not <code>e2</code>)</li>
<li><code>e1.foo</code> dereferences <code>e1</code> iff <code>e1</code> is an entity</li>
<li><code>e1 has foo</code> dereferences <code>e1</code> iff <code>e1</code> is an entity</li>
</ol>
<p>Note that testing equality <em>is not</em> a dereferencing operation. Therefore expressions like <code>e1 == e2</code>, <code>e1.contains(e2)</code> and <code>e3 in e2</code> do not dereference <code>e1</code> or <code>e2</code>.</p>
<p>Also note that by “dereference” above, we are only referring to the given operation, not about any operations that might be executed to evaluate subexpressions. For example, while <code>e1 in e2</code> only dereferences <code>e1</code> (per rule 1 above), if <code>e2</code> is <code>principal.foo</code>, then of course evaluating <code>e2</code> dereferences <code>principal</code> (per rule 2 above).</p>
<h3 id="entity-roots"><a class="header" href="#entity-roots">Entity roots</a></h3>
<p>The variables <code>principal</code>, <code>action</code>, and <code>resource</code> are <em>entity roots</em>. (Entity literals are <em>not</em> entity roots, and operations on such literals are limited, as described below. Slots and the <code>Unknown</code> entity are treated as entity literals because slots will be replaced by literals and <code>Unknown</code> cannot be dereferenced.) They directly name entities from a request that could be dereferenced in a policy. A <code>context</code> is not an entity root directly; rather, any attributes it (transitively) contains that have entity type are considered roots. For example, consider the following schema:</p>
<pre><code>entity User {
    manager: User,
    age: Long,
};
action getDetails appliesTo {
    principal: User,
    resource: User,
    context: {
        admin: User,
        building: { location: Long, ITDeptHead: User },
        foo: { inner: User },
        bar: { inner: User }
    }
};
</code></pre>
<p>Here, <code>principal</code>, <code>action</code>, and <code>resource</code> are entity roots (as usual), as are:</p>
<ul>
<li><code>context.admin</code></li>
<li><code>context.building.ITDeptHead</code></li>
<li><code>context.foo.inner</code> , and</li>
<li><code>context.bar.inner</code></li>
</ul>
<p>Note that <code>context</code>,  <code>context.building</code>, and  <code>context.building.location</code> are <em>not</em> entity roots because they do not have entity type. Moreover, <code>context.admin.manager</code> is not an entity root because <code>manager</code> is not an attribute of <code>context</code> itself.</p>
<h3 id="dereference-levels"><a class="header" href="#dereference-levels">Dereference levels</a></h3>
<p>During validation, we extend entity types with a <em>level</em>, which is either <code>∞</code> or a natural number. We call these <em>leveled entity types</em>. The level expresses how many entity dereferences are permitted starting from an expression having that type. Levels on types are only used internally; policy/schema writers never see them. When the level is <code>∞</code>, validation is unchanged from the status quo.</p>
<h3 id="specifying-the-level"><a class="header" href="#specifying-the-level">Specifying the level</a></h3>
<p>The maximum level that policies may validate at is specified as a parameter to the validator. Schemas are unchanged. Just like Cedar currently supports strict (the default) and permissive validation, it would now support those things with the additional parameter of what level at which to validate. As discussed in the alternatives below, a drawback of this approach is that policy writers cannot look in one place (the schema) to know the limits on the policies they can write. But in a sense, due to the dichotomy of strict vs. permissive validation, that's already the case.</p>
<h3 id="validation-algorithm"><a class="header" href="#validation-algorithm">Validation algorithm</a></h3>
<p>Validation works essentially as today (see our <a href="https://dl.acm.org/doi/pdf/10.1145/3649835">OOPSLA’24 paper</a>, page 10), but using leveled types. To validate a policy c at level N, we use a request environment which maps <code>principal</code>, <code>resource</code>, and <code>context</code> to leveled types with level N. For example, for the schema given above, to validate at level 2 our request environment would map <code>principal</code> to <code>User</code>(2), <code>resource</code> to <code>User</code>(2), and <code>context</code> to the type given in the schema annotated with 2, i.e., <code>{ admin: User(2), building: { location: Long, ITDeptHead: User(2) },... }</code>.</p>
<p>The rules for expression <code>e1 in e2</code> (line (3) in Fig. 7)(a) in the paper) are extended to require that the entity type of <code>e1</code> is <code>E1(n)</code> where <code>n &gt; 0</code>. This requirement indicates that <code>e1</code> must be an entity from which you can dereference at least one level (to access its ancestors).</p>
<p>The rules for expression <code>e has f</code> and <code>e.f</code> (line (6) in Fig. 7(a) in the paper) are extended so that if <code>e</code> has entity type, then its type must be <code>E(n)</code> where <code>n &gt; 0</code>. The rule for <code>e.f</code> is additionally extended so that if <code>e.f</code> has entity type <code>F</code> (per the schema), then the the final type is leveled as one less than <code>n</code>; e.g., if <code>e</code> has level <code>n</code>, then final expression has type F<code>(n-1)</code>. (Rules for <code>e has f</code> and <code>e.f</code> are unchanged when <code>e</code> has record type.)</p>
<p>The rule for entity literals (not shown in the paper) always ascribes them level 0 unless we are validating at level  <code>∞</code>. For example, the type of expression <code>User::"Alice"</code> is <code>User(0)</code>. This is because we do not permit dereferencing literals in policies when using leveled validation. (See the Alternatives below for a relaxation of this restriction.)</p>
<p>We extend the subtyping judgment (Fig 7(b) in the paper) with the following rule: <code>E(n) &lt;: E(n-1)</code>. That is, it is always safe to treat a leveled entity type at level <code>n</code> as if it had fewer levels. This rule is important when multiple expressions are required to have the same level. For example:</p>
<pre><code>if (principal.age &lt; 25) then
  principal.manager
else
  principal
</code></pre>
<p>Suppose we are validating at level 2, then this expression will have type <code>User(1)</code>, where we use subtyping to give expression <code>principal</code> (in the else branch) type <code>User(1)</code> rather than <code>User(2)</code>. Similarly, if we were defining a set of entities, all of them must be given the same level. For example, we could give <code>[ principal.manager, principal ]</code> the type <code>Set&lt;User(1)&gt;</code>. Note that for records, individual attributes may have entities with different levels. E.g., <code>{ a: principal, b: principal.manager }</code> would have type <code>{ a: User(2), b: User(1) }</code>.</p>
<h3 id="slicing"><a class="header" href="#slicing">Slicing</a></h3>
<p>Once a schema has been validated against a non- infinite level, we can use the following procedure at runtime to compute the entity slice:</p>
<pre><code>/// Takes:
/// request : The request object
/// level : The level the schema was validated at 
/// get-entity : A function for looking up entity data given an EUID 
function slice(request, level, get-entity) { 
    // This will be our entity slice
   let mut es : Map&lt;EUID, EntityData&gt; = {};

   let mut worklist : Set&lt;EUID&gt; = {principal, action, resource, all root euids in context};
   for euid in worklist {
     es.insert(euid, get-entity(euid));
   }
   
   let current-level = 0;
   
   while current-level &lt;= level || worklist.empty? {
        // `t` will become our new worklist
        let t : Set&lt;EUID&gt; = {};
        // Clear our worklist
        for euid in worklist {
            if !es.contains(euid) {
                es.insert(euid, get-entity(euid));
            }
            // Set of all euids mentioned in this entities data
            let new-euids = filter(not-in-es?, all-euids(es.get(euid)));
            t = t.union(new-euids);
        }
        // set t to be the new worklist
        s = t;
        // increment level
        level = level + 1;
   }

    return es;
}

</code></pre>
<h3 id="soundness"><a class="header" href="#soundness">Soundness</a></h3>
<p>Leveled types permit us to generalize the soundness statement we use today. Currently, soundness assumes that expressions like <code>principal.manager</code> will never error, i.e., that the proper entity information is available. Now we assume dereferences are only available up to a certain level. In particular, we define a well-formedness judgment μ ⊢ v : τ where μ is an entity store, v is a value, and τ is a possibly leveled type. This judgment is standard for values having non-entity type, e.g.,</p>
<pre><code>mu |- i : Long

mu |- s : String

mu |- v1 : T1 ... mu |- vn : Tn 
-------------------------------------------------------
mu |- { f1: v1, ..., fn: vn } : { f1: T1, ..., fn: Tn }
</code></pre>
<p>There are two rules for entity literals of type <code>E::s</code>. The first says level <code>0</code> is always allowed. The second says a literal can have a level <code>n</code> only if <code>n</code> dereferences are possible starting from <code>E::s</code>:</p>
<pre><code>mu |- E::s : E(0)

mu(E::s) = (v,h) where v = { f1: v1, ..., fn: vn } and h is an ancestor set
mu |- v1 : T1 ... mu |- vn : Tn
where level(T1) &gt;= n-1 ... level(Tn) &gt;= n-1
------------------------------------------------------------------------------------
mu |- E::s : E(n) where n &gt; 0
</code></pre>
<p>The auxiliary function <code>level(T)</code> identifies the lower-bound of the level of type <code>T</code>. It’s defined as follows:</p>
<ul>
<li><code>level(E(n))</code> = <code>n</code></li>
<li><code>level({ f1: T1, ..., fn: Tn })</code>  = <code>m</code> where <code>m</code> = <code>min(level(T1),...,level(Tn))</code></li>
<li><code>level(Long)</code> = <code>level(String)</code> = <code>level(Boolean)</code> = <code>level(Set(T))</code> = (etc.) = ∞ for all other types</li>
</ul>
<p>Thus the soundness statement says that</p>
<ol>
<li>If policy set <code>p</code> is validated against a schema <code>s</code> with level <code>l</code>, where  <code>l &lt; ∞</code> .</li>
<li>If entity store μ is validated against schema <code>s</code></li>
<li>If request σ is validated against schema <code>s</code></li>
<li>If μ ⊢ σ(principal): E(l) where E is the expected type of the principal for this particular action, and  similarly check the proper leveling of action, request, and context.</li>
<li>Then:
<ol>
<li><code>isAuthorized(sigma, p, mu)</code> is either a successful result value or an integer overflow error
<ol>
<li>All errors except integer overflow + missing entity are prevented by the current validator</li>
<li>missing entity errors are prevented by the new validator + slicer</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>We extend the proof of soundness to leverage premise #4 above: This justifies giving <code>principal</code> a type with level l in the initial request context, and it justifies the extensions to the rules that perform dereferencing, as they decrease the leveled result by 1, just as the μ⊢v:τ rule does, which we are given.</p>
<p>We also want to prove the soundness of the <code>slice(request, level, get-entity)</code> procedure defined above: If <code>slice</code>(σ, <code>l</code>, <code>get-entity</code>) = μ and request σ is validated against schema <code>s</code> and level <code>l</code>, then μ validates against schema <code>s</code> at level <code>l</code>.</p>
<h2 id="drawbacks-18"><a class="header" href="#drawbacks-18">Drawbacks</a></h2>
<p>Level-based slicing is coarse-grained: <em>all</em> attributes up to the required level, and <em>all</em> ancestors, for each required entity must be included in the slice. Much of this information may be unnecessary, though, depending on the particulars of the request. For example, for the TinyTodo policies in our detailed example, if the action in the request was <code>Action::"CreateList"</code>, then only policies 1 and 4 can be satisfied. For these policies, no ancestor data for <code>principal</code> and <code>resource</code> is needed, and only the contents of <code>resource.owner</code>, and not (say) <code>resource.readers</code> and <code>resource.editors</code>, is required. For some applications, the cost to retrieve all of an entity’s data and then pass it to the Cedar authorizer could be nontrivial, so a finer-grained approach may be preferred. Some ideas are sketched under alternatives.</p>
<p>Implementing levels is a non-trivial effort: We must update the Rust code for the validator of policies and entities, and the Lean code and proofs. We also must provide code to perform level-based slicing.</p>
<h2 id="alternatives-17"><a class="header" href="#alternatives-17">Alternatives</a></h2>
<h3 id="alternative-entity-slicing-using-data-tries"><a class="header" href="#alternative-entity-slicing-using-data-tries">Alternative: Entity Slicing using Data Tries</a></h3>
<p><a href="https://github.com/cedar-policy/rfcs/pull/74">RFC 74, Entity Slicing using Data Tries</a> proposes the idea of an <em>entity manifest</em> to ease the task of entity slicing. This manifest is a trie-based data structure that expresses which entity attributes and ancestors are needed for each possible action. This data structure is strictly more precise than the concept of level, meaning that it may require less entity data to be provided. For example, the first part of our Basic Example in this RFC (policies 1, 2, and 4 of TinyTodo), the determined entity manifest would indicate that for the <code>GetList</code> action, you would need to provide <code>resource.owner</code>, <code>resource.readers</code>, <code>resource.editors</code> and the ancestors of <code>principal</code>. This is less data than would be retrieved by the slicing algorithm proposed here: These are level-1 valid policies, so the generic algorithm would acquire the same data given in the manifest but also more, e.g., the ancestors of <code>resource</code> and the attributes of <code>principal</code>.</p>
<p>Entity manifests are less effective as a <em>prescriptive</em> mechanism that aims to limit the shape of allowable policies. For example, a Cedar policy and entity storage service might like to disallow uploading policies whose entity data is expensive to retrieve in the worst case. With levels, such a service can upper-bound this work by blocking schemas with a level greater than a threshold, say 3. Validation will then ensure that uploaded policies respect this upper bound. Manifests are unwieldy as a specification mechanism, since they are specialized to particular entity definitions and name particular types and attributes, of which there could be many. They'd also have to be updated as types evolved over time, while a level-based specification is less likely to change.</p>
<p>We believe that ultimately level-based validation and entity manifests should coexist. Level-based validation is used to bound entity retrieval work and prevent pathological policies, while entity manifests are used to more efficiently define the needed entity data. We could imagine a deployment strategy in which we accept this RFC and perform generic entity slicing as described here, and then later implement entity manifests, and start performing slicing using those instead.</p>
<h3 id="alternative-level-in-the-schema-not-as-a-validation-parameter"><a class="header" href="#alternative-level-in-the-schema-not-as-a-validation-parameter">Alternative: Level in the schema, not as a validation parameter</a></h3>
<p>Instead of specifying the validation level as a parameter to the validation algorithm, we could specify it directly in schemas. The benefit of this is that policy writers can see the expected form of policies in one place. For example, we could extend our schema from the initial example as follows:</p>
<pre><code>level = 1;
entity User {
    manager: User,
    age: Long,
};
action getDetails appliesTo { ... }
</code></pre>
<p>Policy writers know, by seeing <code>level = 1</code>, that they can write <code>principal.manager</code> in policies, but not <code>principal.manager.manager</code>.</p>
<p>On the other hand, you could imagine that different applications might like to use the same schema file but have different restrictions on entity retrieval, owing to the efficiency of a chosen storage strategy. For example, in a graph database, retrieving data may be efficient no matter what the level is, whereas in a relational database, each level might necessitate another join query, which could be very inefficient.</p>
<p>Specifying levels in schemas also adds a complication when multiple schema files are used during validation. When a user specifies multiple files, they are effectively concatenated together by validator. What should happen if multiple files specify <code>level</code> and the level is different? One approach is that the validator would allow at most one to have a <code>level</code> specification, else it's an error. Doing so serves the expected use-case that one of those files will be for the application, specifying the <code>action</code> types and the <code>level</code>, while any others will be only general <code>entity</code> and <code>type</code> definitions, which are not application specific and thus need not concern themselves with entity slicing.</p>
<h3 id="alternative-per-entity-levels-rather-than-a-global-level"><a class="header" href="#alternative-per-entity-levels-rather-than-a-global-level">Alternative: Per-entity levels, rather than a global level</a></h3>
<p>We might refine in-schema <code>level</code> to not apply to all entities, but rather to particular entity types. For example, for <code>User</code> entities (bound to <code>principal</code>) we might specify level 2 but for any other entity type we specify <code>level</code> as 0, as per the following schema:</p>
<pre><code>@level(2)
entity Issue = {
  repo: Repository
};
@level(0)
entity Repository = {
  owner: User,
  readers: Set&lt;User&gt;,
};
@level(0)
entity User = {
  manager: User
};
action ReadIssue appliesTo { principal: User, resource: Issue };
</code></pre>
<p>Per-entity levels allows you to reduce the entities you provide in the slice — given a request, you get the types of the principal and resource entities, look up what their levels are from the schema, and then provide data up to that level for each. Validation for per-entity levels is also a straightforward generalization of the algorithm sketched above.</p>
<p>Note that per-entity levels adds some complication to understandability, in particular for nested attributes. The question is whether the performance benefits are worth it. Suppose I have a policy</p>
<pre><code>permit(principal, action, resource) when {
  resource.repo.owner.manager == principal
};
</code></pre>
<p>This is allowed because <code>Issue</code> is labeled with level 2. That means that we are allowed to write <code>resource.repo.owner.manager</code> (two levels of dereference beyond the first, allowed one by level 0). But this is a little confusing because we wrote <code>@level(0)</code> on <code>Repository</code>, and yet we are accessing one of its attributes. The reason that’s Ok is that <code>Repository</code> never actually is bound to <code>principal</code> or <code>resource</code>, so the level is irrelevant.</p>
<h3 id="alternative-full-support-for-entity-literals"><a class="header" href="#alternative-full-support-for-entity-literals">Alternative: Full support for entity literals</a></h3>
<p>Entity literals cannot be dereferenced. That means that, <em>at all levels</em>, they can only appear in <code>==</code> expressions or on the RHS of <code>in</code>. This captures use-cases that we know about. However, if you wanted to use them on the LHS of <code>in</code> or access their attributes, one approach to doing this would be to extend <a href="https://github.com/cedar-policy/rfcs/blob/main/text/0053-enum-entities.md">enumerated entity types</a> to normal entity type definitions. For example,</p>
<pre><code>entity User in [Team] enum { "default" @level } = {
  manager: User,
  organization: Org
}; 
</code></pre>
<p>This would say that there is a <code>User</code> entity whose ID is <code>default</code> which should always be present in the entity slice, e.g., along with other entities for the principal, resource, etc. That presence is at the level specified globally, e.g., if level was 1, then just the <code>User::"default"</code> and its direct attributes would be included, but not the entities those attributes point to.</p>
<h3 id="alternatives-extensions-to-reduce-ancestor-requirements"><a class="header" href="#alternatives-extensions-to-reduce-ancestor-requirements">Alternatives: Extensions to reduce ancestor requirements</a></h3>
<p>One drawback of level is that it gets <em>all</em> of an entity’s ancestors when it is included in a slice. This could be very expensive in the case that the entity has many such ancestors. For example, in TinyTodo, each <code>User</code> has <code>Team</code>-typed ancestors that correspond to the <code>viewers</code> or <code>editors</code> of the <code>List</code> entities which they can access. This could be 1000s of lists, which are expensive to acquire and to include in the request (especially if calling AVP). Worse, this work is apparently wasted because the policies can only ever look at <em>some</em> of these ancestors, notably those reachable from the <code>editors</code> or <code>viewers</code> of the resource <em>also provided in the request</em>.</p>
<p>Instead of passing in a principal in a request with all of its ancestors, we could just as well pass in only those that are possibly referenced by policy operations. For TinyTodo, it would be those equal to <code>resource.viewers</code> or <code>resource.editors</code> (if they match). Since this invariant is not something the application necessarily knows for certain (it might be true of policies today, but those policies could change in the future), we want a way to <strong>reduce the provided ancestor data while being robust to how policy changes in the future</strong>. Here are three possible approaches to addressing this issue.</p>
<h4 id="alternative-1-leverage-partial-evaluation"><a class="header" href="#alternative-1-leverage-partial-evaluation">Alternative 1: Leverage partial evaluation</a></h4>
<p>We can use partial evaluation to solve this problem: Specify a concrete request with all of the needed attribute data, after entity selection, but <strong>set the ancestor data as **** <em>unknown</em></strong>. Partially evaluating such a request will result in results that have incomplete entity checks. These checks can then be handled by the calling application. This might be a nice feature we can package up and give to customers as a client-side library.</p>
<p>A drawback of this approach is that it could slow down evaluation times. This is because the entity hierarchy is used to perform policy slicing. In the worst case, you’d have to consider all possible policies. It might be possible to provide at least <em>some</em>of the hierarchy with the request to reduce the set of policies that are partially evaluated.</p>
<h4 id="alternative-2-ancestor-allow-lists"><a class="header" href="#alternative-2-ancestor-allow-lists">Alternative 2: Ancestor allow-lists</a></h4>
<p>When validating static policies, it’s possible to see which ancestors are potentially needed. Could we do something similar to level for policy validation, but for ancestors instead?</p>
<p>For TinyTodo policies above, we see the following expressions in policies:</p>
<ul>
<li><code>principal in resource.viewers</code></li>
<li><code>principal in resource.editors</code></li>
<li><code>principal in Team::"admin"</code></li>
</ul>
<p>For the other examples, the situation is similar. We also see multi-level access, e.g., with GitHub policies <code>principal in resource.repo.readers</code>, and we see recursive access through sets, e.g., for Hotel Chains we see <code>resource in principal.viewPermissions.hotelReservations</code> where <code>hotelReservations</code> is a set containing entities, rather than being a single entity.</p>
<p><em>Approach</em>: Add an annotation <code>@ancestors</code> to the <code>in</code> declarations around entities. When I write <code>entity User in [Team]</code>, add an annotation that enumerates the <code>Team</code>-typed expressions that can be on the RHS of <code>in</code> in policies. Here’s an example of the annotated TinyTodo schema:</p>
<pre><code>@ancestors(resource.viewers,resource.editors,Team::"admin",Team::"interns")
entity User in [Team, Application] = {
  "joblevel": Long,
  "location": String,
};
@ancestors()
entity Team in [Team, Application];
@ancestors()
entity List in [Application] = {
  "editors": Team,
  "name": String,
  "owner": User,
  "readers": Team,
  "tasks": Tasks,
};
@ancestors()
entity Application;
...
</code></pre>
<p>Notice that we annotate <code>List</code>, <code>Team</code>, or <code>Application</code> with <code>()</code> since entities of these types never appear on the LHS of <code>in</code>. An entity type with no annotation at all is assumed to require every potential ancestor.</p>
<p><em>Validation</em>: The validator will check for syntactic equality against the expressions in the annotation. In particular, when it sees an expression <code>E in F</code> in a policy, if <code>E</code> has an entity type that is annotated with the set of expressions <code>S</code> in the schema, then the validator will check that <code>F</code> ∈ <code>S</code>, using syntactic equality. With the above schema, all current TinyTodo policies would validate, while the following would not</p>
<pre><code>// Fails because a Team-typed entity is on the LHS of `in`,
//   but entity Team has no legal RHS expressions per the schema
permit(principal,action == Action::"GetList",resource)
when { resource.editors in Team::"admin" };

// Fails because Team::"temp" is not a legal RHS expression for User
permit(principal in Team::"temp",action,resource);
</code></pre>
<p><em>Entity selection</em>: When collecting ancestors during entity selection, the application only gets ancestors per the expressions in the annotation. To do that, it would evaluate these expressions for the current request, and provide the ancestors present in the result, if present. For example, suppose our TinyTodo request was</p>
<pre><code>principal = User::"Alice"
action    = Action::"GetList"
resource  = List::"123"
context   = {}
</code></pre>
<p>Since TinyTodo policies are level 2, we would provide entity data for both <code>User::"Alice"</code> and <code>List::"123"</code>. Suppose that the latter’s data is</p>
<pre><code>{ id = "123", 
  owner = User::"Bob",
  viewers = Team::"123viewers",
  editors = Team::"123editors"
}
</code></pre>
<p>The <code>principal</code> has type <code>User</code>, which is annotated in the schema with the following expressions, shown with what they evaluate to:</p>
<ul>
<li><code>resource.viewers</code> evaluates to <code>List::"123".viewers</code> which evaluates to <code>Team::"123viewers"</code></li>
<li><code>resource.editors</code> evaluates to <code>List::"123".editors</code> which evaluates to <code>Team::"123editors"</code></li>
<li><code>Team::"admin"</code> (itself)</li>
<li><code>Team::"interns"</code> (itself)</li>
</ul>
<p>Thus the application knows we can determine in advance whether <code>User::"Alice"</code> (the <code>principal</code>) has any of these four ancestors, and include them as such with <code>User::"Alice"</code>’s entity data, if so. No other ancestor data needs to be provided.</p>
<p>Note: The above algorithm i not very helpful for templates containing expressions <code>in ?resource</code> or <code>in ?principal</code> ( (templates with only <code>== ?principal</code> and <code>== ?resource</code> in them are fine, since they don’t check the ancestors). For these, you are basically forced to not annotate the entity type because <code>?resource</code> and <code>?principal</code> are not legal expressions. This makes sense inasmuch as a template with constraint <code>principal in ?principal</code> tells us nothing about possible values to which <code>?principal</code> could be linked — the values could include potentially any entity, so in the worst case we’d need to include all possible ancestors. It may be that you could use further contextual data (like the action) to narrow the ones you provide.</p>
<p>Note: Interestingly, no policy-set example ever has an expression other than <code>principal</code> or <code>resource</code> on the LHS of <code>in</code>. The scheme above is not leveraging this fact.</p>
<p>Note: This approach composes nicely with the per-entity <code>@level</code> approach sketched above.</p>
<h3 id="alternative-reduce-attribute-requirements"><a class="header" href="#alternative-reduce-attribute-requirements">Alternative: Reduce attribute requirements</a></h3>
<p>The per-entity level approach is one way to reduce attribute requirements, but only across levels — for a particular entity you still must provide <em>all</em> of its attributes if you are providing its data. We might like to provide only <em>some</em> attributes, similar to the alternative that requires only some, not all, ancestors.</p>
<p>As discussed earlier, partial evaluation can be used to help here. There could also be some sort of allow-list for attributes. Probably it would make sense to associate allow-lists with actions.</p>
<h2 id="appendix-accepted-policy-sets"><a class="header" href="#appendix-accepted-policy-sets">Appendix: Accepted policy sets</a></h2>
<p>All existing policies in published example Cedar applications can be validated using levels. In particular, the following policy sets validate at level 1:</p>
<ul>
<li>Tags and roles: https://github.com/cedar-policy/cedar-examples/tree/main/cedar-example-use-cases/tags_n_roles</li>
<li>Sales orgs: https://github.com/cedar-policy/cedar-examples/tree/main/cedar-example-use-cases/sales_orgs</li>
<li>Hotel chains: https://github.com/cedar-policy/cedar-examples/tree/main/cedar-example-use-cases/hotel_chains</li>
</ul>
<p>And the following validate at level 2:</p>
<ul>
<li>TinyTodo: https://github.com/cedar-policy/cedar-examples/blob/main/tinytodo/policies.cedar and also https://github.com/cedar-policy/cedar-examples/blob/main/tinytodo/policies-templates.cedar
<ul>
<li>Policy 6 includes expression <code>resource.owner.location</code></li>
</ul>
</li>
<li>Tax Preparer: https://github.com/cedar-policy/cedar-examples/blob/main/cedar-example-use-cases/tax_preprarer/policies.cedar
<ul>
<li>The access rule involves checking something to the effect of <code>principal.assigned_orgs.contains(resource.owner.organization)</code>.</li>
</ul>
</li>
<li>Document cloud: https://github.com/cedar-policy/cedar-examples/blob/main/cedar-example-use-cases/document_cloud/policies.cedar
<ul>
<li>This has policy expression <code>(resource.owner.blocked.contains(principal) || principal.blocked.contains(resource.owner))</code>. (It would not make sense to duplicated the <code>blocked</code></li>
</ul>
</li>
<li>GitHub: https://github.com/cedar-policy/cedar-examples/blob/main/cedar-example-use-cases/github_example/policies.cedar
<ul>
<li>Expressions like <code>principal in resource.repo.readers</code> are common: A resource like an issue or pull request inherits the permissions of the repository it is a part of, so the rules chase a pointer to that repository.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="datetime-extension"><a class="header" href="#datetime-extension"><code>datetime</code> extension</a></h1>
<h2 id="related-issues-and-prs-18"><a class="header" href="#related-issues-and-prs-18">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues:</li>
<li>Implementation PR(s):</li>
</ul>
<h2 id="timeline-19"><a class="header" href="#timeline-19">Timeline</a></h2>
<ul>
<li>Started: 2024-08-08</li>
<li>Accepted: 2024-09-11</li>
<li>Landed: TBD</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-20"><a class="header" href="#summary-20">Summary</a></h2>
<p>Cedar currently supports extension functions for IP addresses and decimal values.
A popular request has been support for dates and times as well, but there are several complexities here (e.g., timezones and leap years) that have delayed this.
Recall that anything we add to Cedar, we want to be able to formally model in Lean using our verification-guided development approach (see <a href="https://www.amazon.science/blog/how-we-built-cedar-with-automated-reasoning-and-differential-testing">this blog post</a>).
We also want to support a decidable SMT-based analysis (see <a href="https://dl.acm.org/doi/10.1145/3649835">this paper</a>).
The goal of this RFC is to narrow in on a set of date/time related features that are useful in practice, but still feasible to implement in Cedar given these constraints.</p>
<h2 id="basic-example-16"><a class="header" href="#basic-example-16">Basic example</a></h2>
<p>This RFC would support a policy like the following, which allows a user to access materials in the "device_prototypes" folder only if they have a sufficiently high job level and a tenure of more than one year.</p>
<pre><code class="language-cedar">permit(
  principal is User,
  action == Action::"view",
  resource in Folder::"device_prototypes"
)
when {
  principal.department == "HardwareEngineering" &amp;&amp;
  principal.jobLevel &gt;= 10 &amp;&amp;
  context.now.timestamp.durationSince(principal.hireDate) &gt; duration("365d")
};
</code></pre>
<h2 id="motivation-18"><a class="header" href="#motivation-18">Motivation</a></h2>
<p>Previously for applications that determine authorization based on date/time, our suggestion has been to use <a href="https://en.wikipedia.org/wiki/Unix_time">Unix time</a> (see Workaround A) or to pass the result of time computations in the context (see Workaround B).
But these are not ideal solutions because Cedar policies are intended to <em>expressive</em>,  <em>readable</em>, and <em>auditable</em>.
Unix timestamps fail the readability criteria: an expression like <code>context.now &lt; 1723000000</code> is difficult to read and understand without additional tooling to decode the timestamp.
Unix timestamps are also indistinguishable from any other integral value providing no additional help in expressing the abstraction of time.
Passing in pre-computed values in the context (e.g., a field like <code>context.isWorkingHours</code>) makes authorization logic difficult to audit because it moves this logic outside of Cedar policies and into the calling application.
It is also difficult for the calling application to predict the necessary pre-computed values that a policy writer requires for their intended purpose. These may change over time, and may also differ depending on the principal, action, and/or resource.</p>
<h3 id="additional-examples"><a class="header" href="#additional-examples">Additional examples</a></h3>
<p>The examples below illustrate the types of policies that this proposal would enable. It assumes that the application adds a Cedar Record named <code>now</code> to <code>context</code> with the following fields:</p>
<ul>
<li><code>timestamp</code>: A value of type <code>datetime</code> (defined below) representing the current time at policy evaluation</li>
<li><code>dayOfWeek</code>: A <code>long</code> value representing current the day of week (Sunday = 1, ... Saturday = 7)</li>
<li><code>day</code>: A <code>long</code> representing the current day of the month</li>
<li><code>month</code>: A <code>long</code> representing current month (January = 1)</li>
<li><code>year</code>: A <code>long</code> representing the current year</li>
</ul>
<p><strong>Only allow user "alice" to view JPEG photos for one week after creation.</strong></p>
<pre><code class="language-cedar">permit(
  principal == User::"alice",
  action == PhotoOp::"view",
  resource is Photo
) when {
  resource.fileType == "JPEG" &amp;&amp;
  context.now.timestamp.durationSince(resource.creationTime) &lt;= duration("7d")
};
</code></pre>
<p><strong>Allow access from a certain IP address only between 9am and 6pm UTC.</strong></p>
<pre><code class="language-cedar">permit(
  principal,
  action == Action::"access",
  resource
) when {
  context.srcIp.isInRange(ip("192.168.1.0/24")) &amp;&amp;
  context.workdayStart &lt;= context.now.timestamp &amp;&amp;
  context.now.timestamp &lt; context.workdayEnd
};
</code></pre>
<p><strong>Prevent employees from accessing work documents on the weekend.</strong></p>
<pre><code class="language-cedar">forbid(
  principal,
  action == Action::"access",
  resource is Document
) when {
  [1,7].contains(context.now.dayOfWeek)
};
</code></pre>
<p><strong>Permit access to a special opportunity for persons born on Leap Day.</strong></p>
<pre><code class="language-cedar">permit(
  principal,
  action == Action::"redeem",
  resource is Prize
) when {
  principal.birthDate.day == 29 &amp;&amp;
  principal.birthDate.month == 2 &amp;&amp;
  context.now.day == 29 &amp;&amp;
  context.now.month == 2
};
</code></pre>
<p><strong>Forbid access to EU resources after Brexit</strong></p>
<pre><code class="language-cedar">forbid(
  principal,
  action,
  resource
) when {
  context.now.timestamp &gt; datetime("2020-01-31T23:00:00Z") &amp;&amp;
  context.location.countryOfOrigin == 'GB' &amp;&amp;
  resource.owner == 'EU'
}
</code></pre>
<h2 id="detailed-design-19"><a class="header" href="#detailed-design-19">Detailed design</a></h2>
<p>This RFC proposes supporting two new extension types: <code>datetime</code>, which represents a particular instant of time, up to millisecond accuracy, and <code>duration</code> which represents a duration of time.
To construct and manipulate these types we will provide the functions listed below.
All of this functionality will be hidden behind a <code>datetime</code> feature flag (analogous to the current decimal and IP extensions), allowing users to opt-out.</p>
<h3 id="instants-of-time-datetime"><a class="header" href="#instants-of-time-datetime">Instants of Time (<code>datetime</code>)</a></h3>
<p>The <code>datetime(string)</code> function constructs a datetime value. Like with other extension function constructors, strict validation requires <code>string</code> to be a string literal, although evaluation/authorization support any string-typed expression. The string must be of one of the forms, and regardless of the timezone offset is always normalized to UTC:</p>
<ul>
<li><code>"YYYY-MM-DD"</code> (date only)</li>
<li><code>"YYYY-MM-DDThh:mm:ssZ"</code> (UTC)</li>
<li><code>"YYYY-MM-DDThh:mm:ss.SSSZ"</code> (UTC with millisecond precision)</li>
<li><code>"YYYY-MM-DDThh:mm:ss(+/-)hhmm"</code> (With timezone offset in hours and minutes)</li>
<li><code>"YYYY-MM-DDThh:mm:ss.SSS(+/-)hhmm"</code> (With timezone offset in hours and minutes and millisecond precision)</li>
</ul>
<p>The <code>datetime</code> type does not provide a way for a policy author to create a <code>datetime</code> from a numeric timestamp. One of the readable formats listed above must be used, instead.</p>
<p>Values of type <code>datetime</code> have the following methods:</p>
<ul>
<li><code>.offset(duration)</code> returns a new <code>datetime</code>, offset by duration.</li>
<li><code>.durationSince(DT2)</code> returns the difference between <code>DT</code> and <code>DT2</code> as a <code>duration</code>. (Note that the inverse of <code>durationSince</code> is <code>DT2.offset(duration)</code>).
An invariant for <code>DT1.durationSince(DT2)</code> is that when <code>DT1</code> is before <code>DT2</code> the resulting duration is negative.</li>
<li><code>.toDate()</code> returns a new <code>datetime</code>, truncating to the day, such that printing the <code>datetime</code> would have <code>00:00:00</code> as the time.</li>
<li><code>.toTime()</code> returns a new <code>duration</code>, removing the days, such that only milliseconds since <code>.toDate()</code> are left. This is equivalent to <code>DT.durationSince(DT.toDate())</code></li>
</ul>
<p>Values of type <code>datetime</code> can be used with comparison operators:</p>
<ul>
<li><code>DT1 &lt; DT2</code> returns <code>true</code> when <code>DT1</code> is before <code>DT2</code></li>
<li><code>DT1 &lt;= DT2</code> returns <code>true</code> when <code>DT1</code> is before or equal to <code>DT2</code></li>
<li><code>DT1 &gt; DT2</code> returns <code>true</code> when <code>DT1</code> is after <code>DT2</code></li>
<li><code>DT1 &gt;= DT2</code> returns <code>true</code> when <code>DT1</code> is after or equal to <code>DT2</code></li>
<li><code>DT1 == DT2</code> returns <code>true</code> when <code>DT1</code> is equal to <code>DT2</code></li>
<li><code>DT1 != DT2</code> returns <code>true</code> when <code>DT1</code> is not equal to <code>DT2</code></li>
</ul>
<p>Equality is based on the underlying representation (see below) so, for example, <code>datetime("2024-08-21T") == datetime("2024-08-21T00:00:00.000Z")</code> is true. This behavior is consistent with the decimal extension function, where <code>decimal("1.0") == decimal("1.0000")</code> is also true.</p>
<h4 id="representation"><a class="header" href="#representation">Representation</a></h4>
<p>The <code>datetime</code> type is internally represented as a <code>long</code> and contains a Unix Time in milliseconds. This is the number of non-leap seconds that have passed since <code>1970-01-01T00:00:00Z</code> in milliseconds. A negative Unix Time represents the number of milliseconds before <code>1970-01-01T00:00:00Z</code>. Unix Time days are always 86,400 seconds and handle leap seconds by absorbing them at the start of the day. Due to using Unix Time, and not providing a "current time" function, Cedar avoids the complexities of leap second handling, pushing them to the system and application.</p>
<h3 id="durations-of-time-duration"><a class="header" href="#durations-of-time-duration">Durations of Time (<code>duration</code>)</a></h3>
<p>The <code>duration(string)</code> function constructs a duration value from a duration string. Strict validation requires the argument to be a literal, although evaluation/authorization support any appropriately-typed expressions. The <code>string</code> is a concatenated sequence of quantity-unit pairs. For example, <code>"1d2h3m4s5ms"</code> is a valid duration string.</p>
<p>The quantity part is a natural number. The unit is one of the following:</p>
<ul>
<li><code>d</code>: days</li>
<li><code>h</code>: hours</li>
<li><code>m</code>: minutes</li>
<li><code>s</code>: seconds</li>
<li><code>ms</code>: milliseconds</li>
</ul>
<p>Duration strings are required to be ordered from largest unit to smallest unit, and contain one quantity per unit. Units with zero quantity may be omitted.
<code>"1h"</code>, <code>"-10h"</code>, <code>"5d3ms"</code>, and <code>"3h5m"</code> are all valid duration strings.</p>
<p>A duration may be negative. Negative duration strings must begin with <code>-</code>.</p>
<p>Values of type <code>duration</code> have the following methods:</p>
<ul>
<li><code>.toMilliseconds()</code> returns a <code>long</code> describing the number of milliseconds in this duration. (the value as a long, itself)</li>
<li><code>.toSeconds()</code> returns a <code>long</code> describing the number of seconds in this duration. (<code>.toMilliseconds() / 1000</code>)</li>
<li><code>.toMinutes()</code> returns a <code>long</code> describing the number of minutes in this duration. (<code>.toSeconds() / 60</code>)</li>
<li><code>.toHours()</code> returns a <code>long</code> describing the number of hours in this duration. (<code>.toMinutes() / 60</code>)</li>
<li><code>.toDays()</code> returns a <code>long</code> describing the number of days in this duration. (<code>.toHours() / 24</code>)</li>
</ul>
<p>Values with type <code>duration</code> can also be used with comparison operators:</p>
<ul>
<li><code>DUR1 &lt; DUR2</code> returns <code>true</code> when <code>DUR1</code> is shorter than <code>DUR2</code></li>
<li><code>DUR1 &lt;= DUR2</code> returns <code>true</code> when <code>DUR1</code> is shorter than or equal to <code>DUR2</code></li>
<li><code>DUR1 &gt; DUR2</code> returns <code>true</code> when <code>DUR1</code> is longer than <code>DUR2</code></li>
<li><code>DUR1 &gt;= DUR2</code> returns <code>true</code> when <code>DUR1</code> is longer than or equal to <code>DUR2</code></li>
<li><code>DUR1 == DUR2</code> returns <code>true</code> when <code>DUR1</code> is equal to <code>DUR2</code></li>
<li><code>DUR1 != DUR2</code> returns <code>true</code> when <code>DUR1</code> is not equal to <code>DUR2</code></li>
</ul>
<p>Comparisons are done with respect to the sign of a duration. I.e., <code>duration("-1d") &lt; duration("1s")</code>.</p>
<p>Equality is based on the underlying representation (see below) so, for example, <code>duration("1d") == duration("24h")</code> is true.</p>
<h4 id="representation-1"><a class="header" href="#representation-1">Representation</a></h4>
<p>The <code>duration</code> type is internally represented as a quantity of milliseconds as a <code>long</code>, which can be positive, negative, or zero.</p>
<p>A negative duration may be useful when a user wants to use <code>.offset()</code> to shift a date backwards.
For example: <code>context.now.offset(duration("-3d"))</code> expresses "three days before the current date".</p>
<h3 id="errors"><a class="header" href="#errors">Errors</a></h3>
<p>All the extension functions proposed in this RFC will throw a type error at authorization time if called with the wrong type of arguments.
Additionally, the <code>datetime</code> and <code>duration</code> constructors will return an error if the input string does not match the expected format, or if the internal representation of the value (a 64-bit signed int) would overflow. <code>.offset(duration)</code> will return an error if the resulting datetime would overflow.</p>
<p>As noted above, strict validation will require passing literals to the <code>duration</code> and <code>datetime</code> constructors, and it will raise an error if those strings are malformed. Otherwise, validation is straightforward.</p>
<h3 id="json-encoding"><a class="header" href="#json-encoding">JSON Encoding</a></h3>
<p>Cedar supports a JSON format for policies, schemas, entities, and request contexts. The JSON representation of the <code>datetime</code> and <code>duration</code> functions will match the precedents set by the existing IP address and decimal extensions.</p>
<p>For example, here is the JSON encoding of the expression <code>datetime("2020-01-31T23:00:00Z")</code>, which might occur in a policy condition:</p>
<pre><code class="language-json">"datetime": [
    {
        "Value": "2020-01-31T23:00:00Z"
    }
]
</code></pre>
<p>And here is the JSON encoding for this value when it occurs in entity or context data:</p>
<pre><code class="language-json">{ "__extn": { "fn": "datetime", "arg": "2020-01-31T23:00:00Z" } }
</code></pre>
<p>Finally, here is the JSON encoding of the <code>datetime</code> type in a schema:</p>
<pre><code class="language-json">{
    "type": "Extension",
    "name": "datetime"
}
</code></pre>
<h3 id="out-of-scope"><a class="header" href="#out-of-scope">Out of scope</a></h3>
<ul>
<li>
<p><strong>Conversion between UTC and epochs:</strong> This will be particularly difficult to model and verify in Lean (although it's technically possible, see <a href="https://dl.acm.org/doi/abs/10.1145/3636501.3636958">this paper</a> which does something similar in the Coq proof assistant). Since it will likely require input-dependent loops, it is unlikely that this can be reasoned about efficiently with SMT.</p>
</li>
<li>
<p><strong>Conversion between UTC and other time zones:</strong> Time Zones are a notoriously complex system that evolves rapidly. We avoid this complexity by offering <code>datetime.offset(duration).</code> Policy authors that require "local time" can either provide an additional datetime in <code>context</code> or provide a <code>duration</code> to the <code>context</code> and call <code>.offset()</code> to shift the time.</p>
</li>
<li>
<p><strong>Function to get current time:</strong> A natural extension of this proposal would be a function <code>currentTime()</code> that provides the current time instead of it being passed in through <code>context</code>. However, <code>currentTime()</code> is stateful, i.e. not pure, and cannot be modeled in SMT. It's also not useful: <code>currentTime() == currentTime()</code> may return false, and Cedar does not provide local bindings (e.g. <code>let t = currentTime()</code>). For testing purposes, Cedar would also need to provide some way to override <code>currentTime</code>. These problems all go away if <code>currentTime()</code> is not supported.</p>
</li>
<li>
<p><strong>Leap seconds and leap years:</strong> Cedar does not have a clock, and this proposal does not add one. Instead, applications pass the current time through <code>context</code> or an entity and let the system / application handle complexities like leap seconds and leap years. This means that Cedar cannot provide utilities like <code>datetime.dayOfWeek()</code> or <code>datetime.dayOfMonth()</code>. Cedar applications that wish to define policies based on these ideas should pass pre-computed properties through entities or through the <code>context</code>.</p>
</li>
</ul>
<h3 id="support-for-datetime-in-other-authorization-systems"><a class="header" href="#support-for-datetime-in-other-authorization-systems">Support for date/time in other authorization systems</a></h3>
<p>AWS IAM supports <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition_operators.html#Conditions_Date">date condition operators</a>, which can check relationships between date/time values in the ISO 8601 date format or Unix time. You can find an example of a IAM policy using date/time <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_aws-dates.html">here</a>.</p>
<p><a href="https://www.openpolicyagent.org">Open Policy Agent</a> provides a <a href="https://www.openpolicyagent.org/docs/latest/policy-reference/#time">Time API</a> with nanosecond precision and extensive time zone support. During policy evaluation, the current timestamp can be returned, and date/time arithmetic can be performed. The <code>diff</code> (equivalent to our proposed <code>durationSince</code> operator on <code>datetime</code>) returns an array of positional time unit components, instead of a value typed similarly to our proposed <code>duration</code>.</p>
<h2 id="alternatives-18"><a class="header" href="#alternatives-18">Alternatives</a></h2>
<p>Both alternatives we propose here are "do nothing" options. They show how to encode date/time using existing Cedar types and functionality.</p>
<h3 id="workaround-a-represent-unix-time-with-a-long"><a class="header" href="#workaround-a-represent-unix-time-with-a-long">Workaround A: Represent Unix time with a Long</a></h3>
<p>Cedar has long suggested workarounds for date/time functionality by using the comparison and arithmetic operators with <code>context</code>-provided Unix Timestamps.</p>
<p>Here are the previous examples rewritten to use Unix Time.</p>
<p><strong>Only allow experienced, tenured persons from the Hardware Engineering department to see prototypes.</strong></p>
<pre><code class="language-cedar">permit(
  principal is User,
  action == Action::"view",
  resource in Folder::"device_prototypes"
)
when {
  principal.department == "HardwareEngineering" &amp;&amp;
  principal.jobLevel &gt;= 10 &amp;&amp;
  (context.currentTime - (365 * 24 * 60 * 60)) &gt;= principal.hireDate
};
</code></pre>
<p><strong>Only allow user "alice" to view JPEG photos for one week after creation.</strong></p>
<pre><code class="language-cedar">permit(
  principal == User::"alice",
  action == PhotoOp::"view",
  resource is Photo
) when {
  resource.fileType == "JPEG" &amp;&amp;
  resource.creationDate &lt;= (context.currentTime - (7 * 24 * 60 * 60))
};
</code></pre>
<p><strong>Allow access from a certain IP address only between 9am and 6pm UTC.</strong></p>
<p>Cedar <em>does not currently support</em> arithmetic division (<code>/</code>) or remainder (<code>%</code>), and therefore this example is <em>not expressible</em>, today.</p>
<pre><code class="language-cedar">permit(
  principal,
  action == Action::"access",
  resource
) when {
  context.srcIp.isInRange(ip("192.168.1.0/24")) &amp;&amp;
  9 &lt;= ((context.currentTime / (60 * 60)) % 24) &amp;&amp;
  ((context.currentTime / (60 * 60)) % 24) &lt; 18
};
</code></pre>
<p>Note that the localized version of this example, with timezone offset, could be supported using the <code>+</code> or <code>-</code> operators on <code>context.currentTime</code>.</p>
<p><strong>Prevent employees from accessing work documents on the weekend.</strong></p>
<p>With Unix Time, this requires <code>/</code> and <code>%</code> operators to compute the <code>dayOfWeek</code>, which isn't currently expressible in Cedar.</p>
<p><strong>Permit access to a special opportunity for persons born on Leap Day.</strong></p>
<p>With Unix Time, this requires <code>/</code> and <code>%</code> operators to compute whether or not it is a leap year, which isn't currently expressible in Cedar.</p>
<p><strong>Forbid access to EU resources after Brexit</strong></p>
<pre><code class="language-cedar">forbid(
  principal,
  action,
  resource
) when {
  context.currentTime &gt; 1580511600 &amp;&amp;
  context.location.countryOfOrigin == 'GB' &amp;&amp;
  resource.owner == 'EU'
}
</code></pre>
<h3 id="workaround-b-pass-results-of-time-checks-in-the-context"><a class="header" href="#workaround-b-pass-results-of-time-checks-in-the-context">Workaround B: Pass results of time checks in the context</a></h3>
<p>Another workaround we have suggested is to simply handle date/time logic <em>outside</em> of Cedar, and pass the results of checks in the <code>context</code>. For example, you could pass in fields like  <code>context.isWorkingHours</code> or <code>context.dayOfTheWeek</code>.</p>
<p>Here are the previous examples rewritten to use additional context.</p>
<p><strong>Only allow experienced, tenured persons from the Hardware Engineering department to see prototypes.</strong></p>
<pre><code class="language-cedar">permit(
  principal is User,
  action == Action::"view",
  resource in Folder::"device_prototypes"
)
when {
  principal.department == "HardwareEngineering" &amp;&amp;
  principal.jobLevel &gt;= 10 &amp;&amp;
  principal.hireDate &lt;= context.minimumHiringDateForAccess
};
</code></pre>
<p>Note: assumes <code>context.hireDate</code> and <code>context.minimumHiringDateForAccess</code> are <code>long</code> values (e.g., Unix time).</p>
<p><strong>Only allow user "alice" to view JPEG photos for one week after creation.</strong></p>
<pre><code class="language-cedar">permit(
  principal == User::"alice",
  action == PhotoOp::"view",
  resource is Photo
) when {
  resource.fileType == "JPEG" &amp;&amp;
  resource.creationDate &gt;= context.oldestViewableDate
};
</code></pre>
<p>Note: assumes <code>resource.creationDate</code> and <code>context.oldestViewableDate</code> are <code>long</code> values (e.g., Unix time).</p>
<p><strong>Allow access from a certain IP address only between 9am and 6pm UTC.</strong></p>
<pre><code class="language-cedar">permit(
  principal,
  action == Action::"access",
  resource
) when {
  context.srcIp.isInRange(ip("192.168.1.0/24")) &amp;&amp;
  context.isWorkingHours
};
</code></pre>
<p><strong>Prevent employees from accessing work documents on the weekend.</strong></p>
<pre><code class="language-cedar">forbid(
  principal,
  action == Action::"access",
  resource is Document
) when {
  context.isTheWeekend
};
</code></pre>
<p><strong>Permit access to a special opportunity for persons born on Leap Day.</strong></p>
<pre><code class="language-cedar">permit(
  principal,
  action == Action::"redeem",
  resource is Prize
) when {
  context.isMyBirthday &amp;&amp; context.isLeapDay
};
</code></pre>
<p><strong>Forbid access to EU resources after Brexit</strong></p>
<pre><code class="language-cedar">forbid(
  principal,
  action,
  resource
) when {
  context.afterBrexit &amp;&amp;
  context.location.countryOfOrigin == 'GB' &amp;&amp;
  resource.owner == 'EU'
}
</code></pre>
<h2 id="discussion-notes-1"><a class="header" href="#discussion-notes-1">Discussion notes</a></h2>
<h3 id="local-time"><a class="header" href="#local-time">Local time</a></h3>
<p>The current proposal has no direct support for local time, or time zones outside of UTC. Providing robust time zone support would add significant complications to the formal models and ruin the project's SMT-based analysis goals. Policy authors wishing to use local time can simulate it by:</p>
<ul>
<li>providing offsets, of the form <code>+/-hhmm</code>, to the time strings used by <code>datetime()</code>. (Note: no time zone information is retained. The time will be converted to UTC)</li>
<li>utilizing the <code>datetime.offset()</code> method with <code>duration</code> values, or values passed through entities and/or <code>context</code>.</li>
</ul>
<p>Consider the policy below that checks if a principal's local time is between 09:00 and 17:00.</p>
<pre><code class="language-cedar">permit(
  principal,
  action == Action::"access",
  resource
) when {
  context.now.timestamp.offset(principal.timeZoneOffset).toTime() &gt;= duration("9h") &amp;&amp;
  context.now.timestamp.offset(principal.timeZoneOffset).toTime() &lt;= duration("17h")
};
</code></pre>
<h3 id="operator-overloading"><a class="header" href="#operator-overloading">Operator overloading</a></h3>
<p>This RFC proposes to use operators <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, and <code>&gt;=</code> for comparing <code>datetime</code> and <code>duration</code> objects.
Currently in Cedar, these operations are only supported for <code>long</code>-typed values.
For other extension types with similar operations, Cedar instead uses extension functions (e.g., <code>.lessThan()</code> for decimal values).</p>
<p>This RFC proposes to <em>reverse</em> this decision, and instead allow using builtin operators for extension functions, as appropriate.
This will add some implementation complexity (at least in the primary <a href="https://github.com/cedar-policy/cedar">Rust implementation</a>), but it will make policies that use these operations easier to read and easier to write.</p>
<h3 id="millisecond-precision"><a class="header" href="#millisecond-precision">Millisecond precision</a></h3>
<p>The current proposal supports milliseconds. The ISO 8601 format does not specify a maximum precision, so we can technically allow any number of <code>S</code>s after the <code>.</code> in <code>YYYY-MM-DDThh:mm:ss.SSSZ</code>. Based on <a href="https://nickb.dev/blog/iso8601-and-nanosecond-precision-across-languages/">this blog post</a>, it appears that Javascript supports milliseconds (3 digits), Python supports microseconds (6 digits), and Rust and Go support nanoseconds (9 digits). Assuming nanosecond accuracy, the maximum (signed) 64-bit number (2^63 - 1) represents April 11, 2262. This date seems far enough out that any of these choices (milliseconds, microseconds, or nanoseconds) seems reasonable.</p>
<p>During discussion, we decided that sub-second accuracy was potentially useful, but we did not have a use case in mind for sub-millisecond accuracy.
So in the end we landed on milliseconds.
Note that this is the backwards compatible option (at least with respect to allowable date/time strings) because we can add precision later, but not remove it without a breaking change.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="entity-tags-with-dedicated-syntax-and-semantics"><a class="header" href="#entity-tags-with-dedicated-syntax-and-semantics">Entity tags with dedicated syntax and semantics</a></h1>
<h2 id="related-issues-and-prs-19"><a class="header" href="#related-issues-and-prs-19">Related issues and PRs</a></h2>
<ul>
<li>Reference Issues: <a href="https://github.com/cedar-policy/cedar/issues/305">#305</a></li>
<li>Supersedes <a href="https://github.com/cedar-policy/rfcs/pull/68">RFC 68</a></li>
<li>Implementation PR(s): (leave this empty)</li>
</ul>
<h2 id="timeline-20"><a class="header" href="#timeline-20">Timeline</a></h2>
<ul>
<li>Started: 2024-09-11</li>
<li>Accepted: TBD</li>
<li>Landed: TBD</li>
<li>Released: TBD</li>
</ul>
<h2 id="summary-21"><a class="header" href="#summary-21">Summary</a></h2>
<p>This RFC proposes to extend the Cedar language, type system, and symbolic analysis to include full-featured <em>entity tags</em> for entity types. Tags are a mechanism used by cloud services to attach key-value pairs to resources. Cedar will allow them to be attached to any entities (not just resources).</p>
<p>For evaluation purposes, entity tags are accessed using the methods <code>expr1.hasTag(expr2)</code> and <code>expr1.getTag(expr2)</code>, where <code>expr1</code> evaluates to an entity and <code>expr2</code> to a string.  These are the only ways to access the tags on an entity.  The policy syntax, semantics, type system, and symbolic analysis are extended to support these two methods.  The schema syntax and the entity JSON format are extended to support defining entity tags and their types.</p>
<p>Entity tags strictly increase the expressiveness of Cedar because they allow <em>computed keys</em>, unlike records and entities. Specifically, tag keys need not be literals, so it is possible to write <code>resource.hasTag(context.tag)</code> and <code>resource.getTag(context.tag)</code>.</p>
<p>This proposal is backward-compatible in the sense that existing polices, schemas, entities, etc., do not need to change to accommodate the addition of tags to the language.</p>
<p>This RFC has gone through several revisions, with different revisions proposing alternative designs. The alternatives are discussed at the end of this document.</p>
<h3 id="basic-example-17"><a class="header" href="#basic-example-17">Basic example</a></h3>
<p>Here is a schema defining two entities, each of which contains entity tags.</p>
<pre><code>entity User = {
  jobLevel: Long,
} tags Set&lt;String&gt;;
entity Document = {
  owner: User,
} tags Set&lt;String&gt;;
</code></pre>
<p>The <code>User</code> and <code>Document</code> entities each have entity tags, denoted by <code>tags Set&lt;String&gt;</code>, implementing tags whose values are sets of strings.  The declaration <code>tags Set&lt;String&gt;</code> indicates an unspecified number of optional tags that all have values of type <code>Set&lt;String&gt;</code>.  (Of course, any type could be written, for instance <code>Long</code>, not just <code>Set&lt;String&gt;</code>.) Note that the set of tag (keys) does not have to be defined in the schema, but the type of all tag values needs to be the same (here, <code>Set&lt;String&gt;</code>).  (You cannot have tag <code>foo</code> have value <code>2</code>, and tag <code>bar</code> have value <code>"spam"</code>.)  Note also that there is no way to name the key-value map representing tags; you cannot treat it as a Cedar record or even compare it for equality to the tag-map on a different entity; you can only compare the values of individual keys.</p>
<p>Here's a policy that conforms to this schema:</p>
<pre><code>permit (
  principal is User,
  action == Action::"writeDoc",
  resource is Document)
when {
  document.owner == principal ||
    (principal.jobLevel &gt; 6 &amp;&amp;
    resource.hasTag("write") &amp;&amp;
    principal.hasTag("write") &amp;&amp;
    resource.getTag("write").containsAny(principal.getTag("write")))
};
</code></pre>
<p>This policy states that for a <code>User</code> to carry out the <em>writeDoc</em> action on a <code>Document</code>, the user must own the document, or else the user's job level must be at least 6 and the document and the user must each have a <code>write</code> tag, where at least one of the user's write-tag's values must be present in the document's write-tag's values.</p>
<h2 id="detailed-design-20"><a class="header" href="#detailed-design-20">Detailed design</a></h2>
<p>To support entity tags, we need to extend the JSON format for entities, the JSON and natural syntax for schemas, the policy syntax, as well as the evaluator, validator, and symbolic compiler.</p>
<h3 id="policy-syntax-and-semantics"><a class="header" href="#policy-syntax-and-semantics">Policy syntax and semantics</a></h3>
<p>Tags support two binary operators, where <code>e</code> and <code>k</code> are Cedar expressions:</p>
<pre><code>e.hasTag(k)
e.getTag(k)
</code></pre>
<p>The <code>hasTag</code> operator tests if the entity <code>e</code> has a tag with the key <code>k</code>.  This operator errors if <code>e</code> is not an entity, or <code>k</code> is not a string. It returns <code>false</code> if <code>e</code> doesn't have any tags at all to match the behavior of the <code>has</code> operator on entities and records. In other words, having no tags is equivalent to having an empty tags-map. The <code>getTag</code> operator retrieves the value for the key <code>k</code> from the tags for the entity <code>e</code>.  This operator errors under the same conditions as <code>hasTag</code> and additionally, if <code>e</code> has no tag with the key <code>k</code>.</p>
<p>At the code level, we will extend the Cedar CST, AST, and EST to include the new operators (either as separate nodes in the relevant trees or as two extra binary operators), and we'll extend the evaluator to implement the above semantics.</p>
<h3 id="json-entity-format"><a class="header" href="#json-entity-format">JSON entity format</a></h3>
<p>The JSON entity format is extended to support optionally specifying tags separately from entity attributes:</p>
<pre><code>[
    {
        "uid": {},
        "parents": [],
        "attrs": {},
        "tags": {}
    },
    {
        ...
    }
]
</code></pre>
<h3 id="schema-1"><a class="header" href="#schema-1">Schema</a></h3>
<p>We extend schemas as follows to support the declaration of a tags. Here's the natural syntax:</p>
<pre><code>Entity := 'entity' Idents ['in' EntOrTyps] [['='] EntityRecType] ['tags' Type] ';'
</code></pre>
<p>The new syntax simply extends the <code>Entity</code> production to enable optionally specifying the type of attached tags.</p>
<p>The JSON syntax for schemas specifies tags as a separate <code>tags</code> field that specifies the type of the tag values. Here's our introductory example schema in this format:</p>
<pre><code>"entityTypes": {
    "User" : {
        "shape" : {
            "type" : "Record",
            "attributes" : {
                "jobLevel" : {
                    "type" : "Long"
                },
            }
        },
        "tags" : {
            "type" : "Set",
            "element": { "type": "String" }
        }
    },
    "Document" : {
        "shape" : {
            "type" : "Record",
            "attributes" : {
                "owner" : {
                    "type" : "Entity",
                    "name" : "User"
                },
            }
        },
        "tags" : {
          "type" : "Set",
          "element": { "type": "String" }
        }
    }
}
</code></pre>
<h3 id="validating-policies-1"><a class="header" href="#validating-policies-1">Validating policies</a></h3>
<p>We extend the policy validator to handle the <code>hasTag</code> and <code>getTag</code> operators analogously to how it handles the <code>has</code> and <code>.</code> operator on records and entities.</p>
<h4 id="capabilities-1"><a class="header" href="#capabilities-1">Capabilities</a></h4>
<p>Background: While typechecking an expression involving records or entities with optional attributes, the validator tracks <em>capabilities</em>. These represent the attribute-accessing expressions that are sure to succeed. If <code>principal</code> has type <code>User</code> and <code>User</code> has an optional <code>Boolean</code> attribute <code>sudo</code>, then the expression <code>principal.sudo</code> only validates if <code>principal.sudo</code> is present in the <em>current capability set</em>. Capabilities are added to that set by a preceding expression of the form <code>principal has sudo</code>, e.g., as in <code>principal has sudo &amp;&amp; principal.sudo</code>.</p>
<p>Capability tracking must be generalized to support tags. In particular, <code>tags T</code> should be treated as a record with optional attributes, and <code>hasTag</code> checks on its keys should update the capability set. For our introductory example, consider the following expression</p>
<pre><code>  resource.hasTag("write") &amp;&amp; // (1)
  principal.hasTag("write") &amp;&amp;  // (2)
  resource.getTag("write").containsAny(principal.getTag("write")) // (3)
</code></pre>
<p>After the subexpression (1), <code>resource.hasTag("write")</code> should be added to the current capability set. After subexpression (2), <code>principal.hasTag("write")</code> should be added to it. Finally, when validating subexpression (3), the expression <code>resource.getTag("write")</code> will be considered valid since <code>resource.hasTag("write")</code> is in the current capability set and it will be given type <code>Set&lt;String&gt;</code>, as the <code>tags</code> for <code>resource</code> has type <code>Set&lt;String&gt;</code>. The expression <code>principal.getTag("write")</code> is handled similarly. If either of the <code>hasTag</code> subexpressions (1) or (2) were omitted, subexpression (3) would not validate due to the missing capability set entries.</p>
<p>For entity types with no <code>tags</code> declaration in the schema, the validator gives <code>hasTag</code> the type <code>False</code> (to support short-circuiting), and rejects <code>getTag</code>.</p>
<h3 id="validating-and-parsing-entities-1"><a class="header" href="#validating-and-parsing-entities-1">Validating and parsing entities</a></h3>
<p>The Cedar authorizer's <code>is_authorized</code> function can be asked to validate that entities in a request are consistent with a provided schema. Extending validation to work with tags is straightforward. We check that every value in the <code>tags</code> map for an entity <code>e</code> has type <code>T</code> given that type of <code>e</code> is declared to have <code>tags T</code>.  If the type <code>e</code> doesn't have <code>tags</code> in the schema, then specifying a <code>tags</code> field is an error.</p>
<p>Similarly, schema-based parsing considers schemas when parsing in entities, and it can confirm when parsing that the contents of <code>tags</code> attribute in the JSON have the appropriate shape, and if the type <code>T</code> has different behavior under schema-based parsing (for instance, if it is an extension type), then schema-based parsing can interpret the <code>tags</code> appropriately.</p>
<h3 id="symbolic-compilation"><a class="header" href="#symbolic-compilation">Symbolic compilation</a></h3>
<p>Tags as defined here have an efficient logical representation as <em>uninterpreted binary functions</em>.  In particular, for each declaration <code>entity E ... tags T</code>, we introduce an uninterpreted function <code>f_E</code> of type <code>E -&gt; String -&gt; Option T</code>.  With this representation, we can straightforwardly translate the <code>hasTag</code> and <code>getTag</code> operations as applications of the function <code>f_E</code>, where the absence of a key is denoted by binding it to the value <code>(none T)</code>.</p>
<h2 id="drawbacks-19"><a class="header" href="#drawbacks-19">Drawbacks</a></h2>
<p>Entity types are permitted to have a single <code>tags</code> declaration <code>tags T</code>, which eliminates the possibility of attaching multiple tags-maps to a single entity (unlike <a href="https://github.com/cedar-policy/rfcs/pull/68">RFC 68</a>).  This RFC also does not support tags containing other tags-maps, comparing tags-maps with <code>==</code>, and the like (as discussed above).</p>
<p>The use-cases that we are aware of do not suffer due to these limitations. If you wanted tags-maps to contain other tags-maps, or you wanted to store tags-maps in the <code>context</code> record, or you wanted to attach multiple tags-maps to a single entity, you can create specific entity types with those tags. For example:</p>
<pre><code>entity User {
  roles: Set&lt;String&gt;,
  accessLevels: IntTags
} tags StringTags;
entity StringTags {
} tags String;
entity IntTags {
} tags Long;
</code></pre>
<p>In effect, the <code>User</code>'s tags is equivalent to <code>tags (tags String)</code>, but we have added a level of indirection by expressing the inner <code>(tags String)</code> value as an entity with <code>tags String</code>. Similarly, the <code>User</code>'s <code>accessLevels</code> attribute is equivalent to <code>(tags Long)</code>. So, we can express policies such as:</p>
<pre><code>permit(principal is User, action, resource is Document)
when {
  principal.roles.contains(context.role) &amp;&amp;
  principal.accessLevels.hasTag(context.role) &amp;&amp;
  principal.accessLevels.getTag(context.role) &gt; 3
};

permit(principal is User, action, resource is Document)
when {
  principal.hasTag("clearance") &amp;&amp;
  principal.getTag("clearance").hasTag("level") &amp;&amp;
  principal.getTag("clearance").getTag("level") == "top secret"
};
</code></pre>
<h3 id="implementation-effort-1"><a class="header" href="#implementation-effort-1">Implementation effort</a></h3>
<p>The implementation effort for adding tags is non-trivial, as it will require changing the Rust code, the Lean models and proofs, and the differential test generators. It will affect most components of Cedar, including the policy parser, CST→AST conversion, CST→EST conversion, (schema-based) entity parser, (partial) evaluator, validator, and the symbolic compiler.</p>
<p>While they affect most components of Cedar, these changes are relatively localized and straightforward, as outlined above.</p>
<h2 id="alternatives-and-workarounds"><a class="header" href="#alternatives-and-workarounds">Alternatives and workarounds</a></h2>
<p>This feature has gone through several revisions and iterations.  We compare this proposal to its predecessor, <a href="https://github.com/cedar-policy/rfcs/pull/68">RFC 68</a>, which discusses other alternatives and workarounds in detail.</p>
<p>RFC 68 proposes to add embedded attribute maps (EA-maps) to Cedar as a second-class, validation-time construct that behaves like a record with limited capabilities. Specifically, an entity attribute can have an EA-map type, but EA-maps cannot occur anywhere else (e.g., it is not possible to have a set of EA-maps).  EA-maps are treated as special second-class values during validation. But they are indistinguishable from records during evaluation.</p>
<p>In RFC 68, the validator enforces the second-class status of EA-map records by rejecting (some) expressions that attempt to treat EA-maps as first class values.  For example, the validator would reject <code>principal.authTags == resource.authTags</code>, where the <code>authTags</code> attribute of <code>principal</code> and <code>resource</code> is an EA-map of type <code>{ ? : Set&lt;String&gt; }</code>.  It would also reject <code>(if principal.isAdmin then principal.authTags else principal.authTags).write</code>.  However, it would accept <code>(if true then principal.authTags else resource.authTags).write</code> due to how capabilities work in Cedar's type system.  This behavior is confusing in that EA-maps don't appear to consistently act as second class values, and understanding when they do requires understanding the subtleties of how the Cedar type system works.</p>
<p>In RFC 68, the dynamic semantics is unaware of EA-maps. That is, the concept of EA-maps doesn't exist at evaluation time; they are just records. This leads to lower implementation burden (e.g., evaluator doesn't need to change), but it widens the gap between the dynamic and static (type-aware) semantics of Cedar. Specifically, EA-maps are first-class values during evaluation but not during validation.</p>
<p>EA-maps, as proposed in RFC 68, do not add any new expressiveness to Cedar.  Since EA-maps are just records at evaluation time, computed keys (such as <code>resource.getKey(context.tag)</code>) are disallowed. Adding computed keys (Alternative A in RFC 68) requires roughly the same implementation effort as implementing this proposal. But a downside of adding computed keys to RFC 68 is that doing so would further widen the gap between the dynamic and static semantics, since computed keys would be rejected by the validator but <em>not</em> the evaluator on records that aren't EA-maps.</p>
<p>Finally, after <a href="https://github.com/cedar-policy/cedar-spec/pull/418">modeling RFC 68 in Lean</a>, we found ourselves in an engineering corner, where the type-based enforcement of second-class status of EA-maps makes it difficult to prove a key property of the validator (every policy that is accepted by the validator is also accepted by the symbolic compiler), and also to model and reason about EA-maps in every component that depends on Cedar types.</p>
<p>The core issue is that RFC 68 does not distinguish, at the syntax and semantics level, between records and EA-maps.  This distinction must be enforced at the type level. In particular, we need to introduce a first-class EA-map type, which must then be treated as second-class in specific expressions during type checking and in proofs. The special-casing must be done for <code>==</code>, <code>if ... then ... else</code>, <code>hasAttr</code>, <code>getAttr</code>, <code>contains</code>, <code>containsAll</code>, <code>containsAny</code>, <code>set</code>, and <code>record</code> expressions.</p>
<p>This special-casing will have to be repeated in every component that gives a static (type-aware) semantics to Cedar---such as the symbolic compiler and, potentially, a type-aware partial evaluator. It will also need to be propagated into specifications and proofs of type-aware components. This is expected to increase the overall implementation and proof burden by thousands of lines of Lean code compared to this proposal. (In the symbolic compiler, the burden is further magnified because the special-casing of EA-map types has to be propagated into the underlying Term language too.)</p>
<p>This proposal avoids the issues of RFC 68 by introducing dedicated syntactic and semantic constructs for working with tags.  It is impossible, at the syntax level, to write a Cedar expression that evaluates to a (first-class) tags-map value. Rather, the contents of a tags-map are accessed by applying the <code>hasTag</code> and <code>getTag</code> operators to the entity that has the tags. These two operators are explicit in the AST, and they can be handled locally in the Lean model and proofs, without changing the handling of any other operator. This proposal also reflects tags in both the static and dynamic semantics, keeping their treatment consistent between the two.</p>
<p>Compared to RFC 68, this proposal represents a more substantial addition to the language, and it requires a significantly larger up-front implementation effort.  The tradeoff is that investing in the implementation now means that we won't have to consistently pay an implementation and proof penalty for every new type-aware component we add to Cedar.  And adopting the bigger language change now lets us keep the dynamic and static semantics consistent, freeing users from having to reason about the subtleties of Cedar's type system.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
